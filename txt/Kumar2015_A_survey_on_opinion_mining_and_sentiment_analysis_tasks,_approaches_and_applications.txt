Knowledge-Based Systems 89 (2015) 14–46

Contents lists available at ScienceDirect

Knowledge-Based Systems

j o u r n a l h o m e p a g e : w w w . e l s e v i e r . c o m / l o c a t e / k n o s y s

A survey on opinion mining and sentiment analysis: Tasks, approaches
and applications
Kumar Ravi a,b, Vadlamani Ravi a,⇑

a Center of Excellence in CRM and Analytics, Institute for Development and Research in Banking Technology, Castle Hills Road No. 1, Masab Tank, Hyderabad 500057, AP, India
b School of Computer & Information Sciences, University of Hyderabad, Hyderabad 500046, AP, India

a r t i c l e

i n f o

a b s t r a c t

Article history:
Received 28 January 2015
Received in revised form 13 May 2015
Accepted 23 June 2015
Available online 29 June 2015

Keywords:
Opinion mining
Sentiment analysis
Social media
Micro blog
Lexica creation
Machine learning
Ontology

1. Introduction

With the advent of Web 2.0, people became more eager to express and share their opinions on web
regarding day-to-day activities and global issues as well. Evolution of social media has also contributed
immensely to these activities, thereby providing us a transparent platform to share views across the
world. These electronic Word of Mouth (eWOM) statements expressed on the web are much prevalent
in business and service industry to enable customer to share his/her point of view. In the last one and
half decades, research communities, academia, public and service industries are working rigorously on
sentiment analysis, also known as, opinion mining, to extract and analyze public mood and views. In this
regard, this paper presents a rigorous survey on sentiment analysis, which portrays views presented by
over one hundred articles published in the last decade regarding necessary tasks, approaches, and appli-
cations of sentiment analysis. Several sub-tasks need to be performed for sentiment analysis which in
turn can be accomplished using various approaches and techniques. This survey covering published lit-
erature during 2002–2015, is organized on the basis of sub-tasks to be performed, machine learning and
natural language processing techniques used and applications of sentiment analysis. The paper also pre-
sents open issues and along with a summary table of a hundred and sixty-one articles.

Ó 2015 Elsevier B.V. All rights reserved.

surveillances,

Ever increasing use of

Internet and online activities (like
chatting, conferencing,
ticket booking, online
transactions, e-commerce, social media communications, blog-
ging and micro-blogging, clicks streams, etc.)
leads us to
extract, transform, load, and analyze very huge amount of struc-
tured and unstructured data, at a fast pace, referred to as Big
Data. Such data can be analyzed using a combination of Data
Mining, Web Mining and Text Mining techniques in various real
life applications. Huge amount of information related to cus-
tomer opinions/reviews is quite cumbersome to analyze and
needs extant approaches to get a generalized opinion summary.
Numerous forums, blogs, social networks, e-commerce web
sites, news reports and additional web resources serve as plat-
forms to express opinions, which can be utilized for under-
standing the opinions of the general public and consumers on
social events, political movements, company strategies, market-
ing campaigns, product preferences, and monitoring reputations

⇑ Corresponding author. Tel.: +91 40 23294042; fax: +91 40 23535157.

E-mail addresses: ankitaravi.ravi00@gmail.com (K. Ravi), rav_padma@yahoo.

com (V. Ravi).

http://dx.doi.org/10.1016/j.knosys.2015.06.015
0950-7051/Ó 2015 Elsevier B.V. All rights reserved.

[26]. To accomplish these tasks, research communities and aca-
demicians are working rigorously on sentiment analysis for last
one and half decade. Sentiment analysis (SA) is a computational
study of opinions, sentiments, emotions, and attitude expressed
in texts towards an entity [138]. Sentiment analysis (also called
opinion mining, review mining or appraisal extraction, attitude
analysis) is the task of detecting, extracting and classifying
opinions, sentiments and attitudes concerning different topics,
as expressed in textual
input [2,84]. SA helps in achieving
various goals like observing public mood regarding political
movement, market
the measurement of
customer satisfaction [158], movie sales prediction [131] and
many more.

intelligence [90],

expressing

source of

Sentiments, evaluations, and reviews are becoming very much
evident due to growing interest in e-commerce, which is also a
prominent
and analyzing opinions.
Nowadays, customers on e-commerce site mostly rely on reviews
posted by existing customers, and producers and service providers,
in turn, analyze customers’ opinions to improve the quality and
standards of their products and services. For example opinions
given on e-commerce sites like Amazon, IMDb, epinions.com, etc.
can inﬂuence the customers’ decision in buying products and sub-
scribing services [18].

K. Ravi, V. Ravi / Knowledge-Based Systems 89 (2015) 14–46

15

In developing countries, online and social media is taking the
place of ofﬂine media swiftly, which encourages common people
to involve in political discussions and enable them to put across
unilateral thoughts on Global issues interactively. Online media
provides the platform for wide sharing of ideas and encouraging
public for group discussions with open views. Online media pro-
vides better means to get quick response and feedback on different
Global issues and entities in the form of textual posts, news,
images, and videos. Thus, it can be utilized to analyze peoples’
opinions for learning the behaviors of consumer, patterns market,
and trends of society [206]. Twitter has 255 million monthly active
users and it oversees 500 million tweets every day.1 Thus, it serves
as a good resource to extract heterogeneous opinions published by
people from diverse societies for different purposes like improve-
ment of quality of products and services, prediction of consumers’
demand and taste, etc.

Online media and social networking sites (SNS) are used to
express and share public experiences in the form of product
reviews, blogs, and discussion forums. Collectively, these media
contain highly unstructured data combining text, images, anima-
tions and videos that are useful in making public aware of various
issues.

1.1. Earlier reviews

Pang and Lee [1] performed an extensive survey of more than
three hundred papers by covering applications, common chal-
lenges for sentiment analysis, major tasks of opinion mining viz.,
opinion extraction, sentiment classiﬁcation, polarity determina-
tion, and summarization. Then, Tang et al. [16] discussed four
problems related to opinion mining, i.e., subjectivity classiﬁcation,
word sentiment classiﬁcation, document sentiment classiﬁcation
and opinion extraction. For subjectivity classiﬁcation, they high-
lighted some approaches like similarity dependent, NB classiﬁer,
Multiple NB classiﬁer, and cut-based classiﬁer.

O’Leary [89] presented a survey on blog mining, which includes
introduction on blog search and mining, type of blogs to be ana-
lyzed, unit and type of opinions to be extracted from blogs, and
their applications. Montoyo et al. [84] listed some open issues
along with achievements obtained thus far in the area of subjectiv-
ity analysis and sentiment analysis. Tsytsarau and Palpanas [137]
presented a survey on SA by focusing on opinion mining, opinion
aggregation including spam detection and contradiction analysis.
They compared opinion mining methods, which were employed
on some common dataset.

Liu [181] presented different tasks possible and works pub-
lished in SA and opinion mining. Major tasks listed are subjectivity
and sentiment classiﬁcation, aspect-based SA, sentiment lexicon
generation, opinion summarization, analysis of comparative opin-
ions, opinion search and retrieval, opinion spam detection and
quality of reviews. Cambria et al. [15] pointed out complexities
involved in SA with respect to current demand along with possible
future research directions. Recently, Feldman [14] focused on ﬁve
speciﬁc problems
in the ﬁeld of SA: Document-level SA,
sentence-level SA, aspect-based SA, comparative SA and, sentiment
lexicon acquisition. They also listed some open issues like SA of
composition statement, automatic entity recognition, discussion
on multi-entity in same review, sarcasm detection and subjectivity
classiﬁcation at ﬁner level.

Most recently, Medhat et al. [138] presented a survey on feature
selection and sentiment classiﬁcation methods. A very brief
description is presented about feature selection methods (mainly
pointwise mutual information and Chi-square) and a detailed

1 https://about.twitter.com/company.

discussion is presented on sentiment classiﬁcation methods and
related papers. They summarized ﬁfty-four articles listing out task
accomplished, domain, algorithm utilized, polarity, data scope,
data source, and type of language. The authors’ major concern is
to discuss the techniques applied in surveyed papers.

Along with these surveyed papers, a considerable amount of
work has been reported in this area and a number of lexica have
been created by research community to evaluate new devised sen-
timent analysis algorithm. Especially in the last four years, major
concerns of researchers are micro-blogs, which have been success-
fully applied for market prediction [18], social advertising [43], and
box-ofﬁce prediction [51]. Tsytsarau and Palpanas [137] presented
very limited discussion on this major domain and its applications.
In addition to that, several other issues are reported in recently
published papers. Therefore, there is an urgent need to focus on
several other issues raised in currently published papers, which
were not the part of the extant surveys.

This survey work differs from existing literature surveys in var-
ious ways (i) we classiﬁed existing studies on the basis of opinion
mining tasks, approaches and applications as presented in Fig. 1,
(ii) this paper presents articles related to tasks and major issues
pointed out by existing articles like subjectivity classiﬁcation, sen-
timent classiﬁcation from coarse-grained to ﬁne-grained level,
review usefulness measurement, opinion spam detection, lexicon
creation, and opinion word and product aspect extraction as pre-
sented throughout the paper, (iii) we summarized each of surveyed
articles in four aspects viz. problem addressed, exploited dataset
details, feature representation and selection method (if applied),
techniques applied, obtained results, and indicated future direc-
tions along with our views, (iv) we included some recently pro-
posed feature selection techniques for SA, (v) we provided a
detailed list of online available datasets, (vi) classiﬁcation of arti-
cles on the basis of SA performed at various granular levels as pre-
sented in Table 1, (vii) the exploited lexica are listed in Table 10,
and (viii) summary of one hundred and sixty-one articles is pre-
sented in Table 10 before concluding the paper.

Therefore, works addressing these issues are considered for
this survey. This rest of the paper is organized as follows:
Section 2 presents background information related to the survey.
Section 3 presents state-of-the art discussion on SA covering com-
mon issues listed in previous paragraph. Detailed discussion on
the existing work, open issues, and possible applications of
sentiment analysis is presented in Section 4. The paper is
concluded in Section 5.

2. Preliminary steps of sentiment analysis

Sentiment analysis, opinion mining and subjectivity analysis
are interrelated areas of research which use various techniques
taken from Natural Language Processing (NLP),
Information
Retrieval (IR), structured and unstructured Data Mining (DM).
Major part of data available worldwide, being unstructured (such
as text, speech, audio, and video), poses important research chal-
lenges. To deal with such unstructured text data, traditional meth-
ods of NLP i.e. information retrieval and information extraction
came into existence [84]. In order to get a sense of the extracted
text, numerous research efforts have been witnessed in recent
years leading to automated SA, an extended NLP area of research
[23].

Sentiment analysis is not a single problem; instead it is a
multi-faceted problem [134]. Various steps are needed to perform
opinion mining from given texts, since texts for opinion mining is
coming from several resources in diverse format. Data acquisition
and data preprocessing are most common sub-tasks required for
text mining and SA, which are discussed in this section.

16

K. Ravi, V. Ravi / Knowledge-Based Systems 89 (2015) 14–46

Subjectivity 
Classification 

Sentiment 
Analysis 

Sentiment 

Classification 

Polarity 

Determination

Vagueness 
resolution in 

opinionated text 

Multi- & Cross-

Lingual SC 

Cross-domain SC

Review Usefulness 

Measurement 

Opinion Spam 

Detection 

Lexicon Creation 

Aspect Extraction 

TASKS

APPLICATIONS 

Fig. 1. Organization of the review.

Machine learning 

based 

Lexicon based 

Hybrid 

approaches 

Ontology based 

Non-Ontology 

based 

APPROACHES 

Table 1
Distribution of articles based on the granularity of sentiment analysis.

Level of analysis

#Articles

Articles’ references

Document level

Word level
Aspect level
Sentence level
Concept level
Phrase level
Link based
Clause level
Sense level

73

25
23
20
9
3
3
2
1

[13,18,22,32,33,36,40,43,45,48,50,51,53,54,61,64,66,77,81,80,85,88,90,91,94,96,101,111,117,121,123,130–132,148,155–158,
167–169,175–177,179,180,182,194,195,197,200,203,205–207,209–212,217,220–229,231,232]
[26,37,45,55,57,61,67,69,73,74,86,97,99,109,110,112,114,116,118,127,163,165,166,180,184]
[8,25,35,41,44,56,59,62,63,67,68,76,93,107,126,154,185,186,189,193,218,240,241,243]
[24,29,46,58,100,108,124,125,160,168,171,173,174,178,183,186,190,191,193,213]
[21,23,30,52,95,98,202,214,216]
[12,162,172]
[11,49,70]
[29,170]
[75]

2.1. Data acquisition

2.2. Preprocessing

to get

Facebook

Due to wide availability of various online resources, data
acquisition is highly subjective to the type of media, data format
supported by media, and the type of analysis needed to perform.
Some micro-blogging sites like Twitter, Sina-Wiebo, etc. made
available their Application Programming Interface (API) to collect
public data from their sites. Twitter has provided Twitter REST
API
static data like user proﬁle information, and
Streaming API2 to get streaming data like tweets [19]. Twitter4J
API3 has been exploited by [85,96] to extract streaming tweets.
Similarly,
available
Facebook Graph API4 and Tancent API5 respectively. These APIs
help us extract posts and other information from their site as well
and are exploited in [49,123,190,209]. Xu et al. [70] collected infor-
mation about 5012 members and 23,507 friendships from a pro-
duct review social network ‘‘UrCosme.com’’ and tried to measure
the social
inﬂuence of one user to other. Google Scholar and
Technorati is most commonly utilized blog search engine and have
been exploited in [48].

and Sina-Wiebo have made

2 https://dev.twitter.com/docs/api/1.1.
3 http://twitter4j.org/en/javadoc.html.
4 https://developers.facebook.com/docs/graph-api.
5 http://dev.datasift.com/docs/sources/public-sources/tencentweibo.

Raw data acquired from various sources often needs to be pre-
processed before launching a fully ﬂedged analysis. Some popular
preprocessing steps are: tokenization, stop word removal, stem-
ming, parts of speech (POS) tagging, and feature extraction and
representation. Tokenization is used to break a sentence into
words, phrases, symbols or other meaningful tokens by removing
punctuation marks. Stop words do not contribute to analysis and
hence are dropped during preprocessing step. Stemming is the pro-
cess to bring a word into its root form, while ignoring other POS of
the word. POS tagging is performed to recognize different parts of
speech in the text, which is quite essential for natural language
processing [150]. Some of the publicly available tools for different
preprocessing tasks are listed in Table 2. Due to sparseness and
extreme noise in textual data, it often requires extreme level of fea-
ture extraction, which is also one of the important preprocessing
steps [42]. Aside from feature extraction, feature selection is also
critical to the success of any analysis. A study of sentiment analy-
ses reported in [138] highlights different feature selection tech-
niques like Pointwise Mutual Information (PMI), chi-square, and
latent semantic indexing. In addition to these, some more statisti-
cal feature extraction methods, proposed in recent literature, are
summarized here.

Wang et al. [44] performed subjectivity classiﬁcation by consid-
ering improved Fisher’s discriminant ratio based feature selection

K. Ravi, V. Ravi / Knowledge-Based Systems 89 (2015) 14–46

17

Table 2
Available tools for text preprocessing.

Reference

[251]
[204,250]
[244]
[245]
[246]
[247]
[248]
[249]

Name of the tool

Purpose

TweetMotif
POS tagger
TweetNLPa
Lancaster stemming algorithm
GNU Aspell
Snowball
Stanford Log-linear Part-Of-Speech Tagger
TweeboParser

Tokenization of tweets
Twitter POS tagger
Twitter natural language processing
Stemmer
Spell checker
English stemmer
POS tagger
Tweet dependency parser

a Tweet NLP: http://www.ark.cs.cmu.edu/TweetNLP/.

Table 3
Distribution of articles based on tasks and applications.

S# Tasks and applications

1
2

Subjectivity classiﬁcation
Polarity determination

Vagueness in opinionated text

Cross-domain SA
Review usefulness measurement

3
4 Multi- & cross-lingual SA
5
6
7 Opinion spam detection
8
9 Opinion word and aspects extraction, entity

Lexica and corpora creation

recognition, name disambiguation
Applications of SA

10

Total

#Articles

References

[44,75,110,163,167,174]
[12,26,29,32,33,35,40,45,48,50,54,57,66,85,95,96,108,109,112,114,123,126,154,156,157,160,162,165,
166,168–172,176–180,203,205,206,209]
[22,41,86,216,217]
[46,88,94,115,148,173]
[36,98,99,121]
[76,78,81,130,221–229]
[199,200,212,216,220,231,232]
[21,23,24,30,52,55,56,69,74,97,106,111,116–118,127,136,202,207,211,213,214]
[8,11,25,27,35,37,59–63,67,68,92,93,100–102,107,125,132,175,182,185,186,189–191,
193–196,218,240,241,243]
[13,18,43,47,49,51,53,58,64,73,77,79,80,90,91,124,131,155,158,183,184]

6
43

5
6
4
13
7
22
36

21

163

method. Experiments were performed on two Chinese corpora,
multi-domain reviews; COAE2008s, and 11 different car brand
reviews; BOACAR. The proposed feature sets along with words
appearing in positive (+ve) and negative ( ve) texts were used
for training Support Vector Machine (SVM), which yielded senti-
ment classiﬁcation accuracy of 86.6%. Accuracy can be improved
by training the classiﬁer on richer dictionary. Then, Vinodhini
and Chandrasekaran [197] employed principal component analysis
for dimension reduction and ensembled hybrid techniques for sen-
timent classiﬁcation. They experimented with 500 (250 +ve & 250
 ve) reviews on digital camera. For feature representation, they
tried different combination of unigram, bi-gram and tri-gram rep-
resentation. SVM and Naive Bayes (NB) were compared against
bagged SVM and Bayesian boosting. Bayesian boosting outper-
formed all methods using hybrid (i.e. unigram + bigram) feature
representation by yielding the highest precision of 83.3%. In future,
more novels, diverse and powerful hybrids/ensembles of feature
reduction techniques can be employed.

Abbasi et al. [160] considered multi-lingual (viz. English and
Arabic) sentiment classiﬁcation of forums. Sentiment classiﬁcation
was performed on the basis of syntactic and stylistic features such
as word-length distributions, vocabulary richness measures,
character- and word-level lexical features, and special-character
frequencies. Features were extracted using newly proposed
Entropy Weighted Genetic Algorithm (EWGA). The ﬁrst experiment,
[33,167] achieved the
conducted on movie review dataset
highest accuracy of 87.95% with features
selected using
Stylistic + Syntactic techniques. The EWGA outperformed all other
feature engineering techniques by yielding an accuracy of 91.70%
using SVM. The second experiment was performed on 1000
English web forums messages on US extremist forums and 1000
Arabic web forums messages. EWGA improved the classiﬁcation
accuracy up to 92.84% on English dataset, and 93.84% on Arabic
dataset. In future, the proposed classiﬁcation approach is to be
applied on sentence- and phrase-level SA. Moreover, EWGA can
be employed for topic, genre, and style classiﬁcation.

Along with these notable feature selection based studies, we
surveyed others involving syntactic [92,130,171,174,178,190],
semantic [32,92,48,60,69,109,155,169,172,190],
stylistic [116–
118,127], and information gain [75,165] based methods.

3. Review methodology

considered as

As mentioned earlier, the current review is conducted in seven
broad dimensions viz. subjectivity classiﬁcation, sentiment classiﬁca-
tion, review usefulness measurement, lexicon creation, opinion word
and product aspect extraction, opinion spam detection, and various
applications of opinion mining as presented in Fig. 1. First ﬁve
dimensions represent tasks to be performed in the broad area of
SA. In turn, sentiment classiﬁcation is further divided into four cat-
egories: polarity determination, vagueness resolution in opinionated
text, multi-lingual and cross-lingual SA, and cross-domain sentiment
classiﬁcation. These sub-categories
sub-tasks.
Distribution of reviewed articles with respect to different tasks
and sub-tasks is presented in Table 3. Here, Sections 3.1–3.6 discuss
different tasks and sub-tasks along with applied approaches and
techniques. Applied approaches are broadly classiﬁed into three cat-
egories viz. machine learning, lexicon based, and hybrid approaches
for subjectivity classiﬁcation, sentiment classiﬁcation, review help-
fulness measurement, and opinion spam detection as presented in
Fig. 1. Further, ontology and non-ontology based approaches are con-
sidered for lexicon creation and aspect extraction. All attempted
approaches and techniques are discussed along with review of each
article. For detailed discussion on various techniques applied for
SA, an interested reader can refer Medhat et al. [138]. The last
Section 3.7 presents various existing applications of SA, whereas
possible future applications are discussed in the next section.

The important aspects considered for the reviews of each article
are problem addressed, exploited dataset details, feature representa-
tion and selection method (if applied), obtained results, and indicated
future directions by author and/or us. Most of the studies do not
have uniformly same experimental setup. Therefore, results of

18

K. Ravi, V. Ravi / Knowledge-Based Systems 89 (2015) 14–46

Table 4
Subjectivity classiﬁcation accuracy reported on common datasets.

S#

Dataset

Article

Accuracy achieved

Approaches

1
2
3

4

[167]

[33]

[160]
[167]
[174]

[92]

91.70
92
92.1

87.5

Hybrid
Machine learning
Lexicon based

Machine learning

different studies are not directly comparable. Still, we tried our
best to compare some related works wherever possible.

3.1. Subjectivity classiﬁcation

levels, and using several

Subjectivity classiﬁcation deals with the detection of ‘‘private
states’’ – a term that encloses sentiment, opinions, emotions, eval-
uations, beliefs and speculations [84]. Maks and Vossen [24]
claimed that subjectivity can be expressed in different ways, at
various text
types of expressions.
Subjectivity is the property associated with words and word sense.
Some more complex opinionated texts are news, political docu-
ments, and online debates, which requires identiﬁcation of the atti-
tude holder and topic also. Subjectivity analysis is deﬁned as the
recognition of opinion-oriented language in order to distinguish
it from objective language. Subjectivity and SA are challenging
tasks, spanning over many different areas and applications.
Although a considerable number of studies have been reported in
this ﬁeld in the past decade, much remains to be done in order
to create systems that can be reliably utilized in real-life applica-
tions. The problem of distinguishing subjective versus objective
instances has often proved to be more difﬁcult than subsequent
polarity classiﬁcation. Therefore,
improvements in subjectivity
classiﬁcation promise to positively impact on sentiment classiﬁca-
tion. It has been performed using machine learning [44,167] as
well as lexicon based approaches [75,110,163,174], whereas
Banea et al. [75] and Molina-González et al. [110] undertaken
cross-lingual approaches. Some of the subjectivity classiﬁcation
studies carried out on a common dataset provided by Pang and
Lee [167] are presented in Table 4 for comparison purpose.

Pang and Lee [167] utilized physical proximity between the
items to be classiﬁed, where cut-based classiﬁcation has been
applied for subjectivity classiﬁcation. Cut-based subjectivity detec-
tors determine the subjectivity status of all sentences of the docu-
ment using per-item and pair-wise relationship information. 5000
movie-reviews snippets from www.rottentomatoes.com, for sub-
jective sentences, and 5000 sentences from plot summaries avail-
able from www.imdb.com, for objective sentences, have been
considered in this study. NB and SVM yielded average 10-fold cross
validation (FCV) performance on the subjectivity dataset accuracy
of 92% and 90% respectively. Possible development claimed as
inclusion of parameter-selection techniques and incorporation of
other contextual cues besides sentence proximity. Xuan et al.
[174] achieved slighted better accuracy than that of Pang and Lee
[167]. They constructed in total twenty-two syntactic patterns
over adjectives, adverbs, verbs, and noun to determine the subjec-
tivity of the text. Maximum entropy was employed on the Pang
and Lee [167] dataset and achieved up to an accuracy of 92.1%,
which turned out to be better than selected three baseline meth-
ods. The proposed approach should be tested on other languages
also. Bravo-Marquez et al. [163] utilized the diverse features of
several lexica together for subjectivity and sentiment classiﬁcation
like polarity, strength and emotion. They experimented with Go
et al. [164] dataset, Sanders,6 and SemEval7 and improved accuracy

6 http://www.sananalytics.com/lab/twitter-sentiment/.
7 16 http://www.cs.york.ac.uk/semeval-2012/.

by 5% compared to individual classiﬁer. Due to streaming texts,
online algorithms should be experimented for real time subjectivity
and sentiment classiﬁcation.

Molina-González et al. [110] presented a new Spanish lexicon
(SOL – Spanish Opinion Lexicon) comprising opinion words for per-
forming opinion mining. They utilized the Bing Liu English Lexicon
[38] and automatically translated it into Spanish language to get
Spanish Opinion Lexicon (SOL). Sentiment classiﬁcation was per-
formed on 3878 movie reviews selected from MuchoCine Corpus
(MC) in Spanish language and achieved an accuracy of 63.16%. In
future work, random walk algorithm can be utilized for building
domain-oriented sentiment lexicons for Spanish language. Banea
et al. [75] performed sense level multilingual subjectivity classiﬁ-
cation for English and Romanian languages. They have started with
intersection of words from English WordNet [133] and Romanian
WordNet to get initial senses as seeds. Multilingual bootstrapping
was applied to explore a list of senses. The obtained list yielded
subjectivity classiﬁcation accuracy of 73.98% for both languages.
The quantitative study was also performed by applying informa-
tion gain based feature selection. In future, the proposed approach
can be applied in various other languages and a list of senses can be
explored further.

3.2. Sentiment classiﬁcation

Sentiment classiﬁcation is the determination of orientation of
sentiment of given text in two or more classes. Sentiment classiﬁ-
cation has been performed in various classes like binary, ternary,
n-ary in the form of stars [130], and ‘‘thumbs up’’ or ‘‘thumbs
down’’ [32,33], etc. Sentiment classiﬁcation can be performed
using machine learning as well as lexicon-based approaches as
reported in [138]. Machine learning yields maximum accuracy
while semantic orientation provides better generality. Machine
learning can be further divided into supervised and unsupervised
approaches. For supervised approaches, we need two sets of anno-
tated data, one each for training and testing. Some of the com-
monly applied classiﬁers for supervised learning were Decision
Tree (DT), SVM, Neural Network (NN), Naïve Bayes, and
Maximum Entropy (ME). Under lexicon based approaches, one
can use either dictionary or corpus based approach. Dictionary
based approach will use an existing dictionary, which is a collec-
tion of opinion words along with their positive (+ve) or negative
( ve) sentiment strength.
In turn, dictionaries were created
with/without using ontology. Corpus based approach relies on
the probability of occurrence of a sentiment word in conjunction
with positive or negative set of words by performing search on
very huge amount of texts like Google search, AltaVista search, etc.

3.2.1. Polarity determination

Sentiment classiﬁcation is concerned with determining polarity
of a sentence, whether a sentence is expressing positive, negative
or neutral sentiment towards the subject. Hence, Sentiment classi-
ﬁcation is also termed as polarity determination. Polarity determi-
nation has been performed for product reviews, forums, blogs,
news articles, and micro-blogs. Due to the word limit of 140 words,
micro-blogs do not contain full sentences. Moreover, micro-blogs
often contain abbreviations and noisy texts. Therefore, it needs
high level preprocessing as well as more intelligent techniques
for analysis. Micro-blogs has been proved useful for various appli-
cations [11,18,43,49,51,80,131]. Study carried out under polarity
determination can be grouped under machine learning based [26,
33,45,50,57,66,114,156,157,162,168], lexicon based [12,32,154,16
5,166,169–172,178], and hybrid based [29,48,54,95,108,109,112,1
80,209] approaches. Some of these studies exploited common
datasets, which are presented in Table 5 for global comparison.

K. Ravi, V. Ravi / Knowledge-Based Systems 89 (2015) 14–46

19

Table 5
Sentiment classiﬁcation accuracy reported on common datasets.

S#

1
2
3
4
5
6
7
8
9
10
11
12
13
14

15
16
17
18
19
20
21
22

23
24
25

28
29

Dataset

Articles

Obtained result

Pang and Lee [167]

Pang et al. [33]

Blitzer et al. [149]

[156]
[112]
[169]
[35]
[54]
[46]
[50]
[26]
[162]
[124]
[61]
[69]
[48]
[98]

[109]
[165]
[172]
[33]
[156]
[180]
[48]
[195]

[45]
[99]
[54]

[165]
[61]

92.70% accuracy
90.45% F1
90.2% accuracy
89.6% accuracy
87.70% accuracy
87.4% accuracy
86.5% accuracy
85.35% accuracy
81% F1
79% accuracy & 86% F1
76.6% accuracy
76.37% accuracy
75% precision
79% precision

Approx. 90% accuracy
88.5% accuracy
87% accuracy
82.9% accuracy
78.08% accuracy
75% accuracy
60% precision
86.04%

84.15% accuracy
80.9% (Avg.) accuracy
85.15% (Avg.) Max. 88.65%
accuracy on Kitchen reviews
88.7% accuracy
71.92% accuracy

the

resolution could improve

3.2.1.1. Machine learning based approaches. Pang and Lee [33] pio-
neered in applying machine learning viz. NB, Maximum Entropy
(ME), and SVM for binary sentiment classiﬁcation of movie
reviews. For experiments, they collected movie reviews from
IMDb.com. They experimented with various feature engineering,
where SVM yielded the highest accuracy of 82.9% with unigrams
features. They claimed that discourse analysis, focus detection,
and co-reference
accuracy.
McDonald et al. [168] presented a structured model for jointly clas-
sifying the sentiment at sentence and document level. They repre-
sented a document and its sentences in the form of cliques. They
assumed that labels of sentences and documents were interdepen-
dent. They applied Viterbi algorithm (a.k.a. linear-chain models)
for inference [103]. MIRA algorithm was employed for classiﬁca-
tion purpose [10,20]. For feature selection, unigram, bigram, and
trigrams conjoined with POS, and their back-offs have been consid-
ered. Experiments were performed on 600 online product reviews
from amazon.com in 3 different domains (a) car seats for children;
(b) ﬁtness equipment; (c) MP3 player. Accuracy reported as 62.6%
at sentence and 82.8% at document level using 10-FCV. The pro-
posed model can be modiﬁed for longer than 2 levels in similar
fashion for ﬁner level sentiment classiﬁcation.

Dang et al. [45] classiﬁed sentiments using SVM by using differ-
ent feature selection methods. Experiments were performed on
two corpora (a) 305 positive reviews and 307 negative reviews
on digital camera and (b) Blitzer et al. [149] multi-domain dataset.
SVM was trained on three collections of features set based on
domain free, domain dependent, and sentiment
features.
Information Gain (IG) was applied to reduce the number of fea-
tures for different combination of features. The reduced features
set performed better on multi-domain dataset than digital camera
dataset, and yielded an accuracy of 84.15% for kitchen appliance.
The proposed feature selection methods should be tested on bigger
dataset and compared with other statistical based feature selection
method. Saleh et al. [26] carried out twenty-seven sentiment clas-
siﬁcation experiments using SVM with various feature selection

methods. Experiments were performed on (a) Pang and Lee [167]
dataset, (b) Taboada and Grieve [65] multi-domain corpora, and
(c) SINAI corpus of digital cameras. Using 10-FCV, the best classiﬁ-
cation accuracy reported were 85.35%, 73.25%, and 91.51% for pang
corpus using binary occurrences and trigrams, Taboada corpus
using term frequency-inverse document frequency (TF-IDF) and
trigrams, and SINAI corpus using TFIDF and bigrams respectively.
Further experiments can be performed to observe the results
affected by rating reviews. Bai
[156] projected a Tabu
Search-Markov-Blanket Classiﬁer (TS-MBC). Here, MB learns con-
ditional dependencies among the words and encodes them into a
Markov Blanket-Directed Acyclic Graph of sentiment words. In
the next step, the author applied a Tabu search meta-heuristic
strategy to ﬁne-tune the MB-DAG to improve the accuracy. The
proposed Tabu search-enhanced Markov blanket model provides
a vocabulary in order to extract sentiments. Using Tabu search–
MB selects 35 relevant words out of 7716 words in the vocabulary.
TS-MBC yielded accuracy of 78.08%, 92.70%, and 73.21% for Pang
and Lee [33] dataset, Pang and Lee [167] dataset, and 600 online
news articles respectively. Validation is required on the larger data
set with more sentiment categories for more ﬁne-grained level SA.
Zhang et al. [114] classiﬁed sentiment using machine learning
(NB and SVM) for restaurant reviews written in Cantonese. They
studied the effects of feature representations and feature size on
the classiﬁcation performance. Experiments were performed on
1500 +ve and 1500  ve reviews. They experimented with different
feature representations like unigram, unigram_freq, bigram,
bigram_freq, trigram, and trigram_freq and varying number of fea-
tures in the range of 50–1600 features. The highest accuracy
reported was 95.67% using NB for 900–1100 features. Future work
can be integration of automatic review mining technologies to
search engines. Tan et al. [162] proposed an automatic approach in
deriving polarity pattern rules to detect sentiment polarity at the
phrase level. Class sequential rules were utilized to automatically
learn the typed dependency patterns. Experiments were performed
on Pang and Lee [167] dataset and achieved the highest up to 85.37%
average F-measure for adjectival modiﬁer over other feature selec-
tion methods. In future, more complex relationships between
phrases are to be considered. More in-depth analysis is required
on the possible phrase-level inﬂuences that would improve overall
sentiment polarity. Wang et al. [66] compared the performance of
three popular ensemble methods viz. bagging, boosting, and random
subspace based on ﬁve base learners namely NB, ME, DT, K-Nearest
Neighbor (KNN), and SVM for sentiment classiﬁcation. They experi-
mented with ten different datasets and reported better accuracy
over base learners at the cost of computational time. Ensemble
method can be further validated on large dataset, and feature con-
struction based on linguistic method can also be considered.
Moraes et al. [50] compared SVM and NB with ANN-based approach
for sentiment classiﬁcation. Experiments were performed on both
balanced and unbalanced dataset. Four datasets were chosen for this
purpose benchmark movies review dataset [167] and reviews on
three distinct product domains: GPS, Books, and Cameras. For unbal-
anced dataset, performances of both classiﬁers Artiﬁcial Neural
Network (ANN) and SVM were affected. Information gain as feature
selection method did not help yield good accuracy for more than
1000 features. Therefore, these classiﬁers should be tested on given
dataset using different feature selection methods.

Basari et al. [157] formed a hybrid method of Particle Swarm
Optimization (PSO) and SVM for sentiment classiﬁcation of movie
reviews. PSO was applied for the selection for the best parameters
in order to solve dual optimization problem. Experiments were
performed on EMOT8 dataset and they achieved an accuracy of

8 Available at: http://cs.stanford.edu/people/alecmgo/trainingandtestdata.zip.

20

K. Ravi, V. Ravi / Knowledge-Based Systems 89 (2015) 14–46

76.20% after data cleansing. In future, multi-class sentiment classiﬁ-
cation and more combinations of feature weighting and n-grams can
be tried to improve the classiﬁcation accuracy. Ghiassi et al. [57] uti-
lized supervised feature reduction using n-grams and statistical
analysis to create Twitter-speciﬁc lexicon for SA. They considered
six features viz. information loss, bias, noise, collision, difference in
scale, and overﬁtting. They collected tweets on then the largest
Twitter account Justin Bieber. Manual annotations were performed
for 3440 tweets in the scale of 5 values. The proposed system uti-
lized 755 of the most frequently occurring terms and emoticons
along with other features like contradictory terms inclusion, syn-
onyms,
feature boundary calculation using afﬁnity to include
bi-grams and trigrams, negation, etc. The Dynamic Artiﬁcial Neural
Network (DAN2) and SVM employed as multi-class classiﬁers.
DAN2 was designed as to contain multiple hidden layers with four
hidden nodes per layer. DAN2 outperformed SVM with an accuracy
of 71.3% for strongly positive, 66.7% for mildly positive, 89.9% for
mildly negative, and 95.1% for strongly negative. The proposed sys-
tem can be improved by adopting ontological approach at the cre-
ation of the lexicon.

(PMI-IR)

3.2.1.2. Lexicon based approaches. Turney [32] utilized a set of pat-
terns of tags for extracting two-word phrases from reviews. They
employed PMI-Information Retrieval
to determine
semantic orientation of review by issuing queries to a search
engine, where ‘‘excellent’’ and ‘‘poor’’ have been taken as boundary
for positive and negative reference words. Experiments have been
carried out on 410 reviews on different domains
from
Epinions.com. The highest accuracy of 84.0% was achieved on the
smallest dataset of 75 reviews on automobiles and the lowest
accuracy of 65.83% was achieved on movies reviews. Further
enhancement can be made by tagging of sentences on the basis
of whole or partial element of discussion. Nasukawa and Yi [171]
performed subject favorability determination by creating a senti-
ment lexicon of 3513 sentiment terms. They considered the syn-
tactic dependencies among the phrases and subject
term
modiﬁers.
a
multi-domain corpus of 175 cases of subject terms within the con-
texts, (b) 2000 cases related camera reviews. The proposed system
has been evaluated on 552,586 web pages and 230,079 news arti-
cles to extract sentiments on an organization by deﬁning 13 sub-
ject terms, which yielded precision of 86% and 88% respectively.
Sentiment extraction about ten products performed on 476,126
web pages in pharmaceutical domain, and achieved a precision
of 91%. The discourse processing, anaphora resolution and indirect
expressions are required to be considered to improve the
efﬁciency.

Experiments have been conducted on (a)

Mullen and Collier [172] proposed a hybrid model comprising
PMI-IR approach [32], Osgoodian semantic differentiation with
WordNet [9], and topic proximity and syntactic-relation features
[171]. Osgoodian semantic gave the potency (strong and weak),
activity (active and passive), and the evaluative factor (good or
bad) for all adjectives. They experimented with the dataset pre-
sented in [33], and 100 reviews on media. The hybrid SVM with
PMI/Osgood and lemmas feature selection yielded the highest
accuracy of 87% using 10-FCV. Incorporation of domain context
to AltaVista search results and dependency relation based feature
selection can improve
classiﬁcation.
Whitelaw et al. [169] semi-automatically created a lexicon of
1329 adjectives and modiﬁers. A detailed semantic analysis of atti-
tude expression was performed by considering appraisal groups.
They emphasized the importance of the appraiser (speaker), atti-
tude, target (the appraised), and the orientation. The adjectival
appraisal group has been labeled with four features: attitude, ori-
entation, graduation, and polarity. SVM with BOW+G:AO feature
selection, out of various feature selection methods, yielded

the performance of

accuracy of 90.2% on Pang and Lee [167] dataset for 10-FCV.
Further attempts can be made for accurate identiﬁcation of apprai-
sal expression including opinion actor (appraiser) and opinion tar-
get (appraised).

Wilson et al. [12] identiﬁed contextual polarity using machine
learning and various sentiment expression based features. They
claimed that the prior polarity of the phrase changes with respect
to context of discussion. They exploited Multi-Perspective
Question Answering (MPQA)9 opinion corpus to add contextual
polarity judgments to sentiment expressions. Experiments per-
formed on a lexicon of over 8000 subjectivity clues, where 92.8%
of
them were marked as either positive (33.1%) or negative
(59.7%). Twenty-eight features were proposed in different categories
for neutral-subjectivity classiﬁcation, which yielded an accuracy of
75.9%. Ten features were proposed in two categories for polarity
classiﬁcation, which yielded an accuracy of 65.7%. Kanayama and
Nasukawa [170] utilized two types of contextual coherency like
intra-sentential and inter-sentential context in terms of polarity.
They extracted lexical entries from the noisy clues. The proposed
method was divided into 3 steps (a) sentence delimitation, (b)
proposition detection at ‘Clause-level’, and (c) 3-ary polarity assign-
ment. They considered verb, adjective, argument coincidence with
the proposition, and negation. English sentiment lexicon [7] was
used to extract various polar atoms. Experiments were performed
on digital cameras, movies, mobile phones, and car dataset contain-
ing 1757917, 637054, 609072, 959831 sentences respectively.
Evaluation was performed on four domain corpora by manually
selecting 100 random polar atoms per domain, which yielded a pre-
cision of 90% for all four domains.

Benamara et al.

[178] composed three Adverb-Adjective
Combinations (AAC) scoring methods viz. variable scoring for adjec-
tive, adjective priority scoring for adjective with relevance to
adverb, and adverb ﬁrst scoring for adverb with relevance to adjec-
tive. AAC was mainly based on the intensity of adverb of degree at
ﬁve linguistic level and assigned score between 0 and 1. For the
experiment, annotations have been performed by 10 annotators
to 200 BBC news articles. The correlation between the proposed
algorithms performance and human subjects was reported.
Human subjects correlation yielded r = 0.35 for Pearson’s coefﬁ-
cient. Adjective priority scoring was reported as the best algorithm,
which implies that adjective was more important than adverb.
More adverb scoring axioms and syntactic constructions can be
explored like adverb of time or frequency, adverb and verb combi-
nation, etc. Lu et al. [166] calculated sentiment polarity strength of
a review by multiplying the strength of used adjectives and
adverbs. The strength of an adjective was calculated using progres-
sive relation rules of adjectives and link analysis (propagation algo-
rithm). A total of 3497 adjective and 100 adverb words from
Chinese lexicon were considered to represent progressive relation
rules. The strength of the selected adverbs was calculated, which
ranges from +1 to  1. Sentiment classiﬁcation was performed on
2000 positive and 2000 negative hotel reviews in Chinese and
yielded up to a precision of 71.65%. More experiments are required
to ensure the effectiveness the proposed method.

Eirinaki et al. [154] developed a two-step based feature-level
opinion mining and ranking algorithm which was deployed in a
search engine AskUs [159]. In the ﬁrst step, High Adjective Count
algorithm identiﬁes mostly discussed nouns in the reviews and
respective opinion score. The opinion score of each noun was the
number of adjectives used along with a noun. In the second step,
Max Opinion Score algorithm determined opinion score of each
opinion word along with negation by assigning a value in the range
of [ 4,+4]. And,
it also determines score of each feature by

9 http://nrrc.mitre.org/NRRC/publications.htm.

K. Ravi, V. Ravi / Knowledge-Based Systems 89 (2015) 14–46

21

summing up opinion scores of utilized opinion words with a fea-
ture. The highest scored feature was ranked as the highest and so
on. Experiments were performed on Hu and Liu [38] dataset and
accuracy achieved on vacuum dataset was the best at 97% and
the worst on DVD Player was 87%. The proposed method should
be compared with some standard lexicon based sentiment calcula-
tion approach. Deng et al. [165] devised a supervised term weight-
ing scheme based on importance of a term in a document (ITD) and
importance of a term for expressing sentiment (ITS) with the help of 7
statistical feature selection methods viz. document frequency (DF),
information gain (IG), mutual information (MI), odds ratio (OR),
chi-square statistic (CHI), Weighted Log Likelihood Ratio (WLLR)
and Weighed Frequency and Odds (WFO). They experimented with
proposed weighting schemes using SVM on Pang et al. [33] dataset,
multi-domain dataset,10 and Maas et al. [39] dataset and achieved
accuracy of 88.5%, 88.7%, and 88.0%, respectively. Further accuracy
can be improved by combining proposed method with more unsu-
pervised approaches.

Agarwal et al. [177] performed sentiment classiﬁcation of
tweets. They experimented with 11,875 manually annotated
tweets. They employed ﬁve different combinations of features over
unigram, senti-features, and tree kernel. SVM was used for 2-way
and 3-way classiﬁcation tasks. For 2-way classiﬁcation tasks, uni-
gram + senti-features outperformed all other feature representa-
tion with an accuracy of 75.39%. For 3-way classiﬁcation tasks,
tree kernel + senti-features outperformed all other feature repre-
sentation with an accuracy of 60.83%. In future, richer linguistic
analysis can be tried. Taddy [40] came up with an algorithm for
maximizing sampling efﬁciency, which was required in selection
of a sub-sample of representative posts for sentiment scoring. He
predicted both generic and subject-speciﬁc document sentiment
through the use of variable interactions in multinomial inverse
regression. For the experiments, tweets on different USA politicians
have been collected during January 27 to February 28, 2012. They
classiﬁed collected tweets into positive, negative and neutral cate-
gory for each politician. Proposed approach can be tried on long
text also. Khan et al.
[85] applied 3 methods in tandem:
Enhanced Emoticon Classiﬁer (EEC), Improved Polarity Classiﬁer
(IPC), and SentiWordNet based classiﬁer (SWNC) to classify tweets.
For the classiﬁcation, at ﬁrst EEC was applied using a total of 145
emoticons (70 positive and 75 negative). Neutral tweets yielded
by previous step were given as input to IPC, which uses Opinion
Lexicon [38] and Bill McDonald dictionaries. Neutral tweets classi-
ﬁed by IPC were further classiﬁed using SentiWordNet dictionary.
For the experiment, 2116 tweets have been collected on six per-
sonalities to create 6 datasets viz. Imran khan, Nawaz Sharif,
Dhoni, Tom Crouise, Pakistan, and America. Proposed method
achieved average accuracy of 85.7% over all datasets. In future, val-
idation can be performed based on supervised learning algorithms.
Mostafa [126] analyzed consumers’ sentiments towards major
worldwide brands such as IBM, Nokia, and DHL using qualitative
and quantitative methodology. He addressed issues like detection
of hidden patterns in consumers’ sentiments towards Global
brands. And, he also assessed the importance of blogosphere for
companies to redesign their marketing and advertising campaigns.
Relative frequency word counts were generated to get insights and
predict characteristics of a particular topic. The proximity graph
plotted
brands.
Multidimensional scaling (MDS) technique was employed to draw
3-D concept map, which shows the tendency of co-occurrence of
phrases or words. 3516 tweets for sixteen brands from July 18,
2012, to August 17, 2012 have been collected for analysis purpose.
To determine the polarity of tweets, the dictionary proposed by Hu

frequency

different

the

of

tweets

for

and Liu [38] has been utilized. The qualitative part was carried out
using QDA Miner 4.0 software package. For future work, the most
representative topics discussed behind each sentiment is required.
Moreover, extra effort is required to identify vendor’s interest
towards products and services.

Kontopoulos et al. [96] analyzed sentiment of tweets using
ontological engineering. After preprocessing of 667 tweets on
mobile, they created domain ontology of tweets using a proposed
algorithm. They employed a web service Opendover11 in order to
tag the opinions and get intensity of the sentiment expression.
Evaluations were performed on two versions of the proposed archi-
tecture (a) the full-ﬂedged ontology-based semantically-enabled
system (SEM), and (b) the same system without synonym/hyponym
augmentation. The former has yielded better recall and the degree of
synchronization. In future, Opendover can be replaced by some
advanced algorithmic approach for sentiment determination of each
tweet. Bell et al. [203] exploited twitter as a platform to instruct an
educational tool called Finch Robot to take a picture and reading
temperature, where both instructions could be given in any order.
Tweets were preprocessed and POS tagged using tweet tagger
[204]. They devised 15 rules on the basis of POS to extract different
events, which were veriﬁed using ConceptNet. Evaluation of the
developed system was carried out by a total of 11 participants.
And authors reported efﬁciency, effectiveness, and satisfaction on
the basis of users’ experiences. In future, the proposed architecture
can be modiﬁed in order to carry out some other works like vacuum
cleaning robot, etc. And additional information like spatial, temporal,
physical, social, and psychological information can be exploited for
better operations.

Popescu and Strapparava [206] studied diachronic phenomena
of two different domains namely socio-political and sports on
Google N-grams corpora. Analysis was performed 761 and 34
words from Socio-political domain and sport respectively. Epoch
delimitation was performed on the basis of word distribution over
certain periods of time. They also analyzed the opinion change
phenomenon using the covariance between the frequencies of
two or more terms over a certain period of time. Eight types of
emotions were decided for 14,000 words using WNA based NRC
Word-Emotion Association Lexicon (WNANRC) and Semeval 2007
Affective Text (SAT). The proposed methodology can be extended
to predict future changes in society like the covariance between
socialism and capitalism, etc.

3.2.1.3. Hybrid approaches. Sindhwani and Melville [180] devel-
oped an unsupervised and a semi-supervised sentiment classiﬁca-
tion algorithm. For unsupervised method, they utilized a lexicon
containing human-labeled 2968 words to achieve domain adapt-
ability. For semi-supervised lexical classiﬁcation, they utilized
bipartite representation of the data i.e. document-word bipartite
and regularization operator graph. Due to sparseness of data, they
used Regularized Least Squares (RLS) classiﬁcation algorithm. They
incorporated prior knowledge of sentiment-laden terms directly
into the model using Lexical-RLS. Generality of the approach have
been justiﬁed by experimenting on three, very different, domains
(a) Pang et al. [33], (b) lotus blogs, and (c) political blogs using
10-FCV. They compared the lexical RLS and semi-supervised lexical
RLS with three baseline methods and performed well. More feature
extraction methods along with non-linear kernel based classiﬁer
can be tested to improve the performance. Narayanan et al. [29]
performed linguistic analysis of conditional sentences and senti-
ment classiﬁcation using supervised learning. Different linguistic
features viz. opinion words, POS tags of sentiment words, words
without opinion, tense patterns, special characters, conditional

10 http://www.cs.jhu.edu/mdredze/datasets/sentiment/.

11 OpenDover sentiment tagging web service: http://opendover.nl/.

22

K. Ravi, V. Ravi / Knowledge-Based Systems 89 (2015) 14–46

connectives, length of condition and consequent clauses, and nega-
tion words were exploited to determine the orientation of a sen-
tence. SVM with Gaussian kernel yielded F-score 75.6% by
training on manually annotated 1378 sentences taken from forums
on cellphone, automobile, LCD TV, audio systems, and medicine.
More rigorous experiments should be performed to ensure the efﬁ-
ciency of the proposed system.

Prabowo and Thelwall [112] developed different hybrid classi-
ﬁers over ﬁve classiﬁers viz. (a) General Inquirer based classiﬁer
(GIBC) [105], (b) rule based classiﬁer (RBC), (c) statistics based clas-
siﬁer (SBC), (d) induction rule-based classiﬁer (IRBC) (like ID3 and
Ripper), and (e) SVM. Experiments were performed on Pang and
Lee [167],12 Movie Review-2 (100 +ve and 100  ve reviews from
reviews (180 +ve and 180  ve),
previous dataset), product
MySpace comments (110 +ve and 110  ve). They reported the high-
est micro averaged F1 90.45% by applying RBC, SBC, GIBC, SVM in
tandem on MySpace comments. In future, the performance of the
proposed hybrid classiﬁer should be tried on bigger and complex
data set. Abbasi et al. [109] framed a feature relation network
(FRN), which was rule-based, multi-variate, n-gram feature selection
technique. It incorporates semantic information derived from exist-
ing lexical resources, enabling augmented ranking of n-gram fea-
tures. Sentiment classiﬁcation has been performed on 2000
reviews on digital cameras from epinions.com, 2000 reviews on
automobiles from edmunds.com, and Pang et al. [33] dataset. FRN
outperformed
chi-square, word
n-grams/LL, and bag of words/LL for all three test beds with consid-
erably better accuracy on virtually all feature subset sizes. A lot of
scope is there for future improvement like augmenting FRN with
occurrence frequency and positional/distributional
feature, and
incorporating FRN in conjunction with other multivariate selection
techniques.

log-likelihood

ratio

(LL),

Xia et al. [54] ensembled feature sets and machine learning for
sentiment classiﬁcation. Two types of feature sets namely ‘‘POS
based features’’ and ‘‘the world-relation based feature sets’’ have
been designed. These feature selection methods were ensembled
with NB, ME, and SVM using 3 techniques viz. ﬁxed combination,
weighted combination and meta-classiﬁer combination. Word
relation based weighted classiﬁer yielded accuracy of 87.7% and
average 85.15% on Pang and Lee [167] and Blitzer et al. [149] data-
set respectively. Feature selection based on syntactic relations can
improve accuracy. Chen et al. [48] classiﬁed sentiment of blogs on
products. Classiﬁcation was performed using hybrid of semantic
orientation and back-propagation neural network. They proposed
4 different types of semantic orientation (SO) indexes as the input
neurons viz. SO-PMI (AND), SO-PMI (NEAR), semantic association,
and latent semantic analysis. Experiments were performed on
Blogs (Data size: 353, +ve: 157,  ve: 186), MP3 (Data size: 579
+ve: 235,  ve: 344), EC (Data size: 386  ve: 249  ve: 137),
Movie-001, and Movie-002 (Data size: +ve: 500,  ve: 500) and
yielded 87.5%, 73.5%, 81.2%, 75%, and 67.8% recall respectively.
The proposed approach should be tested on different corpora like
Twitter, Plurk, Facebook, etc. employing different machine learning
techniques.

Balahur et al. [95] extended her own proposed method to detect
emotion using commonsense knowledge. For the experiment, 1081
examples from ISEAR have been selected for the test set A, and 895
examples were selected out of 1081 for test set B. She applied dif-
ferent
Sequential Minimal
Optimization-SVM technique and linguistic features. The proposed
EmotiNet based technique outperformed some other supervised
and lexical-knowledge based techniques. Future work was claimed
as to extend of EmotiNet, test new methods to assign affective

combination

supervised

of

value to the concepts, and expand EmotiNet to other language
and domain as well. Abdul-Mageed et al. [108] performed subjec-
tivity and sentiment analysis (SSA) of social media for a
morphologically-rich language. Experiments were performed on
2798 chat turns, 3015 Arabic tweets, 3008 sentences from 30 mod-
ern standard Arabic Wikipedia Talk pages, and 3097 web forum
sentences. For the subjectivity analysis, each of the sentences of
collected data sets was labeled manually for the subjectivity and
objectivity. 3982 Arabic adjectives were collected for binary polar-
ity classiﬁcation of the sentences. SVM outperformed baseline
methods for subjectivity classiﬁcation, and yielded an accuracy of
73% for tweets and 84.36% for forums. SVM outperformed baseline
method for sentiment classiﬁcation with an accuracy of 70.30% for
chat turns. Error analysis and irony detection can play signiﬁcant
role in the improvement of accuracy.

Ortigosa et al. [209] performed sentiment classiﬁcation and
sentiment change detection on Facebook comments using lexicon
and machine learning based approach. They developed a sentiment
lexicon on the basis of Spanish Linguistic Inquiry and Word Count
(LIWC) and slang found in the comments. In order to evaluate the
proposed lexicon, they employed C4.5, NB, and SVM to classify
3000 status messages (1000 for each class: positive, negative and
neutral) and yielded an accuracy of 83.17%, 83.13%, and 83.27%
respectively. Future improvement would be to calculate contextual
sentiment score.

Jiang et al. [176] proposed a target-dependent and contextual
based approach to perform sentiment classiﬁcation of tweets.
Subjectivity and sentiment classiﬁcation was performed using
SVM. The graph-based optimization was applied on related tweets
to boost the performance. PMI was used to identify top-k nouns
and noun phrases associated with the target. For the experiment,
they collected 400 English tweets on each of the query like
Obama, Google, iPad, Lakers, Lady Gaga and achieved accuracy up
to 68.2% for subjectivity classiﬁcation and up to 85.6% for senti-
ment classiﬁcation. In future, Twitter’s user proﬁle based senti-
ment classiﬁcation can be undertaken. Kouloumpis et al. [179]
classiﬁed sentiment expressed in tweets. They used a list of fea-
tures viz. 1000 n-gram, MPQA subjectivity lexicon, POS,
micro-blogging
features.
Adaboost.MH was trained on HASH dataset containing 222,570
tweets, and EMOT dataset containing 381,381 tweets and emoti-
cons. Testing was performed on 4015 tweets from HASH + EMOT
dataset. The micro-blogging feature, n-grams+lex+twit, was
reported as the best feature combination and yielded average accu-
racy of 75.0% on test dataset.

abbreviations

emoticons,

and

Li and Xu [123] enacted a novel method to classify emotions
using the emotions cause extraction technique. The emotion cause
extraction helped in removal of unnecessary features. Further
chi-square method was employed to remove irrelevant features.
A list of 1845 emotion words and short phrases has been collected
to identify emotion words from tweets. To test the proposed lexi-
con, 16,485 posts from Sina-Wiebo have been collected. Support
vector regression (SVR) with linear kernel was utilized for
multi-class classiﬁcation and yielded a precision of 75.70%. The
obtained precision can be improved by considering more linguistic
patterns, elements and factors. Automatic generation and modiﬁ-
cation of the pattern set will reduce the manual effort. Rill et al.
[205] proposed early detection of twitter trend, which was faster
than Google Trends. They considered temporal changes in the
number of tweets to decide the emerging topic. Polarity of tweets
were decided using sentiment lexica like SenticNet3,13 SWN, etc.,
where polarity of novel words were determined by plotting a rela-
tional graph of emerging political tweets at different time periods.

12 Available at: http://www.cs.cornell.edu/people/pabo/movie-review-data/.

13 http://sentic.net/senticnet-3.0.zip.

K. Ravi, V. Ravi / Knowledge-Based Systems 89 (2015) 14–46

23

They collected 4,000,000 tweets during Germany parliamentary
election on nine political parties to test the proposed system. In
future emerging patterns of controversial topics can be explored.

3.2.2. Vagueness resolution in opinionated text

Ambiguity and vagueness have been considered as major issues
since user reviews are often written using a loose style than stan-
dard texts, and often express sarcasm (mock or convey or irony),
rhetoric or metaphor. Political discussion and extreme often
include irony and sarcastic words; detection of such expression
is a challenging task in opinion mining area. The fuzzy approach
is quite useful to represent such feelings and expressions. In this
regard, some initiatives taken in sentiment analysis area are sum-
marized in this section.

Li and Tsai [41] framed a classiﬁcation framework on the basis
of fuzzy formal concept analysis (FFCA). For feature representation
and dimensionality reduction, TF-IDF,
Inverted Conformity
Frequency (ICF) and Uniformity (Uni), and the relation between
documents and terms have been considered using context matri-
ces. The attribute lattice set was represented using terms of the
document. The TF-IDF value represented the degree of signiﬁcance
of each term in the lattice object set, which were given to the clas-
siﬁer. Experiments were performed on (a) Reuters-21578 contain-
ing 21,578 economic news stories, (b) Pang and Lee [167] dataset,
(c) Kindle eBook reviews (1000 +ve and 1000  ve). Fuzzy Formal
Concept analysis Model (FFCM) outperformed J48, KNN, SVM and
BN, and reported a precision of 96.20%, 88.75%, 95.09% on the three
datasets respectively. Topics such as Multi-class classiﬁcation,
novel similarity measures, and computational complexity of
FFCM are the future research directions.

Reyes and Rosso [86] composed six notable features to deal
with verbal irony. Those features were n-grams, POS n-grams,
funny proﬁling, +ve/ ve proﬁling, affective proﬁling, and pleasant
proﬁling. Among these features, ﬁrst and second were common for
preprocessing purpose. The third feature gives humorous property
of the sentence. The fourth one deals with SA and utilized the
Macquarie Semantic Orientation Lexicon (MSOL) [139]. Fifth fea-
ture uses WordNet-Affect (WNA) to categorize affective content
into 11 different classes. And, ﬁnal one assigns a score of pleasant-
ness to approximately 9000 English words. For the experiments,
3163 ironic reviews on ﬁve products from Amazon.com and three
negative sets containing 3000 document each from Amazon.com
(AMA), Slashdot.com (SLA), and TripAdvisor.com (TRI) have been
collected. For the classiﬁcation NB, SVM, and DT were trained on
5861 instances (2861 +ve and 3000  ve) using 10-FCV. SVM clas-
siﬁed AMA with best performance 75.75%, NB classiﬁed SLA with
best performance 75.19%, and DT classiﬁed TRI with best perfor-
mance 89.05%. In future, more rigorous validation of result is
required. Bosco et al. [22] developed a corpus, Senti-TUT, of irony
words used in political discussion in Italy. The proposed corpora
exploited two twitter corpora TWNews
(3288 posts) and
TWSpino (1159 posts) of Italian political discussions during 6
October 2001 to 3 February 2012 for Mario Monti nominations.
Each tweet was annotated one of the following sentiment tags:
positive, negative, humor, mixed (positive and negative both),
none (objective). Five annotators employed to annotate tweets
and inter-annotator agreement was determined by Cohen’s
K score = 0.65. To apply polarity reverser, 723 ironic tweets from
TWNews have been classiﬁed by human annotator and
Blogmeter classiﬁer (BC).14 BC is a rule-based approach which relies
on a sentiment lexicon and sentiment grammar expressed by com-
positional rules. To determine emotion level of tweets, BC was
employed to annotate ironic tweets into six different categories.

Future work is required to consider a formal account and a measure
of these phenomena, and a ﬁner granularity of text analysis.

Justo et al. [217] proposed to classify sarcasm and nastiness
available in dialogic language on the web. They integrated statistic,
linguistic, semantic and emotional features to train a RBC and NB
classiﬁer. Statistic features were dictated by n-grams. The linguis-
tic features involved word and character counts, etc. Semantic and
emotional features were obtained by SenticNet 3.0. Chi-square fea-
ture selection was employed to select most prominent features.
Experiments were carried out on two subsets of the IAC15 sarcasm
data set consisting of 6461 instances and nastiness data set consist-
ing of 2765 instances balanced between nasty and not nasty posts
and achieved an F-measure of 70.7% and 79.7% respectively. The pro-
posed approach can be enhanced in order to achieve better
F-measure. Weichselbraun et al. [216] proposed context based polar-
ity ambiguity removal. They employed ConceptNet based vector
space similarity, and WordNet based graph-based similarity to
determine the polarity of a concept. They evaluated the proposed
system on 2000 reviews on each of Amazon electronics, Amazon
software, IMDb comedy, IMDb crime, and IMDb drama, which out-
performed baseline methods. The proposed system could be evalu-
ated on larger dataset and can be developed at sentence level.

3.2.3. Multi-lingual and cross-lingual sentiment analysis

Different languages across the world have different degree of
expressive power regarding sentiments. An important body of
research has tried to address this issue at some extent. Although,
higher accuracy is not achieved in this regard, unexplored corners
of several approaches can positively inﬂuence the accuracy.
Cross-lingual sentiment analysis can be performed using two dif-
ferent
a
target-language subjectivity classiﬁer is generated by translating
an existing lexicon into another idiom; (b) Corpus-based approach,
where a subjectivity-annotated corpus for the target language is
built through projection, training a statistical classiﬁer on the
resulting corpus [82]. For multi-lingual and cross-lingual senti-
ment analysis, following study is divided into two categories:
machine learning [46,88,115] and hybrid approach [94,148,173].

Lexicon-based approach, where

approaches:

(a)

Hiroshi et al. [173] developed Japanese Sentiment Analysis sys-
tem (JSA) to extract sentiment units from Japanese corpus. JSA sys-
tem performs Japanese to English translation using transfer-based
machine translation engine containing 3 parts: (a) a source lan-
guage syntactic parser, (b) a bilingual transfer which handles syn-
tactic tree structures [161], and (c) a target language generator.
They also employed full syntactic parser and top-down pattern
matching. Opinion word sense disambiguation in machine transla-
tion and aggregation was performed to extract frequently men-
tioned opinions. Experiments were conducted on 200 digital
camera review sentences to extract sentiment units. Weak and
strong precision were claimed as 100% and 89% respectively by
the proposed system. The proposed system outperformed lexicon
only system for sentiment unit extraction and measurement for
the appropriateness of the sentiment scope. Some other machine
translation, such as word sense disambiguation, anaphora resolu-
tion, and automatic pattern extraction can improve the efﬁciency
of the system. Boiy and Moens [46] performed multilingual and
multiple domain sentiment classiﬁcation. They utilized different
feature representations like unigrams, negation, discourse features,
compound words and verbs, etc. They utilized cascaded approach
with 3 single classiﬁers viz. MNB, ME, SVM for experiments using
various combination. They reported the best results using MNB
for English, SVM (linear kernel) for Dutch, and ME for French. For
experiments, they collected 750 positive sentences and 750

14 www.blogmeter.eu.

15 https://nlds.soe.ucsc.edu/iac.

24

K. Ravi, V. Ravi / Knowledge-Based Systems 89 (2015) 14–46

negative sentences for each language; evaluation was performed
on Pang and Lee [167] dataset and reported up to accuracy of
87.40%. Irony and sarcasm detection will be the major issue for
cross-lingual sentiment classiﬁcation.

Demirtas [148] performed cross-lingual SA over English and
Turkish language by applying machine translation techniques from
Turkish to English using Google Translator API. Experiments were
performed on Pang and Lee [198], Blitzer et al. [149], Turkish
movie reviews and Turkish multi-domain product reviews [148].
NB, ME and SMO-SVM were used for classiﬁcation purpose. ME
yielded the best performance for Blitzer et al. [149] dataset.
Martin-Valdivia et al. [94] carried out Spanish sentiment classiﬁca-
tion using a hybrid meta-classiﬁer. Spanish MuchoCine (MC)16 cor-
pus was automatically translated into MuchoCine English (MCE)
corpus. MC contains 3878 movie reviews collected from the
MuchoCine website. For supervised learning, SVM and NB were uti-
lized for both corpora. As an unsupervised approach, SentiWordNet
was used for classiﬁcation of MCE corpus. Finally, both approaches
were combined to get meta-classiﬁer. TF-IDF, Term Frequency (TF),
Term Occurrence (TO), and Binary Occurrence (BO) were considered
as feature representation schemes. SVM outperformed NB for both
corpora. TF-IDF was reported as better representation scheme.
SVM using TF-IDF without stopper and stemmer yielded the best
precision 0.8773 and 0.8776 on MC and MCE respectively. Stacking
ensembling yielded a precision of 88.58%. In future, sentiment clas-
siﬁcation of MCE can be performed using other emotion rich dic-
tionaries like WordNet-Affect, SenticNet, etc.

Seki et al. [88] presented multilingual opinion holder identiﬁca-
tion using author and authority viewpoints. They employed three
annotators to annotate opinionated sentences and opinion holder
with three opinion types. They experimented with four sample
topics of NTCIR-6 Opinion Corpus for Japanese data and MPQA
for English data. Classiﬁcation was performed using SVM for
Japanese corpus, and SVM, Conditional Random Field (CRF), and
Logistic Regression (LR) for English corpora. For Japanese corpora,
SVM yielded 60.9% recall after performing named entity extraction.
The proposed method can be applied for opinion holder identiﬁca-
tion from multilingual blogs. Wang et al. [115] classiﬁed sentence
level subjectivity at the ﬁrst step. At the next step, sentiment score
was calculated using three techniques viz. equal weights, correlation
degree, and sentiment conditional probability. Finally, sentence level
sentiment aggregation was performed over sentences using
weighted average. Experiments were performed in four aspects
viz. sentiment classiﬁcation at sentence level, determining the
importance of a sentence to a document, sentiment classiﬁcation
of a document, and comparative experiment of document-level
sentiment classiﬁcation. Information Gain (IG) was applied to
select initial 300 text features. SVM was utilized for sentence level
classiﬁer. Selected dataset were 4000 Chinese reviews on hotel,
4000 Chinese and 4000 English reviews on cell phone. The accu-
racy of sentiment classiﬁcation at document level declines from
English to Chinese online reviews and from cell phone to hotel
reviews. Removal of manual treatment of negation, and strength-
ening and weakening of sentiment due to exclamation symbols
are issues to be addressed in future work.

3.2.4. Cross-domain sentiment classiﬁcation

Of late, cross-domain sentiment analysis became an interesting
research problem to work upon. Due to high variation of subjectiv-
ity across domains, it is a challenging task. Cross-domain requires
at least two domains: source domain on which a classiﬁer is to be
trained on, and target domain on which testing is to be performed.
Work carried out in this area can be classiﬁed into two groups; the

ﬁrst group requires initial training set from source domain as well
as from target domain [121]. The learners in the second group of
study are trained on source domain and tested on target domain
[98,99]. These studies were carried out using lexicon based
[36,98], machine learning based [121], and hybrid approaches [99].
Tan et al. [121] applied supervised learning approach for
cross-domain sentiment classiﬁcation. They proposed an effective
measure i.e. Frequently Co-occurring Entropy (FCE), to select gen-
eralizable features that occur frequently in both old-domain data
and the unlabeled new-domain data. They employed weighted ex
pectation–maximization based Adapted Naïve Bayes (ANB) to train
a classiﬁcation model for the new domain. For the experiment,
education reviews (1012  ve and 254 +ve), stock reviews (683
 ve and 364 +ve) and computer reviews (390  ve and 544 +ve)
were considered. The proposed approach outperformed NB,
Expectations Maximization-NB (EM-NB), and Naive Bayes transfer
classiﬁer and yielded average 82.62% micro F1 (i.e. for common cat-
egories) and 79.26% macro F1 (i.e. for rare categories). FCE can be
replaced with other techniques to pick out better generalizable
features. Weichselbraun et al.
[98] created contextualized,
cross-domain lexicons that can be integrated into a wide range
of
applications.
Disambiguation and contextualization have been considered to
get better result on cross-domain SA. Ontological lexicon was cre-
ated in three phases (a) ambiguous term detection with the help of
existing pre-labeled corpora, (b) calculating sentiment score based
on the probabilities of co-occurring contextual terms, and ﬁnally
(c) SA by combining polarity values for unambiguous and ambigu-
ous terms. Evaluation was performed on 2500 reviews from
Amazon.com, 1800 hotel reviews from TripAdvisor.com and Pang
and Lee [167] movie review dataset and yielded precision of
76.5%, 82%, 79% respectively. Extension of the proposed lexicon
was required by using grounded concepts from SenticNet [106],
ConceptNet [120], Freebase [128], DBPedia [129], etc.

opinion mining

decision

support

and

Bollegala et al. [99] proposed automatic sentiment sensitive
thesaurus creation and feature expansion for cross-domain senti-
ment classiﬁcation. Novelty of the proposed method was the
exploitation of the created thesaurus to expand feature vectors at
training and testing part of a binary classiﬁer. Sentiment score
was calculated based on PMI between a sentiment element and
feature vectors. Experiments were performed on the Blitzer et al.
[149] dataset and yielded average accuracy of 80.9%. For each
domain, a sentiment sensitive thesaurus was created using labeled
data from source domain and unlabeled data from source and tar-
get domains. Each thesaurus was utilized to expand the labeled
feature vectors from the source domains and train an L1 regular-
ized logistic regression-based binary classiﬁer (Classias17). These
four thesauri were compared against three baseline methods and
yielded better performance over all methods. Future work needs to
ensure wide applicability in other domains as well.

[105],

[106],

SenticNet

Cho et al. [36] suggested cross-domain sentiment classiﬁcation
by integrating multiple sentiment dictionaries viz. WordNet-Affect
[4], SentiWordNet [5,6], WordNet [133], Opinion Lexicon (OL) [38],
AFINN [55], SO-CAL [69], Subjectivity Lexicon [104], General
Inquirer
and
Micro-WNOp [119] together. These were exploited either after
removal of some entries or shifting polarity of some of the entries
according to a given domain. They proposed an algorithm to
remove and/or shift polarity of a sentiment word. For the experi-
ments, 17,500, 35,000, and 90,000 reviews were collected from
Amazon.com for smartphones, movies, and books to build a posi-
tive/negative review dataset. They achieved 82.6%, 80.1%, and
81.8% accuracies for smartphone, movie, and book reviews,

SentiSense

[113],

16 http://www.muchocine.net.

17 Available at: http://www.chokkan.org/software/classias/.

K. Ravi, V. Ravi / Knowledge-Based Systems 89 (2015) 14–46

25

respectively. The proposed approach can be utilized to create a
custom dictionary, which may yield promising result
for
cross-domain sentiment classiﬁcation.

3.3. Review usefulness measurement

In information age, market managers are becoming more inter-
ested in promotion of their products and services. In order to pro-
mote their products some of them are hiring fake reviewers to
write fake reviews [137,181]. Although these fake reviews do not
have long time effect on product sale, it can amplify initial sale.
Thus, opinion spam detection and review usefulness measurement
gained so much attention by research communities [181]. These
two sub-tasks of SA sound similar but they are the two different
side of the same coin. In most of the cases, a review spam usually
concerns a good quality review, while a bad quality review need
not tend to be a review spam. This is because on one hand in the
most of the cases, a review spam is written very intelligently either
to boast the product or discredit the product. On the other hand a
bad quality review is written by an honest consumer. Opinion
spam detection is brieﬂy presented in the next section. The quality
of reviews is discussed brieﬂy in [181]. Therefore, we considered
some of recent advancements made by existing study for review
usefulness measurement. The study followed machine learning
[76,81,222–228] and hybrid approaches [78,130,221,229].

Ghose and Ipeirotis [81] identiﬁed several features to measure
helpfulness of a review like subjectivity levels, various measures
of readability and extent of spelling errors to identify important
text-based features. Some more features related to multiple
reviewer features like average usefulness of past reviews, the
self-disclosed identity measures of reviewers have been consid-
ered. Observation was that subjectivity, informativeness, readabil-
ity, and linguistic correctness in reviews matter in inﬂuencing sales
and perceived usefulness. Experiments have been performed on
product reviews collected over 15 months from Amazon.com on
audio and video player, digital camera, and DVD. SVM and
Random forest (RF) were utilized for predicting review helpfulness,
where RF outperformed SVM in all cases. They concluded that only
subjective or objective reviews have good impact on product sales
in comparison to highly subjective or highly objective reviews. In
future, helpfulness can be calculated on the basis other factors like
considering type of users and the context, etc. Liu et al. [76] devel-
oped an algorithm in two phases to measure the helpfulness of a
review. In the ﬁrst phase, product feature extraction was per-
formed using PMI based document proﬁle model. For the helpful-
ness prediction, bootstrap aggregating algorithm along with
decision tree outperformed MLP, simple linear regression (SLR),
and sequential minimal optimization-support vector regression
(SMOreg). In second phase, principal component analysis (PCA),
feature-instance similarity, and mutual information (MI) based
feature selection methods were applied to extract generic features
to determine helpfulness. Experiments were performed on 1000
reviews collected from Amazon.com on mobile phone, and
achieved MAE 0.599 for training in the ﬁrst phase, and MI and
PCA outperformed for 3 datasets. Further experiments can be car-
ried out on new domain.

relationship among reviewer’s

Racherla and Friske [222] established that review helpfulness
was correlated with a combination of review and reviewer’s char-
acteristics. Credibility of a review was proven by establishing lin-
ear
identity, expertise, and
reputation along with review elaborateness, review valence, and
review helpfulness using ordinary least square regression method.
They experimented with 3000 reviews on three different service
categories taken from www.yelp.com. Consequently, most of the
characteristics listed above were found to be effective except
reviewers’
identity. Future study can include brand, cost of

services, number of review reads, reviews from different reviews
site and category, etc. to determine the credibility of a review.
Mudambi and Schuff [223] applied regression model to measure
helpfulness of a set of reviews. They considered type of products
viz. experience or search, number of votes to a review, number of
people found a review to be helpful, number of stars, and word
count. Experiments were carried out on 1608 reviews on six pro-
duct items taken from www.amazon.com. They reported that pro-
duct type affects rating and review length. Moreover, review length
positively affects the helpfulness of a review. This study is further
extended by Huang and Yen [224] and proposed two modiﬁed
regression equations. They experimented with 2209 reviews in
the same category of products but slightly new version of products.
The proposed method yielded up to 15.7% of variation in review
helpfulness. In future, reviewer’s information, product metadata
and subjectivity can be considered to improve the performance.

Chen and Tseng [225] proposed information quality framework
on the basis of nine dimensions of review features. The prominent
dimensions included believability, objectivity, reputation, rele-
vancy, timeliness, completeness, appropriate amount of informa-
tion, ease of understanding, and concise representation. These
nine review dimensions gave ﬁfty-one features in order to classify
useful and non-useful reviews using SVM. On the basis of proposed
method, they developed a quality-based review retrieval system.
The proposed system was used to extract top 150 reviews on each
of ten categories of digital camera and mp3 players. Evaluation of
the result was carried out by employing 3 human experts. The pro-
posed framework can be extended to other domain like forums,
blogs, etc. as well. Lee and Choeh [226] employed MLP to measure
helpfulness of a review, which outperformed the linear regression
analysis. Required features considered for the model were: product
related information, linguistic features, and metadata of a review.
They predicted helpfulness of 28,299 reviews on different products
taken from www.amazon.com using in total of 20 features.
Training and testing have been performed 12 times on 12 different
test sets using MLP yielding the least mean-squared error of 0.122.
Statistical signiﬁcance test conducted using Wilcoxon test indi-
cated that the results of different test sets are different. In future,
temporal
information about review can be incorporated to
improve the effectiveness of the approach.

Ngo-Ye and Sinha [227] employed vector space model and RFM
(Recency, Frequency, and Monetary Value) score to predict helpful-
ness of a review.
In RFM, recency referred to the difference
between current review post date and last review post date, fre-
quency represented the number of reviews written by a reviewer,
and monetary value was calculated on the basis of average number
of helpful votes a reviewer received on his/her entire written
reviews. In total 28 different types of models have been proposed
and experimented with 584 Amazon book reviews and 7465 Yelp
restaurant reviews. Out of 28 models, modiﬁed bag of words
(BOW0) + RFM score based model yielded the best helpfulness pre-
diction using SVR model. Here, BOW0 represented subset of fea-
tures obtained by applying correlation-based feature selection on
the features obtained in document-term matrix using TF-IDF.
And RFM score gave three features in the form of Recency,
Frequency, and Monetory value. The study suggested more review-
ers’ information to be included for better helpfulness prediction
and proposed method should be tested on various other domains.
Krishnamoorthy [228] developed a predictive model to measure
helpfulness of a review. He mainly considered linguistic features,
review metadata, readability and subjectivity features to estimate
helpfulness. Among linguistic features like adjectives, state verbs,
action verbs, he emphasized action verbs due to its concreteness,
veriﬁability, indisputability, and being informative. They experi-
mented with the dataset of Blitzer et al. [149] and 1653 reviews
on different products reporting an F-measure of 87.21% and

26

K. Ravi, V. Ravi / Knowledge-Based Systems 89 (2015) 14–46

81.33% respectively using RF. RF outperformed NB and SVM in this
study. He compared different categories of features involving lin-
guistic, review metadata, readability and subjectivity features
and found linguistic features to the best. Study indicated several
interesting future directions to work further.

Hu et al. [78] devised two discretionary accruals based models,
one for helpfulness measurement and other for validation. The
model considered 7 variables to decide the helpfulness of a review.
Considered variables were viz. bestseller dummy, time dummy,
mean and variance helpful vote dummy, high-average-helpful vote
dummy, high-variance-helpful vote dummy, popularity, and price.
Experiments were performed on 100 consumer ratings on 1851
books from amazon.com during July, 2005. With the help of the
second model, they found that the bestsellers were less likely to
engage in review manipulation, and review manipulation decrease
over time. Future studies require observing the behavior of review
manipulator over time and across different categories. Zhang [130]
aggregated online product reviews by weighing stars in two
orthogonal dimensions: polarity extraction, and usefulness scoring
using regression analysis. He utilized 3 features (a) lexical similar-
ity features, (b) shallow syntactic features, and (c) lexical subjectiv-
ity clues to identify useful reviews and usefulness scoring. In order
to measure the lexical similarity between customer reviews and
product speciﬁcation, cosine similarity with TF-IDF were utilized.
Shallow syntactic features and lexical subjectivity clues have been
retrieved using 4 different existing works by Hatzivassiloglou [31],
Wiebe [87], Rilo et al. [153] i.e. MetaBoot algorithm, and Thelen
et al. [83] i.e. Basilisk algorithm. For the experiment, Amazon
Web Services18 was used to collect reviews on three different
domains: electronics (Sony and Canon), video, and books. The author
assessed the inﬂuence of the review author’s proﬁle using analysis of
variance between the usefulness score. They inferred that the
full-regression model (e-SVR and m-SVR algorithms) outperform a
uni-variate polarity-based model. The regression models signiﬁ-
cantly outperform the length-based and rating-based baselines.
The proposed model can be applied for different text genres like
blogs and forums on events, public ﬁgures, and social movements,
etc.

Min and Park [221] argued that a review written by an experi-
enced customer was more important than a professional reviewer.
In order to measure the helpfulness of a review they considered the
duration of product use, the number of products used from the
same brand, and temporal detailed description about product
use. They extracted the duration of product use using TERN evalu-
ation19 and time tagger.20 In addition to that discussed entities are
extracted using shallow parsing on the basis of deictic expressions
or time expression. Experiments are carried out on the dataset of
Blitzer et al. [149] and 3345 reviews on apparel and beauty from
amazon.com. They reported F1 up to 88.58% for entity detection
and an accuracy of 83.33% for identifying product-referring terms
using RBC, where RBC outperformed DT and SVM. Evaluation was
performed by employing eight human evaluators to rate the helpful-
ness of 96 reviews. Assumption needs to be more rigorously evalu-
ated on larger set and some other user mentioned cues can be
explored.

Purnawirawan et al. [229] purposed to use the balance (the
ratio of positive and negative reviews) and sequence (the order
in which the reviews are presented) to measure the usefulness of
a review set. They further investigated various effects of review
usefulness on review readers. Regarding balance, they argued that
either positively or negatively inclined reviews were more useful

18 http://aws.amazon.com/ecs.
19 The Time Expression Recognition and Normalization, 2004 http://www.itl.nist.-
gov/iad/mig/tests/ace/2004/.
20 http://fofoca.mitre.org/taggers/timex2_taggers.html.

compared to neutral reviews. In terms of sequence, they found that
wrapping one polarity based reviews into other polarity based
reviews was more useful. Experiments were carried out on 8
positive and 8 negative reviews on 3 (Balance: positive, neutral,
negative)  4 (Sequence: positive/negative, negative/positive,
positive/negative/positive, negative/positive/negative). The proposed
method needs to be extended over larger corpora and different
domains in future.

3.4. Opinion spam detection

With the growing popularity of e-commerce and online
reviews, an individual used to actively engage professionals in
writing false reviews. Here, an individual may be marketing per-
sonnel, a manufacturer, a service provider, a leader, or a movie pro-
ducer, etc. And a false review can also be referred as a fake review,
an opinion spam, a fraudulent review or a non-genuine review. The
person who writes a fake review is called as a spammer or fake
reviewer. If a group of people get involved in the process, then they
are referred to as group spammer [199]. A spammer used to post
fake reviews either to promote a low quality product or to discredit
a good quality product.

Most of the opinion spam detection technique depends on three
types of features related to a fake review, which includes content of
review, meta-data of review, and real-life knowledge about the
product [181]. The ﬁrst and foremost source of information of
spam detection is the text written in a review. The text can be ana-
lyzed using natural language processing and machine learning
techniques in order to uncover deception and lies hidden in the
text [232]. Meta-data of a review includes various attributes viz.
user-id, IP address, geo-location, date and time of writing, number
of stars, etc. [231]. But in the most of the cases all required
meta-data is not easily accessible to spam detector, which makes
review detection a challenging task. Third attribute i.e. real-life
knowledge about the product can play a major role in identifying
an opinion spam. For instance, a particular brand has very good
reputation and an inferior brand has been shown as superior to
that in some reviews posted during speciﬁc period, in such cases
a review can be suspected as a fake review.

Opinion spam detection need to be performed for review spam
detection, spammer detection and group spammer detection [199].
Review spam detection is the process of determining whether a
review is written by an authorized buyer with honest intention
or not. Next, Spammer detection identiﬁes an un-authorized buyer,
who wrote reviews on products or services without experiencing
them. And, group spammer detection discovers whether more than
one person is involved in spamming either from same or different
geographical location. Heydari et al. [199] reviewed a host of meth-
ods proposed for the three types of opinion spam detection. Some
promising review spam detection methods included duplicate
ﬁnding methods [234], concept similarity based method [235],
content based method [200,210], and review and reviewer ori-
ented features based method [236], etc. Spammer detection tech-
niques
temporal
activity-based method [238], etc. Graph based method builds a
graph of review, reviewer and product in order to capture trust-
worthiness of the reviewer, the honesty of review and the reliabil-
ity of the product, sentiment of the review, etc. Group spammer
detection technique involved pattern mining based method
[239]. Apart from these techniques, some other recently proposed
studies are broadly classiﬁed into machine learning based
approaches [200,216,232] and hybrid approaches [212,220,231].
Interested reader can refer to Refs. [137,181,199] for detailed
reviews on opinion spam detection.

graph-based method

included

[237],

Ott et al. [212] performed opinion spam detection on the basis
of artiﬁcially developed positive review spam dataset. The dataset

K. Ravi, V. Ravi / Knowledge-Based Systems 89 (2015) 14–46

27

and

They

observed

deceptive

classiﬁcation.

contained 400 positive truthful reviews which are taken from
TripAdvisor.com and having rating star 5. Amazon’s Mechanical
Turkers were employed to write 400 positive deceptive reviews.
In order to detect a spam, (a) they performed genre identiﬁcation
based on POS tag, (b) psycholinguistic deception detection using
LIWC software, and (c) NB and SVM based text categorization using
different n-gram based representation. LIWC + Bigram representa-
tion based SVM yielded the best F-measure of 89.8% for both truth-
ful
several
relationships between emotion and deceptive reviews. In other
study, Ott et al. [200] developed a negative deceptive opinion data-
set and performed spam classiﬁcation using SVM. The dataset con-
tained 400 negative truthful and 400 negative deceptive reviews.
Truthful reviews were collected from 6 review sites having rating
stars 1 or 2. Deceptive reviews were written by workers employed
by AMT service, where each review is written by different worker.
So, the deceptive dataset contained 20 reviews on each of the 20
hotels situated at Chicago. They experimented with the developed
800 negative reviews and 800 positive reviews taken from Ott et al.
[212] on unigram and bigram term-frequency representation.
Linear SVM yielded an F-measure of 86.1% and 89.3% respectively
under 5-FCV framework. They explored relationships between sen-
timent and deception. Moreover, they found to fake negative
reviews were linguistically different from truthful and fake posi-
tive reviews in terms of ﬁrst person singular use, verbs use, etc.
At the beginning of a launched product item review manipulation
occurs more frequently and it decreases over time [78].

Hu et al. [231] proved that review manipulation is a monoton-
ically decreasing function of the product’s true quality or the mean
consumer rating of that product using regression. Regression
included some important features of a review like age of the previ-
ous review, age difference between two successive reviews, aver-
age rating, popularity, constant to control the product category,
etc. They experimented with reviews collected from Amazon and
Barners & Noble on books, DVD, and videos collected over several
months at approximately three-day intervals. The study mainly
relied on rating based features and content based features can be
considered in future. Banerjee and Chua [220] considered some lin-
guistic features viz. readability, genre, and writing style in order to
predict review spam. First, they computed readability using
Gunning-Fog
(CLI),
Automated-Readability Index (ARI), and Flesch- Kincaid Grade
Level (FKG). Second, the review genre included distribution of dif-
ferent POS. Third, writing style calculated ratio of positive cues,
perceptual words, and future tense using LIWC software. In total,
they considered 13 features involving two readability metrics,
the eight POS tags, and the three writing style metrics. The vari-
ance inﬂation factors (VIF) were calculated in order to check the
existence of multi-co-linearity. Then, they classiﬁed with Ott
et al. [212] dataset using Binomial logistic regression and yielded
a sensitivity of 71.75% and a speciﬁcity of 70.75%, where deceptive
review spam comes under positive class. The proposed approach
can be employed to other negative review spam review detection,
different domain, and big data as well.

Coleman-Liau

(FOG),

Index,

Index

Fusilier et al. [232] developed a modiﬁed PU-learning (Positive
and Unlabeled samples based learning) [233] in order to detect
positive and negative deceptive opinions. PU-learning is a
semi-supervised kind of learning, which performs binary classiﬁca-
tion using positive samples and unlabeled samples. They experi-
mented with Ott et al.
[200] dataset, which contains 400
deceptive and 400 truthful reviews on each positive and negative
category. The modiﬁed PU-learning model yielded an F-measure
of 78.0% on positive spam vs. positive genuine and 65.7% on nega-
tive spam vs. negative genuine dataset respectively. In future, they
would like to apply the proposed approach in the detection of
online sexual predators and lies. Costa et al. [210] performed spam

classiﬁcation of tips written about different places. They experi-
mented with 7076 tips (3538 spam and 3538 non-spam) which
were collected from a Brazilian Location Based Social Networks
using Apontador API. Spam and non-spam labels were manually
assigned by three annotators. Classiﬁcation was performed on
the basis of Variable Importance Measures and ranked 60 attributes
comprising content, user, place, social attributes, etc. The ﬂat and
hierarchical classiﬁcations had been performed using SVM and
RF. The ﬂat classiﬁcation was performed into four classes:
non-spam, local marketing spam, bad-mouthing spam and pollu-
tion spam. The hierarchical classiﬁcation was performed at two
levels. The ﬁrst level classiﬁcation was non-spam vs. spam. The
second level classiﬁcation was performed for spam group consist-
ing of three classes: local marketing, bad-marketing and pollution.
For both classiﬁers, ﬂat classiﬁcation dominated hierarchical clas-
siﬁcation for non-spam and local marketing determination and
hierarchical
classiﬁcation for
bad-marketing and pollution detection. They analyzed the impact
of different subsets of attributes of size 10 and all subgroups of
attributes were found to outperform the baseline method. The pro-
posed approach can be extended to ﬁnd spam group as well.

classiﬁcation dominated ﬂat

Therefore, in summary, the key challenges in this area include
lack of proper review spam dataset in order to compare effective-
ness of two or more techniques and no access to spammers’ iden-
tity to analyst. There are mainly three techniques to collect spam
reviews, which have been exploited in different opinion spam
detection studies. First option is to collect suspected spam reviews
from different review sites. Second alternative is to synthesize a
list of non-real reviews from existing real reviews by taking differ-
ent combination of sentences. Third solution is to employ human
resource from Amazon Mechanical Turk21 (AMT) to write fake
reviews, but that cannot make a real challenging task for analyst.
That happens due to psycholinguistic state of mind of an AMT
employer will be very different from a fake reviewer. Moreover, a
fake reviewer can write a fake review, which can be quite similar
to an original review.

3.5. Lexica and corpora creation

A lexicon is a vocabulary of sentiment words with respective
sentiment polarity and strength value. The lexicon creation starts
with an initial list of words also known as seed words and the list
is extended using synonym and antonym of seed words.
Synonyms and antonyms words were taken from WordNet
[3,133] dictionary. This process is repeated until extension of the
list is not stopped. Lexicon can be broadly divided into two cate-
gories: non-ontology based [6,24,55,56,69,74,97,111,116–118,127
] and ontology based [21,23,30,52,106,120,199,211]. Majority of
these study considered here are based on English language, except
[26,111,211].

3.5.1. Non-ontology based approaches

This category includes lexica created using machine learning,

lexicon based and hybrid approaches.

Thelwall et al. [116] produced a lexicon, SentiStrength, for sen-
timent classiﬁcation. The lexicon was created by identifying senti-
ment expressed in a range of recognized nonstandard spellings and
other common textual methods found on MySpace. For the evalua-
tion of the proposed lexicon, MySpace22 2600 comments for the
learning and 1041 comments for the evaluation were considered.
The effectiveness of the proposed lexicon based sentiment classiﬁca-
tion was compared against a host of classiﬁers. The proposed

21 https://www.mturk.com/mturk/welcome.
22 www.myspace.com.

28

K. Ravi, V. Ravi / Knowledge-Based Systems 89 (2015) 14–46

method predicted positive emotion with an accuracy of 60.6% and
negative emotion with an accuracy of 72.8%. The performance of
the system can be improved through linguistic processing.
Thelwall et al. [117] analyzed the sentiment strength of public opin-
ion associated with popular events. Observations on top 30 events
gave strong evidence that popular events were normally associated
with increases in negative sentiment strength. For the experiments,
part of spinn3r datasets, 34,770,790 English language tweets from
2,749,840 different accounts were considered. Sentiment classiﬁca-
tion is performed using a dictionary, SentiStrength [116], which gave
sentiment strength either positive or negative of each tweet. The
hourly average positive and negative sentiment strength scores have
also been computed for each topic. They came up with six different
conclusions
strength difference
between different events.

regarding average sentiment

rather

Logistic

regression was more

Working further on SentiStrength, Thelwall et al. [118] assessed
the extended version of SentiStrength viz., SentiStrength 2.
Evaluations was performed on six diverse social web datasets viz.
BBC forum, Runners World Marathon discussion forum, MySpace
comments, Tweets, YouTube comments, Digg News identiﬁcation
site. SentiStrength 2 performed well on all datasets except BBC
news discussion forums. Machine-learning approach can outper-
form SentiStrength 2 if discourse features were indirectly associ-
than by directly identifying
ated with sentiment
sentiment.
than
SentiStrength 2, if sufﬁcient human-coded data were available par-
ticularly for news discussions. The lexicon-based approach was
more robust and relatively domain-independent. For
future
enhancement of SentiStrength, discourse analysis, irony and sar-
casm detection should be considered. Nielsen [55] extended an
existing sentiment lexicon namely AFINN-96. Extension was per-
formed using a list of existing lexica and corpora. Lexica and cor-
pora include the Compass DeRose uide to Emotion Words,23
Urban dictionary, Wiktionary, Original Balanced Affective Word
List,24 tweets on the United Nation Climate Conference, etc.
AFINN-96 outperformed Affective Norms
for English Words
(ANEW) for twitter data but not SentiStrength. Further extension is
required to improve its effectiveness.

suitable

Thelwall and Buckley [127] classiﬁed sentiments using
SentiStrength in two phases: mood setting and lexicon extension.
These functions can improve the accuracy of topic-speciﬁc lexical
sentiment strength detection. Thus, for sentiment classiﬁcation,
SentiStrength lexicon was extended for the particular topic with
respect to mood of social web. The proposed method was applied
for tweet corpora: the UK riot rumors corpus and the AV referen-
dum corpus. Evaluation was performed on six corpora generated
in [118]. The proposed method was not performing well on news
discussion forums. In future, evaluation is required on larger
corpora.

SentiWordNet 3.0 is the one of the most promising lexical
resource for sentiment score determination of an opinion word
[6]. It deﬁnes three types of sentiment scores (Obj(s), Pos(s), and
Neg(s), which range from 0.0 to 1.0 and in sum equal to 1.0) to each
noun, verb, adjective and adverb given in WordNet [133]. Score
was decided using eight ternary classiﬁers, which were trained
on glosses deﬁned for WordNet synsets. But, 93.75% synset of
SentiWordNet 3 are objective type. Hung et al. [97] considered
these objective words to further classify into binary polarity.
Sentiment orientation of an objective word was decided on the
basis of other common subjective words used in the sentence. If
positive score of a sentence was higher than negative score, then
objective words were assigned positive polarity otherwise negative

polarity. And, sentiment value of the objective word was computed
using pairwise mutual
information from two words being
extended to a word and its associated sentence. Evaluation of the
proposed method was performed on 27,886 movie review articles.
Sequential Minimal Optimization-SVM with a poly kernel was
used for classiﬁcation and yielded the average accuracy of
76.02%, which was 4.13% more than traditional SentiWordNet clas-
siﬁer. In future, semantic viewpoint based sentiment extraction
and document summarization at different level can be tried.

Further advancement

in SentiWordNet can be seen in
Neviarouskaya et al. [74], who reported better performance over
SentiWordNet. Initially, they created a lexicon SentiFul which
was created by exploiting WordNet-Affect database containing
2438 direct and indirect emotion-related entries based on nine dif-
ferent emotions. SentiFul has been further extended using
SentiWordNet and polysemy. New lexemes have been devised by
compounding of words, changing bases and afﬁxes of opinion
words, where sufﬁxes played pivotal role. Evaluation of the lexicon
was performed in two phases: in the ﬁrst phase two annotators
were employed to annotate 200 terms from each of the ﬁve lists
created by different methods. The second phase evaluation was
performed using General Inquirer (GI) and accuracy achieved was
94.1% and 86.3% for SentiFul core and SentiFul respectively. The pro-
posed dictionary can be extended further using more linguistic fea-
tures like modal verbs and adverbs. It should then be evaluated
using machine learning algorithm.

Taboada et al. [69] extended their own proposed dictionary
Semantic Orientation-Calculator (SO-CAL), which gives polarity
and strength of an opinion word. They computed semantic orienta-
tion using a simple aggregate-and-average method: the total score
of all adjectives was divided by the total number of adjectives in the
document. To develop the dictionary, different corpora described in
Taboada and Grieve [71] and Taboada et al. [72], consisting of a
400-text collection of epinion.com reviews i.e. Epinions 1, were uti-
lized. They considered a list of opinion words taken from Taboada
and Grieve [71] and Taboada et al. [72], Epinions 1 Polarity
Dataset, and General Inquirer (GI) [105] dictionary to prepare the
dictionary. The dictionary was extended by considering intensiﬁca-
tion, negation, irrealis (non-sentiment word indicator) blocking,
etc. The performances have been tested on four dataset: (a)
Epinions 1, (b) Epinions 2, (c) Pang and Lee [167] dataset, (d)
Camera: A 2400-text corpus of camera, printer, and stroller reviews.
The highest classiﬁcation accuracy reported for Computers in
Epinions 1 and Epinions 2 was 0.94 and 0.90 respectively. The pro-
posed dictionary was also evaluated across domain using different
dataset for short texts. In future, contextual information, word dis-
ambiguation, and discourse analysis can be considered.

In the view of several names for a feature of the product, Zhai
[56] developed an automatic system for synonym grouping. They
applied semi-supervised learning, which starts with a small set
of seeds i.e. labeled data, and expanded with other synonyms.
Expectation maximization was applied to assign soft constrained
labels to a set of unlabeled feature expressions. WordNet was uti-
lized to calculate lexical similarity between different classes of fea-
tures. Bayesian learning was applied to each feature expression of
the document. Evaluation was performed on ﬁve domains: home
theater, insurance, mattresses, cars, and vacuums, which included
reviews,
feature expressions, and groups. The proposed soft
constrained-expectation maximization method outperformed 16
baseline methods. In future, natural-language knowledge is to be
exploited at more semantic level.

Kang et al. [111] created a new senti-lexicon25 for SA of restau-
rant review, which was based on unigram + bigram, negation and

23 http://www.derose.net/steve/resources/emotionwords/ewords.html.
24 http://www.sci.sdsu.edu/CAL/wordlist/origwordlist.html.

25 Available at: http://irlab.sejong.ac.kr/res-sentiwordnet/.

K. Ravi, V. Ravi / Knowledge-Based Systems 89 (2015) 14–46

29

intensiﬁers. Two improved Naïve Bayes methods were proposed to
map the gap between positive and negative classiﬁcation accuracy,
and to improve the average classiﬁcation accuracy. Sentiment classi-
ﬁcation has been performed on approximately 70,000 review docu-
ments from different restaurant search sites. The proposed NB
outperformed baseline methods, and yielded up to accuracy of
81.2%. In future, performance of the proposed algorithm is to be
tested using more experiments and for different languages.

Maks and Vossen [24] extended an existing Dutch lexicon, i.e.
Cornetto. The lexicon combines two resources with different
semantic organizations:
the Dutch WordNet and the Dutch
Reference Lexicon. They emphasized on the extent to which a
speaker is able to interpret the meaning. For this purpose, they
considered different type of subjectivity like epistemic subjectivity
(how certain or uncertain a speaker
is about a given
state-of-affairs), speaker subjectivity, character subjectivity, where
existing literature concerns more about the presence of a speaker.
For evaluation, annotation was performed on 574 verbs, 595
nouns, and 609 adjective lexical units, yielded inter-annotator
agreement 66%, 74%, and 79% respectively. They created a gold
standard of approximately 600 items for each part-of-speech in
order to build a rich subjectivity lexicon of Dutch.

3.5.2. Ontology based approaches

An ontology is an explicit speciﬁcation of a conceptualization
It provides formal representation of knowledge, which
[192].
enables reasoning. It is better than taxonomy or relational data-
base management system, since it captures semantic association
between concepts and relationships as well. Therefore, SA commu-
nity swiftly moving towards ontological based approaches to rep-
resent commonsense knowledge base [95,106,120].

iterative regression model, which was

ConceptNet is a freely available large-scale knowledge base
with an integrated natural-language-processing tool-kit that sup-
ports many practical textual-reasoning tasks over real-world doc-
uments [120]. Tsai et al. [21] developed sentiment dictionary
based on ConceptNet using iterative regression model. The regres-
sion model was built upon concept, concept sentiment value and
polarity, and features of neighboring concepts. Values generated
using regression model were used as the starting values for the
proposed random-walk method with in-link normalization. 4-ary
concept polarity and concept-pair ranking evaluation was per-
formed by knowledge workers, Amazon Mechanical Turk,26 whose
annotation quality was assessed using ANEW dictionary. SVM was
used for
trained on
SenticNet and ANEW, and tested on Outside dataset (unique concepts
of ConceptNet not found in SenticNet and ANEW). The proposed
method achieves the highest ratios in both datasets, which ensures
the fewer concepts have insigniﬁcantly low sentiment values. The
study was further extended by Wu and Tsai [207]. Wu and Tsai
[207] added two new steps viz. relation selection and bias correction.
They selected 33 relation types of ConceptNet and applied sequential
forward search to ﬁlter relations in order to modify existing lexicon.
Bias correction was carried out using zero-alignment, and mean &
variance alignment. Evaluation of polarity accuracy determination
and concept-pair
ranking were performed by AMT worker.
Moreover, inter-annotator agreement as measured by Fleiss’ kappa
value, turned to be 0.74. Experiments were carried out on the data-
sets of Pang and Lee [167] and Rajagopal et al. [208] for sentiment
classiﬁcation. Effectiveness of the lexicon can be ensured by per-
forming sentiment classiﬁcation on different domains.

As regards ontological development of sentiment knowledge
base, Cambria et al. [106] developed SenticNet 1.0. They exploited
ConceptNet [120] and WordNet-Affect27 (WNA) [4] to build a

vector

space

of

affective

knowledge

n-dimensional
viz.,
AffectiveSpace [141]. AffectiveSpace was obtained by applying sin-
gular value decomposition in order to select 100 principal compo-
nents representing common sense concepts and emotions. In order
to decide positive and negative valence, they considered positive
and negative eigen components. Unlike 3 sentiment score values in
SentiWordNet, single sentiment score was assigned to each concept
on the basis of hourglass of emotions. Manual evaluation was per-
formed on 2000 patient opinions and yielded better F-measure over
SentiWordNet i.e. 67% versus 49%. SenticNet 1.0 was further
extended by Poria et al. [23] with emotion label taken from WNA
[4]. They used supervised machine-learning to assign WNA emotion
labels to SenticNet’s concepts. WordNet 3.0 [142] was exploited for
lexical induction to SenticNet 1.0 WNA and International Survey of
Emotion Antecedents and Reactions (ISEAR) dataset28 was used to
extract classiﬁcation features, which yielded 40 ISEAR dataset attri-
butes and corpus-based similarity measures. Concept co-occurrence
similarity measure was calculated using SenticNet score-based sim-
ilarity, WordNet distance-based similarity, PMI, emotional afﬁnity,
and ISEAR text-distance similarity. ISEAR-based features were con-
sidered for classiﬁcation. SVM yielded the best accuracy of 88.64%,
which was better than that of NB (71.20%) and MLP (74.12%). The
proposed lexicon can be extended with new concepts taken from
new monolingual or multilingual corpora.

In order

Meanwhile, Cambria et al. [136] proposed SenticNet 2.0, which
was based on sentic computing and principles taken from com-
puter and social sciences. It provides the semantics and sentics
(that is, the cognitive and affective information) associated with
over 14,000 concepts.
to capture common and
common-sense knowledge base, Cambria et al. [202] developed
SenticNet 3, which was an ensemble of several knowledge base
viz. ConceptNet, DBPedia, WordNet, etc. SenticNet 3 knowledge
base was developed in two stages. In the ﬁrst stage, it builds
Resource Description Framework (RDF) triplets, which were then
were inserted into a graph through the energy-based knowledge
representation (EBKR) formalism. Cambria et al. [52] proposed a
novel cognitive model to capture multi-word expressions by
exploiting ConceptNet and WordNet-Affect. AffectiveSpace [141]
was able to grasp the semantic and affective similarity between
concepts by plotting them into a multi-dimensional vector space.
Principal component analysis was applied for feature selection.
KNN and K-medoids were applied to determine semantically
related concepts. In order to determine the level of affective
valence of concept ‘discrete’ neural network (DNN) and ‘continu-
ous’ neural network (CNN) were designed. Testing was performed
on the benchmark for affective common-sense knowledge (BACK)
[140] using 10-FCV. DNN yielded the highest strict accuracy of
46.9% and CNN yielded the highest relaxed accuracy of 84.3% over
KNN, and K-medoids, and Random classiﬁer. For practical environ-
ment, testing was performed by embedding ANNs into an opinion
mining engine [140] to infer cognitive and affective information
associated with natural language on a patient opinion database29
and CNN outperformed baseline methods. In future, more feature
selection methods can be tested.

Along the same line, Poria et al. [213] introduced a hybrid
approach comprises linguistics, common-sense computing, and
machine learning for concept-level sentiment analysis. In order
to extract concepts and events from natural language text, they
proposed POS-based bigram algorithm and event concept extrac-
tion algorithm. Concept polarity and intensity were calculated
using AffectiveSpace and the Hourglass of Emotions, where
AffectiveSpace was obtained by applying truncated singular value

26 www.mturk.com/mturk/welcome.
27 www.cse.unt.edu/rada/affectivetext/data/WordNetAffectEmotionLists.tar.gz.

28 www.affective-sciences.org/system/ﬁles/page/2636/ISEAR.zip and www.affec-
tive-sciences.org/researchmaterial.
29 http://patientopinion.org.uk.

30

K. Ravi, V. Ravi / Knowledge-Based Systems 89 (2015) 14–46

decomposition on matrix representation of AffectNet. Extreme
Learning Machine (ELM) was applied to cluster AffectiveSpace with
respect to the Hourglass model. A list of linguistic patterns was
developed to deal with various natural language complexities like
coordination, discourse and dependency rules based structures.
Experiments were carried out on Socher et al. [201] and Blitzer
et al. [149] and yielded a precision of 86.21% and 87% respectively.
The proposed approach also outperformed state-of-the-art
approach in sentiment classiﬁcation of sentences with conjunc-
tions and comparisons. In other study, Poria et al. [214] developed
EmoSenticSpace on the basis of SenticNet, EmoSenticNet and
AffectiveSpace, where EmoSenticNet was created by merging
WNA and SenticNet. They assigned one of the six emotion label
of WordNetAffect viz. anger, fear, disgust, sadness, surprise, and
joy to each concept of SenticNet. In order to do that, they applied
supervised classiﬁcation using SVM. The number of features was
identiﬁed in two stages. In the ﬁrst stage, in order to obtain mem-
bership value of concept to six emotion categories, they applied
Fuzzy C-means clustering (FCM). FCM was applied on 16 ISEAR
data columns and 13 similarity measures calculated using
WordNet 3.0, SenticNet score and co-occurrence. In the second
stage, membership values belonging to six emotion categories
were considered. SVM yielded 92.15% accuracy, which was applied
to top two fuzzy clusters. Evaluation was performed on sentiment
classiﬁcation of Stanford Twitter Dataset [169], emotion recogni-
tion on the ISEAR dataset, and personality detection from
Matthews et al. [215] dataset. Some possible improvements have
been suggested in the literature. The proposed lexicon can be
applied to different domains.

Balahur et al. [30] constructed a knowledge base EmotiNet for
representing and storing affective reaction to real-life contexts.
They exploited various existing dictionaries and corpora like
SentiWordNet [5], ConceptNet [120], VerbOcean [146], and ISEAR
[147] to extract emotion expressing words. They evaluated the
proposed ontology on three different size of dataset created using
ISEAR and found promising result. In future, EmotiNet can be
improved by adding more affective properties to the concepts.
Montejo-Ráez et al. [211] developed a corpora of emotional words
crawled from streaming data to perform sentiment classiﬁcation.
They extended an existing project WeFeelFine30 for Spanish lan-
guage. WeFeelFine contained 2178 different feelings collected from
2 million sentences. Out of 2178 feelings, the 200 most frequent ones
had been considered for the study. They crawled 1,863,758 tweets to
generate MeSientoX corpus in Spanish. Opinion words were
extracted on the presence of ‘‘me siento’’ (‘‘I feel’’) and the polarity
was decided using SenticNet 3 and three manual annotators. The
whole process yielded 201 opinion words (the most frequently
occurring ones), of which 84 were considered as positive and 117
as negative opinion words. In order to perform explicit sentiment
analysis, a document was projected onto a space of feelings, and
latent semantic analysis based cosine similarity was calculated to
determine the polarity. Evaluations were performed on Emoticon
data set and SFU Review corpus and yielded an accuracy of 71.86%
and 69.75% respectively. They indicated to use on-line learning algo-
rithms and evolving training data in future work.

3.6. Opinion feature extraction and product aspects extraction

In order to perform ﬁne grained level SA, we need to identify
people’s opinion on various parts of a product. Sentiment score
of different aspect will have varying degree of affect on aggregate
opinion on a product. Thus, mostly discussed as well as important
aspect should be extracted from feedback text. Data collected from

30 http://wefeelﬁne.org.

diverse domain often contain so much noise that it makes opinion
word and aspect extraction very hard. Therefore, research attempts
were made to address these issues.

3.6.1. Opinion feature extraction

It has been observed that opinion feature may appear either in
text format or social media links. Therefore, this sub-section is
divided into two groups namely opinion word extraction and opin-
ion extraction from social networking.

3.6.1.1. Opinion word extraction. Most effective part of speech for
opinion words is adjective, adverb, verb, and noun. These kinds
of part-of-speech are known as opinion or sentiment word. Thus,
extracting opinion words also follows machine learning based
[61,63,92,100], lexicon based [68,132,175] and hybrid approaches
[8,102].

and

performed

opinion

aspect-based

Zhu et al. [63] developed aspect-based sentence segmentation
model
polling. A
multi-aspect bootstrapping (MAB) method was used to learn
aspect related terms from unlabeled data. MAB was started with
5 seeds per aspect from 500 frequent nouns. Experiments were
performed on 3325 Chinese restaurant reviews collected from
the DianPing.com and achieved 75.5% accuracy for opinion polling.
Domain adaptation was a critical issue for opinion polling. Liu et al.
[100] presented opinion extraction and product features extrac-
tion, which was applied for recommender system. To extract an
opinion word, association rule mining was applied wherever an
adjective follows an adverb and a product feature was extracted
by taking n-gram window around an opinion word. For experi-
ments, they downloaded 54,208 Chinese reviews from (beijing.
koubei.com), yielded 60.23% recall for opinion feature extraction
which was more than Hu and Liu [38] method. Context-aware rec-
ommendation system can also be tried.

Lin et al.

[61] proposed Joint Sentiment-Topic (JST) and
Reverse-JST. Both models were based on modiﬁed Latent
Dirichlet Allocation (LDA) with 4 levels i.e. four layer hierarchical
Bayesian model. Models can extract sentiment as well as positive
and negative topic from the text. JST and RJST outperformed base-
line methods. JST yielded accuracy of 76.6% and 72.5% on Pang and
Lee [167] dataset, and Blitzer et al. [149] respectively. Similarly,
RJST yielded accuracy of 76.6% and 71.92% on Pang and Lee [167]
dataset, and Blitzer et al. [149] respectively. Other supervised
information can be incorporated into LDA to improve the efﬁ-
ciency. Duric and Song [92] suggested three different methods
for sentiment word extraction; (a) Hidden Markov Model-Latent
Dirichlet Allocation (HMM-LDA) to get syntactic classes of features,
(b) syntactic and semantic classes based features, and (c) max
scores based features. Experiments were carried out on Pang and
Lee [33] dataset. Maximum Entropy (ME) yielded up to accuracy
of 87.5% classiﬁcation using max scores. All proposed scheme out-
performed POS-based feature selection schemes. The proposed
techniques should be tested on other domain and other purposes
like aspect extraction as well.

Zhan et al. [132] applied text summarization approach to gather
customer concern. They proposed a new algorithm based on fre-
quent word sequences and equivalent classes to extract candidate
sentences for summarization. Experiments were performed on ﬁve
sets from Hu and Liu [135] corpus and three datasets from
Amazon.com. The proposed approach yielded better results than
opinion mining and clustering summarization approach. The pro-
posed approach should be tested on other corpora as well. Wang
and Lee [175] applied dictionary based approach (viz., Hownet)
to extract opinion phrases from 61 Chinese blog posts on digital
camera. They employed window based opinion extraction method,
which considers same polarity for words utilized along with other
opinion words in the same window. To improve the effectiveness

K. Ravi, V. Ravi / Knowledge-Based Systems 89 (2015) 14–46

31

of the proposed approach further, shallow parsing techniques can
be applied. Cruz et al. [68] deﬁned a set of domain-speciﬁc
resources to extract the opinion words. Domain-speciﬁc resource
consists of a set of features like feature-taxonomy, feature cues,
and dependency patterns. They utilized dictionary based approach
like WordNet-, PMI-, and SentiWordNet-based classiﬁer for senti-
ment classiﬁcation. The lexicon was expanded using random walk
algorithm. They created a dataset31 for the experiment. For the
opinion extraction, resource based extraction outperformed resource
free extraction and achieved up to a precision of 71.69%. An accuracy
of 93.45% was achieved for sentiment classiﬁcation. The domain
adaptability is still a major issue.

Li et al. [8] devised a new product feature ranking method
DPLR-R (Double Propagation-Based Linear Regression with Rules).
They proposed page ranking algorithm based feature opinion rank
to rank the product aspects. Rank was based on the number of
opinion words utilized along with a feature and/or vice-versa.
Experiments were performed on 6000 phone, laptop and hotel
reviews and achieved better results than baseline methods. The
challenge lies in extraction of useful training features for these
ranking models. Zhai et al. [102] proposed to extract different opin-
ion features like sentiment term, substring, substring-group and
key-substring group features. Experiments were carried out on
Hotel,32 Product,33 Ctrip,34 Chinese IT-product website-IT16835
datasets. SVM was trained on selected features and yielded up to
accuracy of 91.9%. The proposed feature selection techniques can
be tried for other languages as well.

3.6.1.2. Opinion extraction from social networking. On social net-
working, if someone is linked to/followed/liked a social networking
group or community or public ﬁgure, it implies that the person has
either positive or negative feelings towards that entity. Thus, social
networking provides a new research challenge for SA community
to ﬁgure sentiment from such links. To the best of our knowledge,
very few studies have been carried out on this issue. Thus, some of
such rare initiatives using hybrid approaches are reviewed here.

Rabelo et al. [11] utilized link mining and user-centric approach
to get opinion expressed by social network users. Link was utilized
for assigning classes to objects based on the relationships among
objects. For the experiment, they collected 8000 posts containing
selected hashtags to get 97,000 nodes and almost 1 million edges
for the graph to apply collective classiﬁcation algorithm. They
applied a link mining technique and assigned classes to objects
based on the relationships among objects. The proposed approach
can be applied for group detection. van den Camp and van den
Bosch [125] performed classiﬁcation of personal relationships in
biographical texts. In order to do that, they performed induction
of social networks using social network extraction and SA. They
utilized two types of
features and
co-occurrence features to train SVM, NB, Ripper, and KNN classi-
ﬁers. For the experiment, they selected 574 Biographical articles
from Biographical Dictionary of Socialism and the Labor movement
in the Netherlands (BWSA) in Dutch language. Evaluation of the
system’s performance was performed by the expert in the ﬁeld of
Dutch social history. Induction of named entity recognition and
disambiguation will help to extract more accurate relations.

feature sets viz.

lexical

Sobkowicz et al. [27] framed an opinion formation framework
using agent technology, where agents were able to capture opin-
ions based on effects of leadership, dynamic social structure, and

31 http://www.lsi.us.es/_fermin/index.php/Datasets.
32 http://www.searchforum.org.cn/tansongbo/corpus/ChnSentiCorp_htl_ba_4000.
rar.
33 http://wanxiaojun1979.googlepages.com/PKU-ICST-ProductReviewData.rar.
34 http://www.ctrip.com/.
35 http://www.it168.com.

effects of social distance. Bayesian framework was suggested for
opinion formation forecasting. Application scenarios were recom-
mended for political discussions in Poland, governance of Java
standard, and BP oil spill emails.

3.6.2. Product aspect extraction for aspect level sentiment analysis

For ﬁne-grained comparison of two or more products of similar
categories, we need to ﬁgure out pros and cons of various compo-
nents and features (aka aspects). Let us consider a review on Apple
iPhone from amazon.com.

‘‘One thing is reading specs, and another is using
it. The new iphone is much better in my hand than it
could be forecasted from the specs. It feels much
lighter, with the nice bigger screen. And it’s faster
and takes better pictures, despite camera having the
same specs!"

In this review, positive opinions are expressed on various
aspects and components of an iPhone. Here, ‘‘much ligther’’ refers
to ‘‘Weight’’, ‘‘nice bigger’’ is used for ‘‘screen’’, ‘‘faster’’ refers to ‘‘pro-
cessor speed’’ and ‘‘better pictures’’ for ‘‘camera quality’’. So, notable
aspects discussed are weight, screen, processor, and camera. In order
to extract aspects and aspect level analysis, aspect level SA came
into picture. During the last few years, some of the researchers
have focused on this issue. Product aspect extraction approaches
are divided into two categories: (a) non-ontological approach [25
,37,59,67,107,185,186,189–191,193,218,240,241,243]
(b)
ontological approach [35,62,182,194–196].

and

further

be

into

3.6.2.1. Non-ontological approach. Non-ontological approaches
can
based
[107,185,189,191,240] and non-topic modeling based approaches
[25,37,59,67,186,190,193,218,241,243].

topic modeling

divided

Moghaddam and Ester [185] devised factorized LDA (FLDA) to
extract aspects and estimate aspect rating from cold-start problem.
The cold-start term was taken from recommender system, where
on each product item, small amount of reviews were available.
They considered reviews inﬂuence too for both purposes. They
worked on multi-domain reviews taken from epinions.com, ama-
zon.com, tripadvisor.com, etc. FLDA-SVM yielded up to accuracy
of 86% for item categorization and an accuracy of 74% for review
rating on cold-start items from TripAdvisor. In future, item catego-
rization can be performed hierarchically. Wang et al. [189] pro-
jected two semi-supervised model viz. Fine-grained Labeled LDA
(FL-LDA) and Uniﬁed Fine-grained Labeled-LDA (UFL-LDA) to
extract aspects from reviews. The ﬁrst model was incorporated
with products seeding aspects taken from e-commerce site. The
second model was incorporated with unlabeled documents to con-
sider high-frequency words. Experiments were performed on
Wang et al. [187]. The qualitative results were evaluated using
cosine similarity between seeding aspect and generated aspects.
And, the quantitative results were evaluated using RandIndex,
Entropy, and Purity. In future, incorporating conceptual knowledge
into a topic model was required to capture aspect hierarchies.

Zheng et al. [191] incorporated appraisal expression pattern into
LDA (AEP-LDA) to extract aspect and sentiment. Appraisal expres-
sion pattern were captured using the shortest dependency path
between POS. The meaningfulness of pattern was decided using
conﬁdence score. Gibbs sampling was used for inference. Hotel,
restaurant, MP3 player and Camera reviews were collected for
experiments. AEP-LDA outperformed some other variants of LDA
for aspect identiﬁcation. AEP-LDA outperformed PMI and nearest
neighbor method for sentiment word identiﬁcation. The proposed
model can be extended for aspect-based review summarization
and clause level topic modeling. Xueke et al. [107] came up with

32

K. Ravi, V. Ravi / Knowledge-Based Systems 89 (2015) 14–46

a Joint Aspect/Sentiment model (JAS) to extract aspects. They devel-
oped aspect dependent sentiment lexicons. The lexicon has been
applied to a series of aspect-level opinion mining tasks viz. implicit
aspect identiﬁcation, aspect-based extractive opinion summariza-
tion and classiﬁcation. Sentiment prior was induced to Latent
Dirichlet Allocation (LDA) for topic extraction and subjectivity clas-
siﬁcation. Experiments were performed on restaurant reviews and
hotel reviews. MPQA, SentiWordNet, and union of them were uti-
lized as opinion lexicon. The proposed model outperformed other
two models
like MaxEnt-LDA and Aspect and Sentiment
Uniﬁcation Model (ASUM). SVM with linear kernel yielded promis-
ing result tor sentiment classiﬁcation. The proposed opinion lexicon
can be extended with embedded composite opinion words, syn-
onyms and antonyms, etc. Xu et al. [240] developed an implicit
aspect extraction model, which used LDA-based explicit topic
model and SVM. LDA was used to extract aspects, where a few
explicit aspects were assigned to different topics before applying
topic modeling. Explicit topic model was guided by two constraints
and relevance-based prior knowledge, which yielded training attri-
butes for SVM. Finally SVM was trained to classify implicit and
explicit features. They experimented with 14218 Chinese sentences
from www.360buy.com and yielded an F-measure of 77.78%. The
proposed method should be tested on bigger corpora and be devel-
oped for different domains and languages.

Kim et al. [186] formed a hierarchical aspect sentiment model
(HASM) to represent hierarchical structure of aspect-based senti-
ments. They extracted structure and parameters of the tree using
a Bayesian non-parametric model viz.,
recursive Chinese
Restaurant Process. Gibbs sampling was used for inference.
Experiments were performed on reviews on different product
and services. The proposed model outperformed three other mod-
els for small scale and large scale dataset for classiﬁcation purpose.
They found better hierarchical afﬁnity and aspect-sentiment con-
sistency than baseline methods, thereby demonstrating the power
of HASM. The proposed model can further be utilized to discover a
set of topics with shared features in a hierarchical structure. Zhang
et al.
[190] suggested context-based sentiment classiﬁcation
method. They incorporated CRF with several syntactic and seman-
tic features like similarity to neighboring sentences, word posi-
tions, comparative and superlative POS, conjunction terms,
+ve/ ve emotions, etc. Experiments were performed on 300 digital
camera reviews, 300 TV reviews, and 500 Facebook comments
from 13 walls. The proposed approach outperformed rule based
algorithm, SVM, LR, and HMM for camera reviews with an accuracy
of 72%. Sarcastic sentences can be included in the scope in future.
Chen et al. [37] compared the Conditional Random Fields (CRF)
based opinion mining method to four typical related methods: (a)
model based methods such as Lexicalized Hidden Markov Model
(L-HMM), (b) statistical methods like association rule mining based
(ASM)
rule-based
method on the basis of several opinion mining units: basic product
entities, opinions, intensiﬁers, phrases, infrequent entities, and
opinion sentences. Experiments were performed on Hu and Liu
[38] dataset containing 821 reviews on 9 digital cameras and in
addition to that authors collected 187 reviews of four extra digital
cameras. It has been observed that CRF-based learning method was
more suitable for mining aspects, opinions and intensiﬁers (includ-
ing phrases) in comparison to L-HMMs based and statistical meth-
ods. Visualization of opinion mining (OM) results and evaluation of
opinion extraction is required. García-Moya et al. [59] introduced a
language modeling framework for aspect-based summarization of
reviews. The framework combines a probabilistic model of opinion
words and a stochastic mapping between words. It estimates a uni-
gram language model of product features. Expectation–maximiza
tion (EM) was utilized to minimize the cross entropy, which was
based on background language model of the source language. To

(c) ASM + Linguistics, and (d)

techniques,

retrieve the product features,
iterative strategy was followed,
which starts with an initial list of features and expanded using
bottom-up strategy. A kernel-based density estimation approach
was utilized to learn the model of opinion words, which started
with a list of seed words from SenticNet. Experiments were per-
formed on 3 datasets: Hu and Liu [38], TBOD, TripAdvisor.
Training for opinion words was performed on Hu and Liu [38]36
for English and the fullStrengthLexicon for Spanish. The proposed
system outperformed
(a) Double
Propagation, and (b) Hyperlink-Induced Topic Search (HITS-based)
algorithm for aspects extraction. Integration of the proposed model
into a probabilistic topic-modeling framework can be performed.

baseline methods

two

Hai et al. [193] considered domain relevance of an opinion fea-
ture to identify opinion feature. They suggested intrinsic and
extrinsic domain relevance, which relies on threshold for disper-
sion and deviation calculated on the basis of TF-IDF weight. The
domain relevance formula was used for measuring inter-corpus
statistics disparity. Experiments were performed on Chinese
10,073 cellphone and 6313 hotel reviews. The proposed approach
outperformed other six methods for opinion feature extraction as
well as for feature-based opinion mining. In future, the proposed
approach can be modiﬁed to deal with infrequent features,
non-noun opinion feature, and multi-lingual corpora. Miao et al.
[25] developed a sentiment mining and retrieval system viz.,
AMAZING. AMAZING uses a novel ranking mechanism Temporal
Opinion Quality (TOQ) and relevance. This method can rank review
sentences, visualize opinion trends, and evaluation of a particular
feature. POS tagging was performed using NLProcessor. Rule asso-
ciation miner CBA was applied to extract frequent nouns aka fea-
tures. Opinions were extracted with respect to each feature using
dictionary based approach, which also yielded polarity and
strength. Lucene API was utilized to create index ﬁle of review sen-
tences. Review sentence rank was created using TOQ and Lucene
Rank, which was based on Vector Space Model. Experiments were
performed on product reviews on 20 digital cameras, 20 cell
phones, 20 laptops and 20 MP3 players taken from Amazon.com.
Average precision 87.4% was achieved on queries supplied by 8
participants. In future, implicit opinion and opinions expressed
with verbs are required to be extracted.

et

al.

Bagheri

[218] proposed an unsupervised and
domain-independent model
to extract explicit and implicit
multi- and single word aspects. In order to get candidate explicit
aspect list, they exploited four POS patterns based on nouns, adjec-
tives, determiners, and verb gerunds. The aspect list was further
expanded using bootstrapping algorithm. They ranked the
obtained aspects list by applying extended FLR (Frequencies and
Left and Right of the current word) algorithm. Pruning was per-
formed using PMI and frequency based A-scoring method, two
heuristic
subset- and superset-support based rules.
Moreover, graph based scoring method were employed to identify
implicit words, where a pre-deﬁned aspects and related opinion
words were represented using nodes. They experimented with
more than 2400 reviews on ﬁve gadgets collected from ama-
zon.com and cnet.com and yielded an average precision of
84.52%. The proposed approach outperformed Wei et al. [219]
and Hu and Liu [38]. They proposed to augment the proposed
method with clustering in order to extract explicit and implicit
aspects and opinions.

rules,

Quan and Ren [67] coined a novel similarity measure,
PMI-TFIDF, to identify association between products and its
aspects. They performed aspect-level SA based on aspect-opinion
pair extraction and aspect oriented opinion lexicon generation.
Experiments were carried out on 10 datasets, where 4 have been

36 www.cs.uic.edu/liub/FBS/opinion-lexicon-English.rar.

K. Ravi, V. Ravi / Knowledge-Based Systems 89 (2015) 14–46

33

taken from Hu and Liu [135]. For feature extraction, the proposed
method outperformed that of Hu and Liu [135], Popescu and
Etzioni [143], Qiu et al. [145] for 4 datasets and yielded more than
89% recall. For sentiment classiﬁcation, three hybrid models were
proposed, where 2 hybrid models were based on PMI and TF-IDF
that outperformed third model GI-SVM (with polynomial kernel).
Aspect based ontology generation is claimed as future work. Yan
et al. [241] developed EXPRS (an Extended PageRank algorithm
enhanced by a Synonym lexicon) to extract product features. In
order to extract features, they extracted nouns/noun phrases ﬁrst,
and then extracted dependency relations between nouns/noun
phrases and associated sentiment words. Dependency relations
included subject-predicate relations, adjectival modifying rela-
tions, relative clause modifying relations, and verb-object rela-
tions. The list of product
features was extended using its
synonyms. Non-features nouns were removed on the basis of
proper nouns, brand names, verbal nouns and personal nouns.
They experimented with 8901, 11,291, and 9000 reviews on
Samsung GalaxyNote II, Canon EOS 600D, and Philips DVP3600
respectively. In terms of results, they achieved an F-measure of
76.2%, 73.0%, and 72.7% on Samsung GalaxyNote II, Canon EOS
600D, and Philips DVP3600 respectively and in the process outper-
formed Eirinaki et al. [154] and HITS based algorithm Zhang et al.
[242]. Their method does not deal with implicit features, on which
sentiments are expressed without specifying a product feature
name in the reviews. Li et al. [243] augmented frequency-based
extraction and PMI-IR in order to extract product aspects. In order
to identify frequent aspects from the dataset, they employed
Apriori algorithm and they removed useless rules using compact-
ness and redundancy rules. To ﬁnalize the number of relevant
aspects they applied location based ordering and similarity i.e.
PMI-IR based ﬁltering. In order to classify the extracted aspects
into aspects and non-aspects category, they applied RCut with
threshold value of 1 on PMI-IR score. They experimented with
120 reviews for nine categories of products, achieved an average
F-score of 73.3% and outperformed Popescu and Etzioni [143]. In
future, extraction of infrequent aspects can be performed.

3.6.2.2. Ontological approaches. Quality of a product is fully depen-
dent on its aspects’ quality. In turn, aspects will be qualiﬁed by
their various attributes. Hence, we can say that products and
aspects are hierarchically related. In order to capture this relation-
ship, ontological approaches proved helpful. And, it yielded better
sentiment classiﬁcation accuracy over non-ontological approaches
[35]. Therefore, some of initiatives taken by SA community are pre-
sented in this section.

Liu et al. [62] automatically constructed fuzzy domain senti-
ment ontology tree (FDSOT) based on the product features and sen-
timent words. FDSOT was used further for feature based sentiment
classiﬁcation. They exploited 2400 product reviews for laptops
from 360buy.com to create FDSOT using double propagation
method. They achieved a precision of 72.4% compared to 58.4%
without FDSOT. To improve the effectiveness of the proposed
method, feature relation, discourse analysis can be considered.
Lau et al. [182] enacted an ontology learning system for contextual
aspect-level SA. They generated ontology in two phases: in the ﬁrst
phase implicit and explicit aspects ontology was generated. In the
second phase contextual sentiment words for each aspect was pre-
sented in the ontology form. They extracted implicit and explicit
aspects using LDA and Gibbs sampling methods. They created
ontology for several domains. The proposed ontology quality was
compared against Text-to-Onto based ontology. They reported
11.6% better sentiment classiﬁcation accuracy than that obtained
by OpinionFinder. In future aspect-oriented SA can be conducted.
Mukherjee and Joshi [194] focused on sentiments aggregation
technique using ontology considering 4 level hierarchical

relationships. They assigned high weight to the aspect occurring
at higher level and low weight at lower level. Ontology was con-
structed with the help of ConceptNet 5 ontology. Liu [38] lexicon
was used to decide the subjectivity of a word. They collected
584, 986, and 1000 reviews on automobile, camera and software
respectively. They further devised a Phrase annotated Author
Speciﬁc Sentiment Ontology Tree (PASOT) based on an existing
movie ontology [195]. Ontology was mapped to WordNet based
similarity measure. They aggregated the node polarities using
bottom-up approach to get overall review polarity. They experi-
mented with Pang and Lee [33] dataset. The proposed approach
outperformed other 11 approaches and achieved an accuracy of
7.55% over SVM classiﬁer. Outlined technique can be applied for
other domain as well.

Zhou and Chaovalit [196] manually developed a movie ontology
for polarity mining. Conceptual properties were derived by two
persons by analyzing 180 movie reviews from IMDb.com. They
applied maximum likelihood estimation for bi-gram modeling.
The performance of bi-gram modeling were compared with that
of GI based technique. Further experiments should be carried out
on new domains and larger dataset. Peñalver-Martinez et al. [35]
enacted a methodology to perform aspect-based SA of movie
reviews. To extract the movie features from the reviews, they uti-
lized a domain ontology viz., Movie Ontology. Different relative
sentiment score has been assigned to a movie feature according
to its appearance in the review viz. beginning, middle, and end.
SentiWordNet was utilized to calculate the sentiment score. For
the experiment, they exploited Pang and Lee [167] movie dataset
to create the domain ontology. The proposed method yielded clas-
siﬁcation accuracy of 89.6%.

3.6.3. Relation extraction

Detection of relation between entities is useful for the compet-
itive intelligence. Xu et al. [93] developed a CRF based model to
extract comparative relations from customer reviews. Relation
extraction was performed in three stages: (i) entities viz., product
name and attributes were recognized using a developed lexicon of
mobile phone names and attributes, (ii) a graphical model was
developed using CRF to model the dependencies between relations
and entities (iii) then, the belief propagation algorithm was applied
with unﬁxed interdependencies. Experiments were performed on
1348 reviews on 33 types of mobile phones collected from various
sources. CRF with/without
interdependencies outperformed
multi-class SVM. The proposed model should be tested on large
scale dataset on different domains. The model can be extended
to jointly recognize the comparative relations so as to reduce the
errors accumulated in the pipeline errors.

3.6.4. Named entity recognition and name disambiguation in micro-
blogs

Named entity recognition and name disambiguation are widely
studied on long text, while micro-text based study is also gaining
importance. Noisy and short contents of micro-blog make this task
harder. Hence, it is an essential task to recognize an entity dis-
cussed in the comment. In this regard, Jung [60] considered named
entity recognition (NER) system for streaming micro-text. It was
based on different contextual associations like semantic associa-
tion,
temporal association, and social association between
micro-text clusters. Four types of entity classes namely persons,
organizations,
exploited.
Maximum entropy approach-based NER method has been applied
to determine the micro text clusters. On the basis of manually col-
lected training sets, the proposed NER system detected the named
entities from the text streams online.

and digital

locations,

IDs were

Spina et al. [101] developed an algorithm for company name dis-
ambiguation from tweets. They extracted ﬁlter keywords from

34

K. Ravi, V. Ravi / Knowledge-Based Systems 89 (2015) 14–46

micro-blogs that did not use any previously annotated data about
the target company. A positive/negative ﬁlter keyword, if present
in a tweet, indicates high probability that the tweet was related.
Filtering was performed manually as well as using C4.5 decision
tree classiﬁer. For automatic ﬁlter keyword identiﬁcation, three
hybrid
collection-based,
web-based and features expanded with co-occurrence have been
applied. Experiments were performed on WePS-3 Online
Reputation Management Task dataset
i.e. TREC Micro blog
Track37 using NN, C4.5 and CART Decision Trees, Linear Support
Vector Machines and NB. In future, cross-lingual strategies should
be employed.

selection methods

feature

like

3.7. Various applications of opinion mining

SA is in its infancy stage, as far as the real life applications are
concerned. It has been tried in various areas like business intelli-
gence, market prediction, attrition prediction, etc., which will be
reviewed now.

3.7.1. Market and FOREX rate prediction

[34]

Bollen et al. [18] studied market prediction by augmenting twit-
ter sentiment to ﬁnancial data. For the analysis of the twitter con-
tent, two mood tracking tools were utilized, namely OpinionFinder
(OF)38
that measures positive vs. negative mood, and
Google-Proﬁle of Mood States (GPOMS) that measures mood in
terms of 6 dimensions viz. Calm, Alert, Sure, Vital, Kind, and
Happy. In total 7 public mood time series were utilized. For the anal-
ysis, 9,853,498 tweets by approximately 2.8 million users during 28
February 2008 to December 2008 and a time-series of daily Dow
Jones Industrial Average closing-values from Yahoo! Finance were
collected. To evaluate the effectiveness of OF and GPOMS time series,
experiments have been performed on U.S Presidential election and
Thanksgiving and which yielded promising result. So, the daily time
series obtained by OF and GPOMS were applied on DJIA using econo-
metric technique of Granger causality analysis, which shows that
there was predictive relation between certain mood dimensions
and DJIA. The relation between public mood and stock market values
was almost certainly non-linear, while Granger causality analysis
was based on linear regression. Therefore, to address this issue bet-
ter, Self-organizing Fuzzy Neural Network (SOFNN) was utilized to
predict DJIA values on the basis of two sets of inputs: (a) 3 days of
DJIA values, and (b) the same combined with various performance
of the obtained time series.

Qiu et al. [80] exploited wisdom of crowds approach to predict
the market. It was based on the assumption that information and
knowledge in social systems frequently exist only as dispersed
opinions, and that aggregating dispersed information. A theoretical
model of network prediction market was set up, which frames a
two-stage network game. In the ﬁrst stage, information acquisition
was performed by an agent. In the second stage, agent makes use
of her information to choose the optimal demand for the risky
asset. Random social network with 100 agents in the form of
100  100-dimensional matrix was utilized. Pari-mutuel betting
mechanism was utilized for twitter based market prediction.
Future work is claimed as to test whether participants in the same
local structure exhibit similar bets and prediction performance.

Yu et al. [124] investigated the effect of social media and
conventional media, their relative importance, and their interrelat-
edness on ﬁrm performances. For the experiments, the ﬁnancial-
statement and ﬁnancial-market data for the 824 companies from
COMPUSTAT and the Center of Research in Security Prices (CRSP)

37 https://sites.google.com/site/microblogtrack.
38 http://www.cs.pitt.edu/mpqa/opinionﬁnderrelease/.

was recorded. These data help them to construct measures of
abnormal returns and cumulative abnormal returns. Naïve Bayes
was trained on Pang and Lee [167] dataset for binary sentiment
classiﬁcation system and achieved up to 86% F1. They found several
observations like overall social media has a stronger relationship
with ﬁrm stock performance than conventional media, both media
were interrelated, etc. Future work could be to explore the tone of
the messages in various media sources, and to study the extent of
sentiment among the general public as compared to sophisticated
media practitioners. Nassitoussi et al. [183] proposed to predict
intraday directional movements of a currency-pair in the foreign
exchange market. Contributions were made in many folds for text
mining and market prediction. They used SentiWordNet to get sen-
timent score, WordNet to get hypernyms, TF-IDF to get weight of a
term and SVM for sentiment classiﬁcation of news headlines. They
collected ﬁnancial news from MarketWatch.com and foreign
exchange historic data in the form of Euro/USD. Evaluation was
performed for heuristics-hypernym feature-selection, TF-IDF sum-
score, synchronous targeted feature-reduction, and machine learn-
ing algorithm. SVM outperformed NB and KNN and yielded an
accuracy of 83.33%. The proposed method can be tried for other
market prediction purposes as well.

Li et al. [184] performed intra-day market prediction. They rep-
resented news articles in the form of vector space model, which
was multiplied by sentiment word matrix. Each headline was
labeled with intra-day return. They performed 3-class classiﬁca-
tion of news (+ve,  ve, and neutral) using SVM. For the experi-
ment, news articles were collected from Hong Kong ﬁnancial
news archive during January 2003 to March 2008. And stock daily
quotes were collected from Yahoo! Finance for the same period.
Comparisons were performed between stock, index and sector
level for the validation and testing purposes. Accuracy achieved
up to 69.68% for testing. In future, relationship between news
impact and intra-day stock price return can be analyzed. Geva
and Zahavi [53] performed a systematic evaluation of the effective-
ness of augmenting market-data with textual news-based data for
intraday stock recommendation decisions. Dataset were obtained
from the New York Stock Exchange (NYSE) Trades Quotes (TAQ)
database for 50 sell and purchase companies, and 51,263 news
items from ‘Reuters 3000’. A feed forward neural network algo-
rithm, decision trees involving a genetic algorithm, and stepwise
logistic regression were trained on dataset. They utilized double
scoring approach for positive and negative model to reduce predic-
tion biases and rule-based expert system for feature selection.
Some other classiﬁers and hybrid models can be tried on textual
and market data for better accuracy.

3.7.2. Box ofﬁce prediction

Yu et al. [155] mentioned a novel approach to sentiment mining
based on Probabilistic Latent Semantic Analysis (PLSA), which was
called as Sentiment PLSA (S-PLSA). Autoregressive (AR) model was
employed to capture the past performance of same movie. A com-
bined form of S-PLSA and AR was proposed and known as
Autoregressive Sentiment and Quality Aware (ARSQA) model for
sales prediction. For the purpose of feature selection, the authors
took 2030 appraisal words from the Whitelaw et al. [169] lexicon.
To determine the helpfulness of a review, e-Support Vector
Regression with Radial Basis Function (RBF) kernels was utilized
to learn the relationship between vector of features and the quality
of reviews. Experiments were performed on movie blogs along
with helpfulness score collected on two movies, one month box
ofﬁce revenue data from IMDb, and 45,046 blog entries. The pro-
posed model yielded the least Mean Average Percentage Error
(MAPE) values in comparison to other competitive model. S-PLSA
can be tried for clustering and classiﬁcation of reviews based on

K. Ravi, V. Ravi / Knowledge-Based Systems 89 (2015) 14–46

35

sentiments. It can be used to track and monitor sentiment pattern
expressed online.

Du et al. [51] accomplished micro-blogs based box ofﬁce predic-
tion using two features: count and content based features. Count
based features considers several factors like quantity and quality
of users, inﬂuence of expert users to other users, and time based
factors. The content based features label the comments into 3 cat-
egories: beneﬁcial, harmful and neutral. 3000 Chinese micro-blogs
on 17 movies were labeled for the training purpose. Experiments
were performed on 24 movies’ box ofﬁces collected from
Entgroup box ofﬁce and 120,413 microblogs from 68,269 users
from Tencent micro-blog. Different combinations of 5 feature
selection methods were applied, where chi-square test plus subse-
quence using unigram representation yielded the best result. NN
outperformed linear model and SVM with linear kernel for classiﬁ-
cation with lowest MAPE value. Improvement can be made to the
proposed method by considering the relationship among users. Rui
et al. [131] analyzed twitter sentiment to predict the movies sales.
They introduced the pre-consumption concept of product sales,
instead of post-consumption. Experiments were performed on
movie sales data from BoxOfﬁceMojo.com, 4,166,623 tweets on
63 movies along with different author’s proﬁle. SVM was utilized
for subjectivity classiﬁcation and NB was utilized for sentiment
classiﬁcation of tweets. Training for both classiﬁers was performed
on 3000 tweets, which were manually labeled. For movie sales pre-
diction, intention tweets ratio (%), positive tweets ratio (%), nega-
tive tweets ratio (%) were utilized as explanatory variables. The
number of followers of a Twitter user was considered as a variable,
which should be replaced by Twitter user’s personal inﬂuence.

3.7.3. Business analytics

Coussement and Van den Poel

[77] considered emotions
expressed in client/company emails to be incorporated in a churn
prediction model for a newspaper subscription business. For the
experiment, 18,331 e-mails from a Belgian newspaper have been
purchased. Linguistic Inquiry and Word Count (LIWC) [28] was uti-
lized to create a list of 690 positive words and 1347 negative
words, that helps in classifying the contents of emails either in pos-
itive or negative category. Logistic Regression (LR), Support Vector
Machine (SVM), and RF had been utilized for sentiment classiﬁca-
tion. RF outperformed other two classiﬁers. In future, the proposed
framework can be utilized for different kind of business applica-
tions like cross- and up-sell applications, customer acquisition in
wide range of industries, e.g. retail, ﬁnance, services, e-commerce,
etc.

Kang and Park [158] assessed and visualized the customer satis-
faction in mobile service using a combination of SA and VIKOR
approaches. Experiments were performed on 1487 reviews from
AppStore HQ collected on 8 mobile application services i.e. alterna-
tives. Dictionary based approach (proposed in [13]) was utilized for
sentiment score calculation with respect to common eight aspects
or criteria of mobile applications. Here, VIKOR multi-criteria deci-
sion making method was utilized for ranking of different mobile
services. Maximum group utility and individual regret values were
plotted to visualize customer satisfaction towards various alterna-
tives and criteria. In future, basic SA technique should be replaced
by some more advanced techniques. Comparative analysis with
some other multi-criteria decision making methods can be carried
out.

3.7.4. Recommender system

Li and Shiu [43] developed a recommender system for social
advertising over microblogs. They exploited various features like
structure of relationship, content popularity, social activeness,
social interactions, social similarity, click through rate, etc. These
features helped them to get a list of targeted users for each

endorser at the current stage, and suitable paths for information
diffusion. On the basis of that, they produced a recommended list
of targeted users for endorsing an advertisement. For the experi-
ment, they collected 247,099 users and their 1,969,253 plurks,
responses and interactions. Incorporating other tangible factors
and dynamic modules into the mechanism may improve the qual-
ity of the system.

Garcia-Cumbreras et al. [79] projected a novel application of SA
in recommender system by categorizing users according to the
average polarity of their comments. At ﬁrst they justiﬁed the rela-
tion between comments and ratings. And, they incorporated this
knowledge to the recommender system. Two groups of users, opti-
mists and pessimists, have been created for collaborative ﬁltering.
SVM outperformed on KNN for rating calculation and KNN with
K = 80 has yielded the least error for rating prediction. For the
experiment, they collected user’s ratings and user’s comments on
2713 movies, 54,112 users, and 80,848 opinions from IMDb. The
proposed system can be improved with a higher level of integra-
tion, changing the between-items and between-users similarity
in the core of collaborative ﬁltering algorithms. Bao et al. [49] pro-
posed a temporal and social probabilistic matrix factorization
model to predict user’s future interests. They integrated users’
friendships and users’ historical interests in micro-blogging sites.
They utilized Sina-wiebo posts on 2788 topics by 1170 users
posted during 15 days, where the last day’s data was utilized for
testing the model. Automatic tuning of parameters like number
of users can be performed using MCMC algorithm. Some other
effective factors can enhance the performance of the proposed
model like re-tweeting relationship and discussions among users.

3.7.5. Marketing intelligence

Market intelligence is designed to fulﬁll four needs of business
managers like (a) opportunities and threat determination, (b)
knowing competitors, (c) help preempt competitors’ actions, and
(d) aid effective marketing decision making. In this regard, Li and
Li [90] framed a framework for market intelligence with the help
of different tasks like trendy topic detection, opinion classiﬁcation,
credibility assessment, and numeric summarization. The ﬁrst task
was performed by assigning topic tendency score with the help
of term frequency,
inverse document frequency, and patterns
appear in a term. The second task was performed in two phases
(a) subjectivity classiﬁcation based on self developed lexicon and
(b) sentiment classiﬁcation using SVM with RBF Kernel and NB
with emoticons, unigram, bigram, unigram + bigram, and subjec-
tive word set as feature representation. Third task was credibility
calculation based on follower–followee ratio. Finally, semantic
score and the credibility score have been aggregated under
numeric summarization task. For the experiment, follower and fol-
lowee relationship and tweets on three brands viz. Google,
Microsoft, Sony, for three products namely iPhone, iPad, and Mac
book have been collected from Twitter. For the training, 11,929
tweets have been collected with two emoticons ‘‘:)’’ and ‘‘:(’’,
SVM and NB have been trained on 9165 preprocessed tweets.
SVM outperformed NB and unigram feature representation domi-
nated other alternatives. So, improvement can be made by consid-
ering meronym patterns, PageRank consideration for
the
credibility assessment, etc.

3.7.6. Other applications

Fortuny et al. [47] analyzed the media coverage in time of polit-
ical crisis on various topics in Belgium. They analyzed 68,000 arti-
cles covered in 8 newspapers. Pattern mining module of Python
was utilized as subjective lexicon containing 3000 Dutch adjectives
with polarity values. To calculate sentiment score for each opinion
word related to political party, a window of 5 sentences have been
analyzed. The frequency of occurrence and the tone of articles have

36

K. Ravi, V. Ravi / Knowledge-Based Systems 89 (2015) 14–46

been considered for bias and SA. The amount of ranking difference
of each newspaper was calculated using Hamming distance, which
gives the degree of disagreement between the consensus rankings.
Sentiment of newspapers towards a political party was visualized,
where 30–40% coverage was negative. The proposed approach can
be tried for different dataset. Moreo et al. [13] devised a linguistic
modularized model with low-cost adaptability for news focus
detection. It can deal with views expressed in non-standard lan-
guage and target detection in a multi-domain scenario. They cre-
ated a taxonomy of objects and features by analyzing 250 news
items. Here, each word has been characterized using polarity and
strength. They divided the whole task into three parts (a) prepro-
cessing, (b) focus identiﬁcation and sentiment classiﬁcation, and
(c) summary mining. For focus identiﬁcation, they considered the
most recurrent discussion topics. Sentiment classiﬁcation module
exploited colloquial
language and multi-word expressions.
Experiments were performed on randomly selected 500 current
news items on different topics achieving an accuracy of 89%.
Though the proposed taxonomy is in initial stage, it can be easily
extended with the concepts of new corpora.

Mohammad [64] studied the distribution of emotion words in dif-
ferent texts like e-mails (love letters, hate mail, and suicide notes),
books, fairy tales, novels, etc. For this, he exploited the Roget the-
saurus to create word-emotion association lexicon NRC Emotion
Lexicon. Relative Salience (RS) was calculated to compare emotion
expressed by different terms. RS is a ratio between the frequencies
of words associated with a particular emotion to the total number
of emotion words in whole text. Four e-mail corpora (a) love letters
corpus (LLC) v 0.1,39 (b) hate mail corpus (HMC) v 0.1,40 (c) the sui-
cide notes corpus (SNC) v 0.1,41 (d) Enron email corpus42 were
exploited. For novels and fairy tales Corpus of English Novels
(CEN) and the Fairy Tale Corpus (FTC)43 have been exploited. This
study can help users to understand writing style of different authors
in emotional point of view. Li and Wu [91] performed online forums
hotspot detection and forecast in two stages. At the ﬁrst stage, emo-
tional polarity was computed. At the second stage, K-means cluster-
ing and SVM have been applied to group the forums into various
clusters. For the experiment 220,053 posts have been collected on
31 different topics from Sina sports forums.44 To determine the
polarity of the forums, HowNet;45 a Chinese sentiment dictionary
have been exploited. With the help of the dictionary eight word lists
with different emotional intensiﬁers have been created: positive,
negative, privatives, and ﬁve lists of modiﬁers. K-means clustering
have been applied with K = 31, i.e. 31 leaf forums, while SVM has
been applied in the sliding time window manner. For each SVM,
the input was a matrix containing 31 leaf forums’ representation
vectors, and the output was a vector containing 31 integer values
either 1 (hotspot) or 0 (non-hotspot). SVM achieved highly consis-
tent results with K-means clustering. And, the top 10 hotspot forums
listed by SVM forecasting resembles 80% of K-means clustering
results. In future, topic extraction is to be included to pop the ques-
tion what event or topic triggered the user attention.

Desmet and Hoste [58] performed emotion detection in suicide
notes. They detected ﬁfteen types of emotions expressed in suicide
notes. Experiments were performed on 1319 suicide notes col-
lected between 1950 and 2011 (total 900 notes: 600 for training
and 300 for testing). SVM was used for binary classiﬁcation.

39 LLC: http://www.lovingyou.com/content/inspiration/loveletters-topic.php?ID=
loveyou.
40 HMC: http://www.ratbags.com.
41 SNC: http://www.well.com/art/suicidenotes.html?w.
42 http://www-2.cs.cmu.edu/enron.
43 CEN: https://perswww.kuleuven.be/u0044428/cen.htm. FTC: https://www.l2f.
inesc-id.pt/wiki/index.php/Fairy_tale_corpus.
44 http://bbs.sports.sina.com.cn/treeforum/App/list.php?bbsid=33&subid=0.
45 http://www.keenage.com/download/sentiment.rar.

Bootstrap sampling was performed to determine threshold to max-
imize F-score for each classiﬁer. Suicide note content analysis can
help in suicide prevention and forensic linguistics and can be
applied for prediction of suicidality in the text. Favorability
Analysis (FA) determines how favorable an article is with respect
to an entity and how much a client interested in that entity. FA
determines sentiment polarity along with favorable objective men-
tions of entities. Lane et al. [73] applied opinion mining for favor-
ability analysis (FA). Data were represented by unigrams, bigrams,
trigrams, entity words and dependency words. Data imbalance was
managed at training time using under sampling and at evaluation
time by modifying the output threshold. Three datasets collected
from newspapers and magazines were utilized for the experiment;
out of them two were on high-tech companies and one was on a
charity trust. Different classiﬁers viz. NB, SVM, JRip, RBF, and
Random were trained with different settings. Experiments were
performed for pseudo-subjectivity and pseudo-sentiment classiﬁ-
cation tasks. For pseudo-subjectivity, SVM outperformed all other
alternatives with cross validation accuracy of 91.2%. For
pseudo-sentiment NB was reported as the best classiﬁer. In future,
proposed approach can be applied on social media.

4. Discussion

This study reviews many interesting and useful works regarding
the state-of-the-art in SA. The paper is organized on the basis of
tasks, approaches and applications of SA as presented in Fig. 1. If
we consider granule based sentiment analysis, most of the studies
focused on document and sentence level as presented in Table 1.
Here, document refers to product reviews, blogs, forums, biogra-
phy, news, news comments,
tweets, plurks, Facebook and
Sina-Wiebo comments, etc. Concept refers to a class or category
in ontological engineering. Phrase is a special combination of two
or more words. Link based studies were carried out in opinion
extraction from social networking while clause level studies dealt
with conditional sentences. In order to compare two or more prod-
ucts we need to perform ﬁne-grained sentiment analysis. Table 1
indicates that more investigation is required at ﬁner-grained level
SA.

Subjectivity classiﬁcation had been addressed in very few stud-
ies as presented in Tables 2 and 3. Out of various sub-tasks of sen-
timent analysis, subjectivity classiﬁcation is more challenging task
than sentiment classiﬁcation. The highest subjectivity classiﬁca-
tion accuracy achieved on Pang and Lee [167] dataset was 92.1%
by Xuan et al. [174], which was minor improvement over 92% by
Pang and Lee [167] as presented in Table 4. Here, Xuan et al.
[174] followed lexicon based approach and Pang and Lee [167]
adopted machine learning based approach. Therefore, we infer that
both approaches are competitive to each other for subjectivity
classiﬁcation. Recently, Maks and Vossen [24] came up with differ-
ent kind of subjectivity classiﬁcation such as epistemic subjectivity,
speaker subjectivity, and character subjectivity. They employed a
professional linguist to detect such kind of subjectivity. For this
purpose, machine learning can be employed to automate the
process.

Table 3 indicates that majority of works have been carried out
in sentiment classiﬁcation. In polarity determination, machine
learning based approach [156] dominated other hybrid [112] and
lexicon based approaches
[169] as presented in Table 5.
Similarly, for Pang et al. [33] dataset, hybrid approach [109] dom-
inated lexicon based approaches [165]. For sentiment classiﬁca-
tion, various
semantic, and statistical
approaches were employed to select most relevant features.
These approaches have been proved to be powerful and conse-
quently, sentiment classiﬁcation accuracy has improved to 92%

types of

syntactic,

K. Ravi, V. Ravi / Knowledge-Based Systems 89 (2015) 14–46

37

Table 6
Distribution of articles based on intelligent techniques applied.

Applied techniques

#Articles

Articles’ references

SVM

Dictionary based approaches (DBA)

NB
NN
DT
Maximum entropy
Logistic regression
Linear regression
Ontology
LDA
Random forest
SVR
CRF and rCRP
Boosting
SVM-SMO
Fuzzy logic
Rule miner
EM
K-medoids
RBF NN

55

41

28
11
9
8
9
8
8
8
4
5
5
4
4
3
4
3
1
1

[21,26,29,33,44–46,50,51,53,54,57,58,66,67,73,76,77,86,88,90,91,94,95,97,101,108,109,111,114,116,118,125,131,
148,157,160,163,165,167,169,172,176,177,183,195,197,200,209,210,212,214,225,228,240]
[13,18,23–25,35,36,47,55,64,67–69,85,96,110,112,117,126,127,158,170,171,175,183,193–196,202,203,
206,207,209,210,213,216,218,220,229,241]
[33,46,50,54,56,73,80,86,90,94,98,101,111,114,116,118,121,124,125,131,148,156,163,167,197,209,217,228]
[48,50–53,57,76,101,116,213,226]
[53,66,73,76,86,94,116,118,209]
[33,46,54,60,63,66,148,156,174]
[53,77,88,99,116,118,163,197,220]
[8,18,70,75,222–224,231]
[30,41,62,98,182,194–196]
[61,92,107,185,189,191,182,240]
[77,81,228,210,228]
[118,123,130,155,227]
[37,88,93,186,190]
[12,118,179,197]
[76,97,118,169]
[23,41,62,213]
[37,100,112,217]
[56,59,155]
[52]
[130]

Table 7
Year wise distribution of articles.

Year

2002
2003
2004
2005
2006
2007
2008
2009
2010
2011
2012
2013
2014
2015

#Articles

Articles’ references

2
1
3
2
2
1
4
8
5
25
27
42
33
5

[32,33]
[171]
[167,172,173]
[12,169]
[170,178]
[168]
[130,160,180,196]
[25,29,46,77,88,112,121,132]
[45,91,116,166,223]
[18,26,30,44,48,54,55,63,69,74,78,81,89,93,109,114,117,156,175–177,179,212,225,231]
[8,11,13,24,27,37,43,47,56,60–62,64,73,86,92,95,111,118,125,154,155,162,174,221,222,229]
[21–23,40,41,49–53,57–59,66,68,70,76,80,85,90,94,96–101,107,110,123,124,126,127,131,148,157,158,185,186,200,218,224]
[35,36,67,75,108,163,165,182–184,189–191,193–195,197,202,203,205–207,209–211,213,214,216,217,220,226,227,232]
[199,228,240,241,243]

[109] from 88.9% [33]. A lot of work still remains to be done for
polarity determination. Moreover, we found very limited amount
of study on other sentiment classiﬁcation sub-tasks like vagueness
resolution in opinionated text, multi-lingual and cross-lingual sen-
timent classiﬁcation, and cross-domain sentiment classiﬁcation.
Machine
for
cross-lingual sentiment classiﬁcation, which requires some extra
effort and time [148,173]. These sub-tasks need to be investigated
at a wider scale in order to have global discussion on common
issues and exchange of views worldwide.

translation based approaches

are

successful

In the cut-throat competition of e-commerce industry, nowa-
days, customer reviews are playing a quintessential role. The pro-
motion of quality product can be affected by bad quality reviews
and opinion spam. Projecting quality reviews, whether positive
or negative, can save customers’ time and effort to get quality
products. For review helpfulness measurement, various features
like lexical similarity features, shallow syntactic features, helpful-
ness votes, subjectivity clues have been exploited. From the cur-
rent study, we found that machine learning models yielded
better results than vote count based measures. Moreover, content
based review quality measurement is more reliable than vote
counts. As regards lexicon creation, non-standard text and spelling
are in rampant use for sentiment expression [116–118,127]. At

another level, sentiment lexicons were constructed using ontology
based approaches [21,23,30,52,106,120,199] to capture semantic
relationships between opinion words and represent commonsense
knowledge [95,106,120]. Aspect level SA requires capturing the
opinion effect of different aspects at various levels. Therefore, some
initiatives were taken to address hierarchical relationship among
product and its aspects [186,195,197]. Further, ontology proved
to be useful for the same purpose [35,62,182,194,195,197].

From Table 6, it is glaringly evident that SVM is the most often
applied technique for various tasks. SVM yielded the best accuracy
in most of the studies, except in [52,54,57,197]. This is because SVM
is eminently suitable for solving high dimensional problems com-
pared to other techniques. However, there are a few exceptions as
follows: Neural network outperformed SVM in [52,54,57], while
Bayesian boosting outperformed SVM in [197]. As regards kernel
of SVM, linear kernel was found to be widely employed except in
[29,67,90,97,155], where, Gaussian kernel was employed in [29];
Polynomial kernel was used in [67,97] and RBF kernel was used
in [90,155]. Further, a tree kernel was developed in [177]. Naive
Bayes with little modiﬁcation performed well for document classi-
ﬁcation [44,121]. A sentiment lexicon is quite relevant for senti-
ment
It yielded promising performance for
sentiment analysis [13,158]. Among non-parametric approaches,

classiﬁcation.

38

K. Ravi, V. Ravi / Knowledge-Based Systems 89 (2015) 14–46

Table 8
Number of articles published (and reviewed here) in different journals.

S#

1
2
3
4
5
6
7
8
9
10
11
12
13
14
15

Name of journals

#Articles

Expert Systems with Applications
Decision Support Systems
Knowledge-based Systems
IEEE Intelligent Systems
IEEE Transactions on Knowledge and Data Engineering
IEEE Transactions on Affective Computing
Information Sciences
Information Processing and Management
Computer Speech and Language
Communications of the ACM
Journal of Computer Science and Technology
Journal of Informetrics
Information Retrieval
Computer Speech and Language
Inf. Retrieval

33
28
17
12
6
3
3
3
2
2
2
2
2
2
1

modiﬁed latent dirichlet allocation (LDA) has been mostly
employed for aspect extraction. This helps us draw several conclu-
sions as presented in Section 5.

Table 7 presents year wise distribution of articles considered for
this systematic literature review. From Table 7, it is quite evident
that research in SA proliferated during 2011–2015. The number
of articles published in some notable journals is presented in
Table 8, which indicates that Journals such as ‘‘Expert Systems with
Applications’’ and ‘‘Decision Support Systems’’ published maxi-
mum number of research papers since research in SA became pop-
ular. Table 9 presents a list of available public dataset for sentiment
analysis. Table 10 listed some attributes of one hundred and
sixty-one articles which were considered for review. The ﬁrst col-
umn contains the reference number. The second column repre-
sents techniques utilized, while the third column represents the
degree of polarity (if applicable) considered, the fourth column
shows the language of corpora exploited for experiments, the ﬁfth
column shows the name of the corpora, and the last column pre-
sents the name of lexica (if utilized). Some abbreviations used in
Table 10 are: English (E), Dutch (D), Chinese (C), Spanish (S),
Turkish (T), Cantonese (CT), Romanian (R), Belgian (B), Arabic (A),
Japanese (J), Italian (I), French (F), German (GE), Product Reviews
(PR), Movie Reviews (MR), Micro-blog (MB), Global domain (G),
Restaurant Reviews (RR), Dictionary Based Approach (DBA),
SenticNet (SN), WordNet (WN), ConceptNet (CN), WordNet-Affect
(WNA), and Bing Liu Opinion Lexicon (OL).

4.1. Open issues/future directions

We now list out the open issues in several aspects of sentiment

analysis.

 Data collected from various resources are often so much noisy,
wrongly spelt and unstructured. There is no automatic system
for spelling correction and noise removal. Preprocessing step
consumes maximum time to convert raw data into a structured
format. For instance, tweets and plurks often contain abbrevia-
tions with high percentage. Even though we have a sort of acro-
nym dictionary like netlingo,46 twittonary,47 urbandictionary,48
etc. to deal with acronyms, they do not contain emerging slangs.
So, data preprocessing is the most time consuming activity and
prone to less accuracy.

 There is a lack of universal opinion grading system across sen-

timent dictionaries.

46 http://www.netlingo.com/.
47 http://www.twittonary.com/.
48 http://www.urbandictionary.com/.

 Online discussion and political discussions often contain irony
and sarcastic sentences [181]. Moreover, Irony and sarcastic
words vary from language to language. Little or no studies have
been devoted in this regard. In order to deal with irony and sar-
casm detection, more computational approaches are needed to
be developed on the basis of appraisal theory.

 For better product comparison, we should compare a set of
products with respect to their common aspects (also known
as product features). For that, we need to identify aspects dis-
cussed in the given text and explicit opinionated sentences
written for the corresponding aspect. Topic modeling based
approaches address this issue to some extent but it requires big-
ger corpora to be trained on. Therefore, a lot of work remains to
be done along this line.

 Machine learning provides automated learning systems to get
insights of data. Then, ontology based studies proved to be suc-
cessful in representing, visualizing, and determining sentiment
units [35,96,182]. Exploitation of the use of ontology can
resolve scalability and vagueness issues in sentiment analysis.
Thus applying machine learning together with ontology on
linked data is still an open research problem.

 A very few attempts were made to utilize the potential of opti-
mization techniques for feature selection. Therefore, various
hybrids of machine learning and optimization techniques can
be developed for feature subset selection.

 There is a lack of opinion mining system in non-English lan-
guages [17]. A great deal of study has been carried out in SA
in English language. Consequently, substantial amount of
resources have been generated for the English language. Thus,
these resources can be mapped to other languages in order to
perform cross-lingual sentiment analysis.

 Cross-domain SA is still a major challenge. Cross-domain SA
needs to address three issues: the ﬁrst issue, opinion expressed
for one domain will be reverted for other domain. For instance,
polarity of a sentence e.g. ‘‘Screen is curved.’’ is positive for TV
but negative for mobile. The next issue is the difference in sen-
timent vocabularies across different domains should be consid-
ered, and the third issue is to objectively assign a strength
marker to each sentiment word.

 Aspect level SA is very much required for comparative visualiza-

tion of similar kind of products.

 The main challenge lies in review helpfulness is the validation
of the proposed method. In order to validate the proposed
method, researcher should have access to sale information
about the product along with date of sale. Such kind of informa-
tion can be very useful to correlate the helpfulness of reviews to
sale of the product, estimation of effect of reviews on sale of
products.

 The lack of proper review spam dataset is a major issue in order
to perform opinion spam detection. Because AMT developed
dataset and artiﬁcially synthesized dataset cannot contain psy-
cholinguistic features like an original spammer. Therefore, com-
parison of effectiveness of two or more techniques is barely
reliable.

 Finally, some more open issues are contextual SA, intrinsic fea-
ture based SA, SA on Facebook posts, sense level subjectivity
classiﬁcation, SA of streaming text, and suitable automatic SA
system with respect to different media.

4.2. Other possible applications

In addition to the existing applications studied in the literature,
we foresee possible applications of SA at two levels viz. global level
and business level. The former includes rumor detection, SA on
streaming data, study the trend of sentiment propagation over dif-
ferent media on some special event like general election, and study

Table 9
List of publicly available datasets.

S# Data set

Stanford large movie data
set
COAE2008

1

2

3

Boacar

Car Reviews

Chinese

http://www.riche.com.cn/boacar/

[187]
[188]

4
5
6 Movie-v2.0
7 Multi-domain
8

SkyDrive de Hermit Dave

9
10
11
12

13
14
15

TripAdvisor
[38]
TBOD [144]
[68]

[148]
[148]
ISEAR

[149]

16
17 DUC data, NIST

18

[70]

[114]
[125]
Spinn3r dataset
[86]

19
20
21
22
23 HASH [179]
24
EMOT [179]

25
26
27
28
29
30
31

ISIEVE [179]
[177]
[52]
[96]
[39]
[164]
[210]

32

[230]

Reviews, forums
Reviews
Movie Reviews
Multi-domain
Spanish Word Lists

Reviews
Multi-Domain
Reviews
Product Reviews

Movie Reviews
Product Reviews
English sentences

Product Reviews
Texts

Restaurant and Hotel
Reviews
Restaurant Reviews
Biographical Articles
Multi-Domain
Ironic Dataset
Tweets
Tweets and
Emoticons
Tweets
Tweets
Opinions
Tweets
Movie Reviews
Tweets
Spam Reviews

Sarcasm and nasty
reviews

English
English
English
English
Spanish

Spanish
English
English
English

Turkish
Turkish
English

English
English

English

http://sifaka.cs.uiuc.edu/wang296/Data/
http://uilab.kaist.ac.kr/research/WSDM11
http://www.cs.cornell.edu/people/pabo/movie-review-data/
http://www.cs.jhu.edu/mdreze/datasets/sentiment
https://skydrive.live.com/?cid=3732e80b128d016f&id=
3732E80B128D016F%213584
http://clic.ub.edu/corpus/es/node/106
www2.cs.uic.edu/liub/FBS/sentiment-analysis.html

http://www.lsi.us.es/_fermin/index.php/Datasets

http://www.win.tue.nl/mpechen/projects/smm/#Datasets
http://www.win.tue.nl/mpechen/projects/smm/#Datasets
www.affective-sciences.org/system/ﬁles/page/2636/ISEAR.zip

http://www.cs.jhu.edu/mdredze/datasets/sentiment/
http://www-nlpir.nist.gov/projects/duc/data.html, http://www.
nist.gov/tac/data/index.html
http://uilab.kaist.ac.kr/research/WSDM11

Cantonese
Dutch
English
English
English
English

http://www.openrice.com
http://www.iisg.nl/bwsa
http://www.icwsm.org/2011/data.php
http://users.dsic.upv.es/grupos/nle/
http://demeter.inf.ed.ac.uk
http://twittersentiment.appspot.com

English
English
English
English
English
English
English

www.i-sieve.com
e-mail: apoorv@cs.columbia.edu
http://patientopinion.org.uk
http://goo.gl/UQvdx
http://ai.stanford.edu/amaas/data/sentiment/
http://cs.stanford.edu/people/alecmgo/trainingandtestdata.zip
http://myleott.com/op_spam

English

https://nlds.soe.ucsc.edu/iac

Type

Movie Reviews

Lang.

English

Web resource
http://ai.stanford.edu/amaas/data/sentiment/

Details

Movie Reviews

Product Reviews

Chinese

http://ir-china.org.cn/coae2008.html

2739 documents for movie, education, ﬁnance, economics, house, computer,
mobile phones, etc. 1525 +ve, 1214  ve
11 type of car TradeMarks and total review 1000 words, having 578 POS, 428  ve
reviews
Accessed: 27 August, 2014
Aspect oriented dataset. Accessed: 18 December, 2014
Data size: 2000 Positive: 1000 Negative: 1000

18,000 customer reviews on hotels and restaurants from Hopinion
6800 opinion words on 10 different products
Product Review on Cars, Headphones, Hotels
Product Reviews from Epinion.com on headphones 587 reviews, hotels 988 reviews
and cars 972 reviews
5331 positive and 5331 negative reviews on movie
700 +ve &700  ve reviews on books, DVD, electronics, kitchen appliances
The dataset contains 7666 such statements, which include 18,146 sentences,
449,060 running words.
Amazon reviews on 4 domain (books, DVDs, electronics, kitchen appliances)
Text summarization data

Restaurant and Hotel Reviews from Amazon and Yelp

Reviews on restaurant
574 Biographical articles

3163 ironic reviews on ﬁve products
31,861 Pos tweets, 64,850 Neg tweets, 125,859 Neu tweets
230,811 Pos & 150,570 Neg tweets

1520 Pos tweets, 200 Neg tweets, 2295 Neu tweets
11,875 tweets
2000 patient opinions
667 tweets
50,000 movie reviews

400 deceptive and 400 truthful reviews in positive and negative category. Last
Accessed by: 12 April, 2015
1000 discussions, 390,000 posts, and some 73,000,000 words

K

.

R
a
v
i
,

V

.

R
a
v
i

/
K
n
o
w
l
e
d
g
e
-
B
a
s
e
d

S
y
s
t
e
m

s

8
9

(
2
0
1
5
)

1
4
–
4
6

3
9

40

K. Ravi, V. Ravi / Knowledge-Based Systems 89 (2015) 14–46

Table 10
Summary of reviewed articles.

Ref.

[8]
[11]
[12]
[13]
[18]
[21]
[22]
[23]
[24]
[25]
[26]
[27]
[29]
[30]

[32]
[33]
[35]
[36]
[37]
[40]
[41]
[43]
[44]
[45]
[46]
[47]
[48]
[49]
[50]
[51]
[52]
[53]
[54]
[55]
[56]
[57]
[58]
[59]
[60]
[61]
[62]
[63]
[64]
[66]
[67]
[68]
[69]
[70]
[73]
[74]
[75]

[76]
[77]
[78]
[80]
[81]
[85]
[86]
[88]
[90]
[91]
[92]
[93]
[94]
[95]

Concepts and techniques utilized

Page rank, Gradient descent, Linear regression
Link mining, Collective classiﬁcation
AdaBoost.HM
DBA
DBA, SOFNN, Linear regression
Regression, Random walk, SVM
Cohen’s K coefﬁcient
Fuzzy clustering, PMI, DBA
DBA
Association Miner CBA, DBA
SVM
Markov-Chain Monte Carlo (MCMC)
SVM with Gaussian Kernel
Ontology, K-means

PMI-IR
NB, SVM, ME
Ontology, DBA
New Algorithm, DBA
CRF
Multinomial inverse regression
FFCA, Lattice
Analytic hierarchy process
Fisher’s discriminant ratio, SVM
Semantic orientation, SVM
MNB, ME, SVM
DBA
Semantic orientation and BackProp
Probabilistic Matrix Factorization
NB, SVM, NN
SVM, NN
DNN, CNN, K-medoids, KNN
SVM, NN, MLP, DT, GA, Stepwise LR, RBC
NB, ME, SVM
DBA
NB, EM
SVM, NN
SVM
EM
ME
Bayesian Model, LDA
Fuzzy Set, Ontology
ME, Bootstrapping, IG
DBA
NB, ME, DT, KNN, SVM
SVM, DBA
DBA, Random walk algorithm
DBA
Linear Regression
BayesNet, J48, Jrip, SVM, NB, ZeroR, Random
Semantic relationships
Multilingual bootstrapping and cross-lingual bootstrapping, linear regression,
IG
Bootstrapping, DT, MLP, PCA, SLR, SMO-SVM
LR, SVM, RF
Discretionary accrual model
Bayes-Nash equilibria
RF
DBA
Semantic, NB, SVM, DT
SVM, LR, CRF
SVM, NB
K-means, SVM
HMM-LDA
Two level CRF
Corpus based approach, SVM, NB, C4.5, BBR
SVM

DBA, Ontology
SMO-SVM, DBA
NB and Ontology
Cosine similarity, L1 regularized logistic regression
Association miner CBA

[96]
[97]
[98]
[99]
[100]
[101] NN, C4.5, CART, SVM, NB

P

2
NA
2
5
2, 7
4, 2
6, 2
6, 2
NA
2
2
NA
3, 2
2

2
2
2
2
NA
3
2
NA
2
3, 2
3, 2
2
2
NA
2
NA
NA
2
2
5, 2
NA
5, 2
NA
NA
NA
2
2
3, 2
NA
NA
2
2
2
NA
5, 2
2
NA

2
2
NA
NA
NA
3, 2
NA
NA
NA
NA
NA
NA
5, 2
NA

2
2
2
2
NA
2

L

E
E
E
E
E
E
I
E
D
E
E
E

E

E
E
E
E

E
E
C
C
E
E, D, F
D, E
E
C
E
C
E
E
E
E
E
E
E
E, S
E
E
C
C
E
C, E
E
E
E
C
E
E
E, R

E
B
E
E
E
E

E
E
C
E
E
E, S
E

E
E
E
E
C
E

Type of data

PR
MB
G
News Comments
MB, DJIA data

MB
G
G
PR
PR
Online discussion

Multi-domain
MR
MR
MR, Book, Mobile
PR
MB
PR
MB
PR
PR
Forum, Blog, PR
News
Blogs, PR
MB
PR
MB
G
News
PR
MB
PR
MB
Suicide Notes
PR
MB
PRMPQA, Appraisal Lexiconsd
PR
PR
e-mail, book
PR, Forums
PR
PR
PR
PR, social network
News, Magazine

Phone Reviews
e-mails
Book Reviews
MB
PR
MB
PR
PR
MB
Forums
PR
PR
PR

MB
MR
PR, MR
PR
PR
MB

Dictionary

GI
New Lexicon
OF, GPOMS
ANEW, CN
SN
WNA, SN, WN.
Dutch WN
WN

MPQA
ReiAction [122],a Family
Relationb

SWN
11 dictionaries

SWN

CN, WNA, AffectiveSpace

WN

WN, SWN.
fullStrengthLexiconc

Hownet, NEUCSPe
Roget Thesaurusf

GI

SWN, GI
WN

WN

SWN
WN, MSOL, WNA

SWN, Tree Tagger
WNA, LIWC, VerbOcean,
CN

SWN, WN
WN
WN and SWN

K. Ravi, V. Ravi / Knowledge-Based Systems 89 (2015) 14–46

41

Table 10 (continued)

Ref.

Concepts and techniques utilized

[102]
[107]
[108]

SVM
LDA, DBA
SVM

Rule-based multivariate features, SVM

IG, DBA
SVM, Statistical approach

SMO-SVM, LR, AdaBoost, SVR, DT, NB, J48, Jrip

Lexical features, NB, Linear SVM, Jrip, KNN

SVR, RBF
SVM, NB

SVM, NB, ME

SVM, Osgoodian values, PMI
Transfer-based machine translation

EWGA, SVM, Bootstrapping
Class sequential rules

Semantic, GI, Chi-square, SVM
Semantic

Linear classiﬁers, Clique, MIRA classiﬁer

SP-LSA, AR, EM, e-SVR
Tabu search, MB, NB, SVM, ME
PSO and SVM

[109]
[110] DBA
[111] NB, SVM
[112] DBA, RBC, SVM
[114]
[115]
[116] DBA, SVM, NB, LR, J48, Jrip, AdaBoost, Decision Table, MLP, NB.
[117] DBA
[118]
[121] Adaptive-NB
[123]
SVR
[124] NB
[125]
[126] DBA
[127] DBA
[130]
[131]
[132] New Algorithm
[148]
[154] New algorithm, Lexical features
[155]
[156]
[157]
[158] DBA
[160]
[162]
[163] DBA, SVM, NB, Logistic, NN
[165]
[166]
[167] NB, SVM, Min.-cut in the graph
[168]
[169] DBA, SVM, and SMO-SVM
[170] DBA
[171] DBA
[172]
[173]
[174] ME
[175] DBA, Sigmoid scoring
[176]
[177]
[178]
[179]
[180]
[182]
[183]
[184] Vector space model
[185] Modiﬁed LDA
[186]
[189]
[190]
[191]
[192]
[193]
[194] Ontology
[195] Ontology
[196] Ontology, Maximum-Likelihood
[197]
[200]
[202] DBA, Graphical Techniques
[203] DBA
[205] Graphical techniques
[206] DBA
[207] Ontology, DBA
[209]
[210]
[211] DBA
[212] NB, SVM, DBA
[213] Ontology, DBA, ELM
[214] Ontology, DBA, SVM, FCM
[216] DBA, Ontology
[217]

SVM, PMI
Convolution kernels [152], SVM, DBA
Statistical method of OASYS [8]
Boosting, SVM
Bipartite graph, Regularization operator
LDA, Ontology, MCMC
SVM, TF-IDF

Recursive Chinese Restaurant Process
LDA incorporated with domain knowledge
CRF, syntactic and semantic features
LDA, Appraisal expression pattern
PMI, TF-IDF
TF-IDF, Domain relevance

PCA, SVM, LR, Bayesian Boosting, Bagged SVM
SVM

SVM, NB, J48
SVM, RF

Rule base classiﬁer, NB

P

2
2
2

2
2
2
2
2
2
2
2
2
NA
6, 2
2
2
2
5, 2
NA
3
NA
2
3
2
2
2
3, 2
2
3
2
2
2
2
2
2
3
2
2
2
2
2
2
2, 3
C
3
2
2
2
3
5
2
NA
2
NA
2
2
2
2
2
2
2
2
2
2
8
4
3
3
2
2
2
2
2
2

L

C
E
A

E
S
E
E
CT
E, C
E
E
E
C
C
E
D
E
E

E

E, T
E
E
E
E
E
E, A
E
E
E
C
E
E
E
J
E
E
J
E
C
E
E
E
E
E
E
E
E
E
E
E
E
E
E
C
E
E
E
E
E
E
E
GE
E
E
S
S
S
E
E
E
E
E

Type of data

HR, PR
RR, HR
Dialects, MB, Wiki Talks,
Forums
MR, PR, Automobile
MR
RR
MR, Product, MySpace texts
RR
HR, Mobile
MySpace
MB
Social Media
PR
Sina-Wiebo
Social & Mass media
Biographies
MB
G

MB, PR
PR

PR
MR
MR and News
MB
Mobile Reviews
Forums
MR
MB
MR and PR
HR
MR
PR
MR
MR and PR
Web pages, News
MR
Camera Review
MR
Blogs
MB
MB
News articles
MB
Blogs
Multi-domain
News headlines, Forex Rate
News articles
PR
PR
Camera and HR
PR, Facebook text
HR, RR, PR
PR
HR, Cellphone
Automobile, PR, SW
MR
MR
PR
PR
G
MB
MB
Google n-grams
PR, MR
Facebook text
Apontador
MB
PR
G
G
PR, MR
Dialogue

Dictionary
TU lexicong
MPQA, SWN

BLEL, WN
SWN
WN, GI

SentiStrength
SWN
SentiStrength

Brouwers thesaurus
OL
SentiStrength

2030 appraisal words

Moreo et al. [13]

SWN
10 dictionaries

WN
Yi et al. [7] lexicon

WN

Hownet
GI
WN, DAL [151]
OASYS
MPQA, NetLingo

OF
SWN
Harvard IV

GI

SWN, GI, OL
WN
GI

CN, DBPedia, WN
CN, WN, JMDict, Verbosity
SWN, SN 3
SN 3, WNANRC, SAT
CN
Spanish LIWC

SN 3, WeFeelFine
LIWC
AffectiveSpace
SN 3, WNA, AffectiveSpace
WN, CN
SN 3

(continued on next page)

42

Table 10 (continued)

Ref.

Concepts and techniques utilized

Bootstrapping, PMI, DBA

[218]
[220] DBA, Binomial LR
Product, Review & Reviewer Information
[221]
Linear Regression
[222]
Linear Regression
[223]
Linear Regression
[224]
[225]
SVM
[226] MLP
[227]
[228]
[229] DBA
[231]
[232]
[240]
[241]
[243]

Linear Regression
PU-learning
LDA, SVM, PMI
PageRank algorithm, DBA
PMI-IR, RCut, Apriori Algo.

RFM, SVR
RF, NB, SVM

K. Ravi, V. Ravi / Knowledge-Based Systems 89 (2015) 14–46

P

NA
NA
NA
2
NA
NA
NA
NA
NA
NA
2
NA
NA
NA
NA
NA

L

E
E
E
E
E
E
E
E
E
E
E
E
E
C
C
C

Type of data

Dictionary

LIWC

PR
PR
PR
PR
PR
PR
PR
PR
PR
PR
PR
PR
PR
PR
PR
PR

a http://cyc.com/cyc/opencyc/overview.
b http://www.ontologyportal.org/index.html.
c https://github.com/maksim2042/snowwhite/blob/master/snowwhite/data/fullStrengthLexicon.txt.
d http://lingcog.iit.edu/arc/appraisal_lexicon_2007b.tar.gz.
e NEUCSP is a Chinese word segmentation and POS tagging tool at (http://www.nlplab.com/chinese/source.htm).
f http://thesaurus.com/Roget-alpha-index.html.
g Available at: http://nlp.csai.tsinghua.edu.cn/_lj/downloads/sentiment.dict.v1.0.zip.

the ﬂow of emotion during chatting, etc. The latter involves celeb-
rity recommendation for speciﬁc brand, comparison of celebrity
popularity, measurement of celebrity effect on the sale of products,
decision making for candidates based on recommendation made
by previous employer, and appraisal preparation for an employee
based
(a
customer-centric approach) etc.

customer

feedback

on

in

service

industry

articles. That will be helpful to a novice researcher to address
new challenges very precisely and ﬁnd out the most common chal-
lenges to look forward for a new solution. Overall, sentiment anal-
ysis has found various promising applications like market
prediction, political sentiment determination, equity value predic-
tion, box ofﬁce prediction, etc. But, a lot work still remains to be
done and it is a fertile area.

5. Conclusions

References

This paper presents a comprehensive, state-of-the-art review
on the research work done in various aspects of SA during 2002–
2014. The paper is reviewed in seven broad dimensions viz. subjec-
tivity classiﬁcation, sentiment classiﬁcation, review usefulness
measurement, lexicon creation, opinion word and product aspect
extraction, opinion spam detection and various applications of
opinion mining. These seven dimensions refer to tasks to be accom-
plished for SA. All tasks and sub-tasks are reviewed in four aspects
viz. problem addressed, dataset exploited, features selected (if
applicable), approaches and techniques employed, result, and indi-
cated future directions by author and/or us. We draw some impor-
tant conclusions from this review paper regarding the applied
techniques. Apart from SVM, NN and lexicon based approaches;
we found that some of the intelligent techniques have not been
exploited exhaustively like random forest, evolutionary computa-
tion, association rule mining, fuzzy rule based systems, rule miner,
conditional random ﬁeld theory (CRF), formal concept analysis,
radial basis function neural network (RBFNN), and online learning
algorithms. Rule miner can help ﬁgure out common opinion words
used together. Selective attempts were made to exploit evolution-
ary computation in feature selection, while its major potential is
still unutilized. Since, sentiment is often found in vague form, fuzzy
logic is eminently suitable to model the vagueness in more robust
way. CRF can be augmented with domain information in better
extraction of aspects. RBFNN and online learning algorithms can
be very much useful especially in big data scenario like sentiment
analysis on streaming text, etc. Ontology can be useful in globaliz-
ing the measurement standard of sentiments.

One of the main contributions of the paper is to present a list of
available public datasets for SA. The most interesting part of the
survey is to present claimed future enhancement in surveyed

[1] B. Pang, L. Lee, Opinion mining and sentiment analysis, Found. Trends Inform.

Retrieval 2 (2008) 1–135.

[2] A. Balahur, Methods and Resources for Sentiment Analysis in Multilingual
Documents of Different Text Types, PhD Thesis, University of Alicante, Spain,
2011, 273p.

[3] I. Niles, A. Pease, Linking lexicons and ontologies:mapping WordNet to the
suggested upper merged ontology, in: Proceedings of the 2003 International
Conference on Information and Knowledge Engineering (IKE 03), Las Vegas,
2003, pp. 23–26.

[4] C. Strapparava, A. Valitutti, WordNet-Affect: an affective extension of

WordNet, in: Proceedings of LREC, vol. 4, 2004, pp. 1083–1086.

[5] A. Esuli, F. Sebastiani, SENTIWORDNET: a publicly available lexical resource
for opinion mining, in: Proceedings of the 5th Conference on Language
Resources and Evaluation LREC-06, Genoa, Italy, 2006, pp. 417–422 (See also:
http://sentiwordnet.isti.cnr.it/).

[6] S. Baccianella, A. Esuli, F. Sebastiani, SENTIWORDNET 3.0: an enhanced lexical
resource for sentiment analysis and opinion mining, in: Proceedings of LREC-
10, Malta, 2010, pp. 2200–2204.

[7] J. Yi, T. Nasukawa, R. Bunescu, W. Niblack, Sentiment analyzer: extracting
sentiments about a given topic using natural language processing techniques,
in: Proceedings of the Third IEEE International Conference on Data Mining,
2003, pp. 427–434.

[8] S.K. Li, Z. Guan, L.Y. Tang, et al., Exploiting consumer reviews for product
feature ranking, J. Comput. Sci. Technol. 27 (3) (2012) 635–649, http://
dx.doi.org/10.1007/s11390-012-1250-z.

[9] J. Kamps, M. Marx, Words with attitude,

in: Proceedings of the 1st

International WordNet Conference, Mysore, India, 2002, pp. 332–341.

[10] K. Crammer, Y. Singer, Ultraconservative online algorithms for multiclass

problems, JMLR (2003).

[11] J.C.B. Rabelo, R.B.C. Prudêncio, F.A. Barros, Using link structure to infer
opinions in social networks, IEEE International Conference on Systems, Man,
and Cybernetics (SMC 2012), IEEE, 2012.

[12] T. Wilson, J. Wiebe, P. Hoffmann, Recognizing contextual polarity in phrase-
in: Proceedings of HLT/EMNLP-05, Vancouver,

level sentiment analysis,
Canada, 2005.

[13] A. Moreo, M. Romero, J.L. Castro, J.M. Zurita, Lexicon-based comments-
oriented news sentiment analyzer system, Expert Syst. Appl. 39 (2012) 9166–
9180.

[14] R. Feldman, Techniques and applications for sentiment analysis, Commun.

ACM 56 (4) (2013) 82–89 (Review Articles).

K. Ravi, V. Ravi / Knowledge-Based Systems 89 (2015) 14–46

43

[15] E. Cambria, B. Schuller, Y.-Q. Xia, New avenues in opinion mining and
sentiment analysis (extended abstract), in: Proceedings of IJCAI, Buenos Aires
2015.

[16] H. Tang, S. Tan, X. Cheng, A survey on sentiment detection of reviews, Expert

Syst. Appl. 36 (2009) 10760–10773.

[17] H. Chen, D. Zimbra, AI and opinion mining, IEEE Intell. Syst. 25 (2010) 74–80.
[18] J. Bollen, H. Mao, X. Zeng, Twitter mood predicts the stock market, J. Comput.

Sci. 2 (2012) 1–8.

[19] S. Kumar, F. Morstatter, H. Liu, Twitter Data Analytics, Springer, 2013 (August

19).

[20] R. McDonald, K. Crammer, F. Pereira, Online large-margin training of

dependency parsers, in: Proc. ACL, 2005.

[21] A.C.-R. Tsai, C.-E. Wu, R.T.-H. Tsai,

J.Y.-J. Hsu, Building a concept-level
sentiment dictionary based on commonsense knowledge, IEEE Intell. Syst. 2
(2013) 22–30.

[22] C. Bosco, V. Patti, A. Bolioli, Developing corpora for sentiment analysis: The

case of irony and senti-tut, IEEE Intell. Syst. 2 (2013) 55–63.

[23] S. Poria, A. Gelbukh, A. Hussain, N. Howard, D. Das, S. Bandyopadhyay,
Enhanced SenticNet with affective labels for concept-based opinion mining,
IEEE Intell. Syst. 2 (2013) 31–38.

[24] I. Maks, P. Vossen, A lexicon model for deep sentiment analysis and opinion

mining applications, Decis. Support Syst. 53 (2012) 680–688.

[46] E. Boiy, M.-F. Moens, A machine learning approach to sentiment analysis in
Inform. Retrieval 12 (2009) 526–558, http://

multilingual Web texts,
dx.doi.org/10.1007/s10791-008-9070-z.

[47] E.J. Fortuny, T.D. Smedt, D. Martens, W. Daelemans, Media coverage in times
of political crisis: a text mining approach, Expert Syst. Appl. 39 (2012)
11616–11622.

[48] L.-S. Chen, C.-H. Liu, H.-J. Chiu, A neural network based approach for

sentiment classiﬁcation in the blogosphere, J. Informet. 5 (2011) 313–322.

[49] H. Bao, Q. Li, S.S. Liao, S. Song, H. Gao, A new temporal and social PMF-based
method to predict users’ interests in micro-blogging, Decis. Support Syst. 55
(2013) 698–709.

[50] R. Moraes,

J.F. Valiati, W.P. Gaviao Neto, Document-level sentiment
classiﬁcation: an empirical comparison between SVM and ANN, Expert Syst.
Appl. 40 (2013) 621–633.

[51] J. Du et al., Box ofﬁce prediction based on microblog, Expert Syst. Appl.

(2013), http://dx.doi.org/10.1016/j.eswa.2013.08.065.

[52] E. Cambria, P. Gastaldo, F. Bisio, R. Zunino, An ELM-based model for affective

analogical reasoning, Neurocomputing 149 (2015) 443–455.

[53] T. Geva, J. Zahavi, Empirical evaluation of an automated intraday stock
recommendation system incorporating both market data and textual news,
Decis. Support Syst. (2013), http://dx.doi.org/10.1016/j.dss.2013.09.013.

[54] R. Xia, C. Zong, S. Li, Ensemble of feature sets and classiﬁcation algorithms for

[25] Q. Miao, Q. Li, R. Dai, AMAZING: a sentiment mining and retrieval system,

sentiment classiﬁcation, Inform. Sci. 181 (2011) 1138–1152.

Expert Syst. Appl. 36 (2009) 7192–7198.

[26] M.R. Saleh, M.T. Martín-Valdivia, A. Montejo-Ráez, L.A. Ureña-López,
Experiments with SVM to classify opinions in different domains, Expert
Syst. Appl. 38 (2011) 14799–14804.

[27] P. Sobkowicz, M. Kaschesky, G. Bouchard, Opinion mining in social media:
modeling, simulating, and forecasting political opinions in the web, Gov.
Inform. Quart. 29 (2012) 470–479.

[28] J. Pennebaker, R. Booth, M. Francias, Linguistic Inquiry and Word Count. LIWC

2007, 2007.

[29] R. Narayanan, B. Liu, A. Choudhary, Sentiment analysis of conditional
sentences, Proceedings of the 2009 Conference on Empirical Methods in
Natural Language Processing, vol. 1, Association for Computational
Linguistics, 2009, pp. 180–189.

[30] A. Balahur, Jesu’s M. Hermida, Andre’s Montoyo, Building and exploiting
EmotiNet, a knowledge base for emotion detection based on the appraisal
theory model, IEEE Trans. Affect. Comput. 3 (1) (2012).

[31] V. Hatzivassiloglou, J. Wiebe, Effects of adjective orientation and gradability
on sentence subjectivity, Proceedings of
the 18th Conference on
Computational Linguistics, vol. 1, Association for Computational Linguistics,
2000, pp. 299–305.

[32] P. Turney, Thumbs up or thumbs down? Semantic orientation applied to
unsupervised classiﬁcation of reviews, in: Proceedings of the 40th Annual
Meeting on Association for Computational Linguistics ACL’02, Association for
Computational Linguistics, Stroudsburg, PA, USA, 2002, pp. 417–424.

[33] B. Pang, L. Lee, S. Vaithyanathan, Thumbs up? Sentiment classiﬁcation using
machine learning techniques, Proceedings of the ACL-02 Conference on
Empirical Methods in Natural Language Processing, vol. 10, Association for
Computational Linguistics, 2002, pp. 79–86.

[34] T. Wilson, P. Hoffmann, S. Somasundaran, J. Kessler, J. Wiebe, Y. Choi, C.
Cardie, E. Riloff, S. Patwardhan, OpinionFinder: a system for subjectivity
analysis,
in: Proceedings of HLT/EMNLP on Interactive Demonstrations,
Association for Computational Linguistics, 2005, pp. 34–35.

[35] I. Peñalver-Martinez et al., Feature-based opinion mining through ontologies,

Expert Syst. Appl. (2014), http://dx.doi.org/10.1016/j.eswa.2014.03.022.

[36] H. Cho et al., Data-driven integration of multiple sentiment dictionaries for
lexicon-based sentiment classiﬁcation of product reviews, Knowl.-Based Syst.
71 (2014) 61–71.

[37] L. Chen, L. Qi, F. Wang, Comparison of feature-level learning methods for

mining online consumer reviews, Expert Syst. Appl. 39 (2012) 9588–9601.

[38] M. Hu, B. Liu, Mining and summarizing customer reviews, in: Proceedings of
Tenth ACM SIGKDD International Conference on Knowledge Discovery and
Data Mining, ACM, 2004, pp. 168–177.

[39] A.L. Maas, R.E. Daly, P.T. Pham, Dan. Huang, A.Y. Ng, C. Potts, Learning word
vectors for sentiment analysis, in: Proceedings of the 49th Annual Meeting of
the Association for Computational Linguistics (ACL 2011) Portland, Oregon,
USA, 2011, pp. 142–150.

[40] Taddy, Measuring Political Sentiment on Twitter: Factor Optimal Design for
Multinomial Inverse Regression, Technometrics, 2013, http://dx.doi.org/10.
1080/00401706.2013.778791.

[41] S.-T. Li, F.-C. Tsai, A fuzzy conceptualization model for text mining with
application in opinion polarity classiﬁcation, Knowl.-Based Syst. 39 (2013)
23–33.

[42] F. Figueiredo, L. Rocha, T. Couto, T. Salles, M.A. Goncalves, W. Meira Jr., Word
co-occurrence features for text classiﬁcation, Inform. Syst. 36 (2011) 843–
858.

[43] Y.-M. Li, Y.-L. Shiu, A diffusion mechanism for social advertising over

microblogs, Decis. Support Syst. 54 (2012) 9–22.

[44] S. Wang, D. Li, X. Song, Y. Wei, H. Li, A feature selection method based on
improved Fisher’s discriminant ratio for text sentiment classiﬁcation, Expert
Syst. Appl. 38 (2011) 8696–8702.

[45] Y. Dang, Y. Zhang, H. Chen, A lexicon-enhanced method for sentiment
classiﬁcation: an experiment on online product reviews, IEEE Intell. Syst. 25
(4) (2010) 46–53.

[55] F.Å. Nielsen, A New ANEW: Evaluation of a Word List for Sentiment Analysis

in Microblogs, 2011. Available from: <arXiv:1103.2903>.

[56] Z. Zhai, Product feature grouping for opinion mining, IEEE Intell. Syst. 4

(2012) 37–44.

[57] M. Ghiassi, J. Skinner, D. Zimbra, Twitter brand sentiment analysis: a hybrid
system using n-gram analysis and dynamic artiﬁcial neural network, Expert
Syst. Appl. 40 (2013) 6266–6282.

[58] B. Desmet, V. Hoste, Emotion detection in suicide notes, Expert Syst. Appl. 40

(2013) 6351–6358.

[59] L. García-Moya, H. Anaya-Sánchez, R. Berlanga-Llavori, Retrieving product
features and opinions from customer reviews, IEEE Intell. Syst. 3 (2013) 19–
27.

[60] J.J. Jung, Online named entity recognition method for microtexts in social
networking services: a case study of twitter, Expert Syst. Appl. 39 (2012)
8066–8070.

[61] C. Lin, Y. He, R. Everson, S. Rüger, Weakly supervised joint sentiment-topic

detection from text, IEEE Trans. Knowl. Data Eng. 24 (6) (2012).

[62] L. Liu, X. Nie, H. Wang, Toward a fuzzy domain sentiment ontology tree for
in: 5th International Congress on Image and Signal

sentiment analysis,
Processing (CISP 2012), 2012.

[63] J. Zhu, H. Wang, M. Zhu, B.K. Tsou, M. Ma, Aspect-based opinion polling from

customer reviews, IEEE Trans. Affect. Comput. 2 (1) (2011).

[64] S.M. Mohammad, From once upon a time to happily ever after: tracking

emotions in mail and books, Decis. Support Syst. 53 (2012) 730–741.

[65] M. Taboada, J. Grieve, Analyzing appraisal automatically, in: Proceedings of
the AAAI Spring Symposium on Exploring Attitude and Affect in Text:
Theories and Applications, 2004, pp. 158–161.

[66] G. Wang et al., Sentiment classiﬁcation: the contribution of ensemble
http://dx.doi.org/10.1016/

Support

learning,
Decis.
j.dss.2013.08.002.

Syst.

(2013),

[67] C. Quan, F. Ren, Unsupervised product feature extraction for feature-oriented

opinion determination, Inform. Sci. 272 (2014) 16–28.

[68] F.L. Cruz, J.A. Troyano, F. Enríquez, F.J. Ortega, C.G. Vallejo, Long autonomy or
long delay? The importance of domain in opinion mining, Expert Syst. Appl.
40 (2013) 3174–3184.

[69] M. Taboada, J. Brooke, M. Toﬁloski, Lexicon-based methods for sentiment

analysis, Comput. Linguist. 37 (2) (2011) 267–307.

[70] Y.C. Xu et al., Measuring product susceptibility in online product review
(2013), http://dx.doi.org/10.1016/

social network, Decis. Support Syst.
j.dss.2013.01.009.

[71] M. Taboada, J. Grieve, Analyzing appraisal automatically, in: Proceedings of
the AAAI Spring Symposium on Exploring Attitude and Affect in Text (AAAI
Technical Report SS-04-07), Stanford, CA, 2004, pp. 158–161.

[72] M. Taboada, C. Anthony, K. Voll, Creating semantic orientation dictionaries,
in: Proceedings of 5th International Conference on Language Resources and
Evaluation (LREC), Genoa, 2006, pp. 427–432.

[73] P.C.R. Lane, D. Clarke, P. Hender, On developing robust models for
favourability analysis: model choice, feature sets and imbalanced data,
Decis. Support Syst. 53 (2012) 712–718.
[74] A. Neviarouskaya, H. Prendinger, M.

Ishizuka, SentiFul: a lexicon for

sentiment analysis, IEEE Trans. Affect. Comput. 2 (1) (2011).

[75] C. Banea, R. Mihalcea, J. Wiebe, Sense-level subjectivity in a multilingual

setting, Comput. Speech Lang. 28 (2014) 7–19.

[76] Y. Liu, J. Jin, P. Ji, J.A. Harding, R.Y.K. Fung, Identifying helpful online reviews: a

product designer’s perspective, Comput. Aided Des. 45 (2013) 180–194.

[77] K. Coussement, D. von den Poel, Improving customer attrition prediction by
integrating emotions from client/company interaction emails and evaluating
multiple classiﬁers, Expert Syst. Appl. 36 (2009) 6127–6134.

[78] N. Hu, I. Bose, Y. Gao, L. Liu, Manipulation in digital word-of-mouth: a reality

check for book reviews, Decis. Support Syst. 50 (2011) 627–635.

[79] M.Á. García-Cumbreras, A. Montejo-Ráez, M.C. Díaz-Galiano, Pessimists and
optimists: improving collaborative ﬁltering through sentiment analysis,
Expert Syst. Appl. 40 (2013) 6758–6765.

44

K. Ravi, V. Ravi / Knowledge-Based Systems 89 (2015) 14–46

[80] L. Qiu, H. Rui, A. Whinston, Social network-embedded prediction markets: the
effects of information acquisition and communication on predictions, Decis.
Support Syst. 55 (2013) 978–987.

[81] A. Ghose, P.G. Ipeirotis, Estimating the helpfulness and economic impact of
product reviews: mining text and reviewer characteristics, IEEE Trans. Knowl.
Data Eng. 23 (10) (2011).

[82] R. Mihalcea, C. Banea, J. Wiebe, Learning multilingual subjective language via
cross-lingual projections, in: Annual Meeting-Association for Computational
Linguistics, vol. 45, no. 1, 2007, p. 976.

[83] M. Thelen, E. Rilo, A bootstrapping method for learning semantic lexicons
using extraction pattern contexts, in: Proc. Conf. on Empirical Methods in
Natural Language Processing (EMNLP 02), Assoc.
for Computational
Linguistics, 2002, pp. 214–221.

[84] A. Montoyo, P. Martínez-Barco, A. Balahur, Subjectivity and sentiment
analysis: an overview of the current state of the area and envisaged
developments, Decis. Support Syst. 53 (2012) 675–679.

[85] F.H. Khan et al., TOM: twitter opinion mining framework using hybrid
classiﬁcation scheme, Decis. Support Syst. (2013), http://dx.doi.org/10.1016/
j.dss.2013.09.004.

[86] A. Reyes, P. Rosso, Making objective decisions from subjective data: detecting

irony in customer reviews, Decis. Support Syst. 53 (2012) 754–760.

[87] J. Wiebe, Learning subjective adjectives from corpora, Proc. 15th Nat’l Conf.

Artiﬁcial Intelligence (AAAI 00), AAAI Press, 2000, pp. 735–740.

[88] Y. Seki, N. Kando, M. Aono, Multilingual opinion holder identiﬁcation using
author and authority viewpoints, Inform. Process. Manage. 45 (2009) 189–
199.

[89] D.E. O’Leary, Blog mining-review and extensions: ‘‘From each according to his

opinion’’, Decis. Support Syst. 51 (2011) 821–830.

[90] Y.M. Li, T.-Y. Li, Deriving market intelligence from microblogs, Decis. Support

Syst. 55 (2013) 206–217.

[91] N. Li, D.D. Wu, Using text mining and sentiment analysis for online forums

hotspot detection and forecast, Decis. Support Syst. 48 (2010) 354–368.

[92] A. Duric, F. Song, Feature selection for sentiment analysis based on content

and syntax models, Decis. Support Syst. 53 (2012) 704–711.

[93] K. Xu, S.S. Liao, J. Li, Y. Song, Mining comparative opinions from customer
reviews for competitive intelligence, Decis. Support Syst. 50 (2011) 743–754.
[94] M.-T. Martin-Valdivia, E. Martínez-Cámara, J.-M. Perea-Ortega, L.A. Ureña-
López, Sentiment polarity detection in Spanish reviews combining supervised
and unsupervised approaches, Expert Syst. Appl. 40 (2013) 3934–3942.

[95] A. Balahur, Jesús M. Hermida, A. Montoyo, Detecting implicit expressions of
emotion in text: a comparative analysis, Decis. Support Syst. 53 (2012) 742–
753.

[96] E. Kontopoulos, C. Berberidis, T. Dergiades, N. Bassiliades, Ontology-based
sentiment analysis of twitter posts, Expert Syst. Appl. 40 (2013) 4065–4074.
[97] C. Hung, H.-K. Lin, C. Yuan, Using objective words in SentiWordNet to
improve word-of-mouth sentiment classiﬁcation, IEEE Intell. Syst. 2 (2013)
47–54.

[98] A. Weichselbraun,

S. Gindl, A.

Scharl, Extracting

and grounding

contextualized sentiment lexicons, IEEE Intell. Syst. 28 (2) (2013) 39–46.

[99] D. Bollegala, D. Weir, J. Carroll, Cross-domain sentiment classiﬁcation using a

sentiment sensitive thesaurus, IEEE Trans. Knowl. Data Eng. 25 (8) (2013).

[100] H. Liu, J. He, T. Wang, W. Song, X. Du, Combining user preferences and user
opinions for accurate recommendation, Electron. Commer. Res. Appl. 12
(2013) 14–23.

[101] D. Spina, J. Gonzalo, E. Amigó, Discovering ﬁlter keywords for company name

disambiguation in twitter, Expert Syst. Appl. 40 (2013) 4986–5003.

[102] Z. Zhai, H. Xu, B. Kang, P. Jia, Exploiting effective features for Chinese

sentiment classiﬁcation, Expert Syst. Appl. 38 (2011) 9139–9146.

International Conference on Language Resources and Evaluation (LREC 2012),
2012, pp. 3562–3567.

[114] Z. Zhang, Q. Ye, Z. Zhang, Y. Li, Sentiment classiﬁcation of

Internet
restaurant reviews written in Cantonese, Expert Syst. Appl. 38 (2011)
7674–7682.

[115] H. Wang, P. Yin, L. Zheng, James N.K. Liu, Sentiment classiﬁcation of online
reviews: using sentence-based language model, J. Exp. Theor. Artif. Intell.
(2013), http://dx.doi.org/10.1080/0952813X.2013.782352.

[116] M. Thelwall, K. Buckley, G. Paltoglou, D. Cai, A. Kappas, Sentiment strength
detection in short informal text, J. Am. Soc. Inform. Sci. Technol. 61 (12)
(2010) 2544–2558.

[117] M. Thelwall, K. Buckley, G. Paltoglou, Sentiment in Twitter events, J. Am. Soc.

Inform. Sci. Technol. 62 (2) (2011) 406–418.

[118] M. Thelwall, K. Buckley, G. Paltoglou, Sentiment strength detection for the

SocialWeb, J. Am. Soc. Inform. Sci. Technol. 63 (1) (2012) 163–173.

[119] S. Cerini, V. Compagnoni, A. Demontis, M. Formentelli, C. Gandini, Micro- 862
WNOp: a gold standard for the evaluation of automatically compiled lexical
resources for opinion mining, in: A. Sanso (Ed.), Language Resources and
Linguistic Theory, Franco Angeli, 2007, pp. 200–210.

[120] K.J. Trainor et al., Social media technology usage and customer relationship
performance: a capabilities-based examination of social CRM, J. Bus. Res.
(2013), http://dx.doi.org/10.1016/j.jbusres.2013.05.002.

[121] S. Tan, X. Cheng, Y. Wang, H. Xu, Adapting naive bayes to domain adaptation
for sentiment analysis, in: M. Boughanem et al. (Eds.), ECIR 2009, LNCS 5478,
2009, pp. 337–349.

[122] C. Matuszek, J. Cabral, M.J. Witbrock, J. DeOliveira, An introduction to the
syntax and content of Cyc, in: AAAI Spring Symposium: Formalizing and
Compiling Background Knowledge and Its Applications to Knowledge
Representation and Question Answering, 2006, pp. 44–49.

[123] W. Li, H. Xu, Text-based emotion classiﬁcation using emotion cause
extraction, Expert Syst. Appl. (2013), http://dx.doi.org/10.1016/j.eswa.2013.
08.073.

[124] Y. Yu, W. Duan, Q. Cao, The impact of social and conventional media on ﬁrm
equity value: a sentiment analysis approach, Decis. Support Syst. 55 (2013)
919–926.

[125] M. van den Camp, A. van den Bosch, The socialist network, Decis. Support

Syst. 53 (2012) 761–769.

[126] Mohamed M. Mostafa, More than words: social networks’ text mining for

consumer brand sentiments, Expert Syst. Appl. 40 (2013) 4241–4251.

[127] M. Thelwall, K. Buckley, Topic-based sentiment analysis for the social web:
the role of mood and issue-related words, J. Am. Soc. Inform. Sci. Technol. 64
(8) (2013) 1608–1617.

[128] K. Bollacker, C. Evans, P. Paritosh, T. Sturge,

J. Taylor, FreeBase: a
collaboratively created graph database for structuring human knowledge,
in: Proceedings of the 2008 ACM SIGMOD International Conference on
Management of Data, ACM, 2008, pp. 1247–1250.

[129] C. Bizer, J. Lehmann, G. Kobilarov, S. Auer, C. Becker, R. Cyganiak, S. Hellmann,
DBpedia-A crystallization point for the web of data, Web Semant.: Sci., Serv.
Agents World Wide Web 7 (3) (2009) 154–165.

[130] Z. Zhang, Weighing stars: aggregating online product reviews for intelligent

e-commerce applications, IEEE Intell. Syst. (September/October) (2008).

[131] H. Rui, Y. Liu, A. Whinston, Whose and what chatter matters? The effect of

tweets on movie sales, Decis. Support Syst. 55 (2013) 863–870.

[132] J. Zhan, H.T. Loh, Y. Liu, Gather customer concerns from online product
reviews – a text summarization approach, Expert Syst. Appl. 36 (2009) 2107–
2115.

[133] G.A. Miller, WordNet: a lexical database for English, Commun. ACM 38 (11)

(1995) 39–41.

[103] L.R. Rabiner, A tutorial on hidden Markov models and selected applications in

[134] B. Liu, Sentiment analysis: a multi-faceted problem, IEEE Intell. Syst. 25 (3)

speech recognition, Proc. IEEE 77 (2) (1989) 257–285.

[104] E. Riloff, J. Wiebe, Learning extraction patterns for subjective expressions, in:
Proceedings of the 2003 Conference on Empirical Methods in Natural
Language Processing (EMNLP 2003), 2003, pp. 105–112.

[105] P.J. Stone, E.B. Hunt, A computer approach to content analysis: studies using
the general inquirer system, in: Proceedings of the Spring Joint Computer
Conference (AFIPS 1963), 1963, pp. 241–256.

[106] E. Cambria, R. Speer, C. Havasi, A. Hussain, SenticNet: a publicly available
in: AAAI Fall Symposium:

resource for opinion mining,

semantic
Commonsense Knowledge, vol. 10, p. 02, 2010.

[107] X. Xueke, C. Xueqi, T. Songbo, L. Yue, S. Huawei, Aspect-level opinion mining

of online customer reviews, Commun. China 10 (3) (2013) 25–41.

[108] M. Abdul-Mageed, M. Diab, S. Kübler, SAMAR: subjectivity and sentiment

analysis for Arabic social media, Comput. Speech Lang. 28 (2014) 20–37.

[109] A. Abbasi, S. France, Z. Zhang, H. Chen, Selecting attributes for sentiment
classiﬁcation using feature relation networks, IEEE Trans. Knowl. Data Eng. 2
(3) (2011).

[110] M.D. Molina-González, E. Martínez-Cámara, M.-T. Martín-Valdivia, José M.
Perea-Ortega, Semantic orientation for polarity classiﬁcation in Spanish
reviews, Expert Syst. Appl. 40 (2013) 7250–7257.

[111] H. Kang, S.J. Yoo, D. Han, Senti-lexicon and improved Naïve Bayes algorithms
for sentiment analysis of restaurant reviews, Expert Syst. Appl. 39 (2012)
6000–6010.

[112] R. Prabowo, M. Thelwall, Sentiment analysis: a combined approach,

J.

Informet. 3 (2009) 143–157.

[113] J.C. de Albornoz, L. Plaza, P. Gervas, Sentisense: an easily scalable concept-
based affective lexicon for sentiment analysis, in: Proceedings of the 8th

(2010) 76–80.

[135] M. Hu, B. Liu, Mining opinion features in customer reviews, in: Proc. of the
Nineteenth National Conference on Artiﬁcial Intelligence (AAAI), 2004, pp.
755–760.

[136] E. Cambria, C. Havasi, A. Hussain, SenticNet 2: a semantic and affective
resource for opinion mining and sentiment analysis, Proc. 25th Int’l Florida
Artiﬁcial Intelligence Research Society Conf., AAAI, 2012, pp. 202–207.

[137] M. Tsytsarau, T. Palpanas, Survey on mining subjective data on the web, Data
Min. Knowl. Disc. 24 (2012) 478–514, http://dx.doi.org/10.1007/s10618-011-
0238-6.

[138] W. Medhat et al., Sentiment analysis algorithms and applications: a survey,

Ain Shams Eng. J. (2014), http://dx.doi.org/10.1016/j.asej.2014.04.011.

[139] M. Saif, D. Cody, D. Bonnie, Generating high-coverage semantic orientation
lexicons from overtly marked words and a thesaurus, Proceedings of the
2009 Conference on EMNLP, Association for Computational Linguistics,
Morristown, NJ, USA, 2009, pp. 599–608.

[140] E. Cambria, A. Hussain, Sentic Computing: Techniques, Tools, and

Applications, Springer, 2012.

[141] E. Cambria, J. Fu, F. Bisio, S. Poria, AffectiveSpace 2: Enabling affective
intuition for concept-level sentiment analysis, in: AAAI, 2015, pp. 508–514,
Austin.

[142] D. Tuﬁ, D. Stefenescu, Experiments with a differential semantics annotation

for WordNet 3.0, Decis. Support Syst. 53 (2012) 695–703.

[143] A. Popescu, O. Etzioni, Extracting product features and opinions from
reviews, in: Proc. of the Conference on Human Language Technology and
Empirical Methods in Natural Language Processing (HLT-EMNLP), 2005, pp.
339–346.

K. Ravi, V. Ravi / Knowledge-Based Systems 89 (2015) 14–46

45

[144] F. Cruz et al., A knowledge-rich approach to feature-based opinion extraction
from product reviews, Proc. 2nd Int’l Workshop on Search and Mining User-
Generated Contents, ACM Press, 2010, pp. 13–20.

[145] G. Qiu, B. Liu, J. Bu, C. Chen, Opinion word expansion and target extraction

through double propagation, Comput. Linguist. 37 (1) (2011) 9–27.

[146] T. Chklovski, P. Pantel, VerbOcean: mining the web for ﬁne-grained semantic
in: Proc. Conf. Empirical Methods in Natural Language

verb relations,
Processing, 2004, pp. 33–40.

[147] K. Scherer, H. Wallbott, The ISEAR Questionnaire and Codebook, Geneva

Emotion Research Group, 1997.

[148] E. Demirtas, Cross-Lingual Sentiment Analysis with Machine Translation,
Utility of Training Corpora and Sentiment Lexica, Master Thesis, University of
Technology, 2013.

[149] J. Blitzer, M. Dredze, F. Pereira, Biographies, bollywood, boom-boxes and
blenders: domain adaptation for sentiment classiﬁcation, in: Proceedings of
the 45th Annual Meeting of the Association for Computational Linguistics,
ACL’07, vol. 7, 2007, pp. 187–205 (13, 29).

[150] M. Collins, Discriminative training methods for hidden Markov models:
theory and experiments with perceptron algorithms, in: Proc. EMNLP, 2002.
[151] C.M. Whissel, The dictionary of affect in language, in: Emotion: Theory

Research and Experience, Acad Press, London, 1989.

[152] D. Haussler, Convolution Kernels on Discrete Structures, Technical Report,

University of California at Santa Cruz, 1999.

[153] E. Rilo, J. Wiebe, T. Wilson, Learning subjective nouns using extraction
in: Proc. Conf. Computational Natural Language

pattern bootstrapping,
Learning (CoNLL 03), 2003, pp. 25–32.

[154] M. Eirinaki, S. Pisal, J. Singh, Feature-based opinion mining and ranking, J.

Comput. Syst. Sci. 78 (2012) 1175–1184.

[155] X. Yu, Y. Liu, J.X. Huang, A. An, Mining online reviews for predicting sales
performance: a case study in the movie domain, IEEE Trans. Knowl. Data Eng.
24 (4) (2012).

[156] X. Bai, Predicting consumer sentiments from online text, Decis. Support Syst.

50 (2011) 732–742.

[157] Abd. S.H. Basari, B. Hussin, I.G.P. Ananta, J. Zeniarja, Opinion mining of movie
review using hybrid method of support vector machine and particle swarm
optimization, Proc. Eng. 53 (2013) 453–462.

[158] D. Kang, Y. Park, Review-based measurement of customer satisfaction in
mobile service: sentiment analysis and VIKOR approach, Expert Syst. Appl.
(2013), http://dx.doi.org/10.1016/j.eswa.2013.07.101.

[159] S. Pisal, J. Singh, M. Eirinaki, AskUs: an opinion search engine, data mining
workshops (ICDMW), in: 2011 IEEE 11th International Conference on, 11–11
December, 2011, pp. 1243–1246, http://dx.doi.org/10.1109/ICDMW.2011.24.
[160] A. Abbasi, H. Chen, A. Salem, Sentiment analysis in multiple languages:
feature selection for opinion classiﬁcation in web forums, ACM Trans. Inform.
Syst. 26 (3) (2008) (Article 12, Publication date: June 2008).

[161] H. Watanabe, A similarity-driven transfer system, in: Proc. of the 14th

COLING, vol. 2, 1992, pp. 770–776.

[162] L.K.W. Tan,

J.C. Na, Y.L. Theng, et al., Phrase-level sentiment polarity
classiﬁcation using rule-based typed dependencies and additional complex
phrases consideration, J. Comput. Sci. Technol. 27 (3) (2012) 650–666, http://
dx.doi.org/10.1007/s11390-012-1251-y.

[163] F. Bravo-Marquez et al., Meta-level sentiment models for big social data

analysis, Knowl.-Based Syst. 69 (2014) 86–99.

[164] A. Go, R. Bhayani, L. Huang, Twitter Sentiment Classiﬁcation using Distant

Supervision, Technical Report Stanford University, 2010.

[165] Z.-H. Deng, K.-H. Luo, H.-L. Yu, A study of supervised term weighting scheme

for sentiment analysis, Expert Syst. Appl. 41 (2014) 3506–3513.

[166] Y. Lu, X. Kong, X. Quan, W. Liu, Y. Xu, Exploring the sentiment strength of user
reviews, in: L. Chen et al. (Eds.), WAIM 2010, LNCS 6184, 2010, pp. 471–482.
[167] B. Pang, L. Lee, A sentiment education: sentiment analysis using subjectivity
summarization based on minimum cuts, in: Proceedings of the 42nd Annual
Meeting on Association for Computational Linguistics, July 2004, p. 271.

[168] R. McDonald et al., Structured models for ﬁne-to-coarse sentiment analysis,
in: Annual Meeting-Association For Computational Linguistics, vol. 45, no. 1,
2007.

[169] C. Whitelaw, N. Garg, S. Argamon, Using appraisal groups for sentiment
analysis,
in: Proceedings of the 14th ACM International Conference on
Information and Knowledge Management, October, ACM, 2005, pp. 625–631.
[170] H. Kanayama, T. Nasukawa, Fully automatic lexicon expansion for domain-
oriented sentiment analysis, in: Proceedings of the 2006 Conference on
Empirical Methods in Natural Language Processing, July, Association for
Computational Linguistics, 2006, pp. 355–363.

[171] T. Nasukawa, J. Yi, Sentiment analysis: capturing favorability using natural
language processing, in: Proceedings of the 2nd International Conference On
Knowledge Capture, October, ACM, 2003, pp. 70–77.

[172] T. Mullen, N. Collier, Sentiment analysis using support vector machines with

diverse information sources, in: EMNLP, July, vol. 4, 2004, pp. 412–418.

[173] K. Hiroshi, N. Tetsuya, W. Hideo, Deeper sentiment analysis using machine
translation technology, in: Proceedings of the 20th International Conference
on Computational Linguistics, Association for Computational Linguistics,
2004, p. 494.

[174] H.N.T. Xuan, A.C. Le, L.M. Nguyen, Linguistic features for subjectivity
classiﬁcation, in: International Conference on Asian Language Processing
(IALP), November 2012, IEEE, 2012, pp. 17–20.

[175] J.H. Wang, C.C. Lee, Unsupervised opinion phrase extraction and rating in
in: IEEE Third International Conference on Privacy,

Chinese blog posts,

Security, Risk And Trust, 2011 and IEEE Third International Conference on
Social Computing (SocialCom), October, IEEE, 2011, pp. 820–823.

[176] L. Jiang, M. Yu, M. Zhou, X. Liu, T. Zhao, Target-dependent Twitter sentiment

classiﬁcation, in: ACL, June 2011, pp. 151–160.

[177] A. Agarwal, B. Xie, I. Vovsha, O. Rambow, R. Passonneau, Sentiment analysis
of twitter data, in: Proceedings of the Workshop on Languages in Social
Media, June, Association for Computational Linguistics, 2011, pp. 30–38.

[178] F. Benamara, C. Cesarano, A. Picariello, D.R. Recupero, V.S. Subrahmanian,
Sentiment analysis: adjectives and adverbs are better than adjectives alone,
in: ICWSM, March 2007.

[179] E. Kouloumpis, T. Wilson, J. Moore, Twitter sentiment analysis: the good the

bad and the OMG! in: ICWSM, May 2011.

[180] V. Sindhwani, P. Melville, Document-word co-regularization for semi-
supervised sentiment analysis, in: Eighth IEEE International Conference on
Data Mining, December 2008, pp. 1025–1030.

[181] B. Liu, Sentiment Analysis and Opinion Mining, Morgan and Claypool

publishers, 2012 (May).

[182] R.Y.K. Lau, S.S.Y. Liao, C. Li, Social analytics: learning fuzzy product ontologies
for aspect-oriented sentiment analysis, Decis. Support Syst. (2014), http://
dx.doi.org/10.1016/j.dss.2014.05.005.

[183] A.K. Nassirtoussi, S. Aghabozorgi, T.Y. Wah, D.C.L. Ngo, Text mining of news-
headlines for FOREX market prediction: a multi-layer dimension reduction
algorithm with semantics & sentiment, Expert Syst. Appl. (2014), http://
dx.doi.org/10.1016/j.eswa.2014.08.004.

[184] X. Li et al., News impact on stock price return via sentiment analysis,

Knowl.-Based Syst. 69 (2014) 14–23.

[185] S. Moghaddam, M. Ester, The ﬂda model for aspect-based opinion mining:
addressing the cold start problem, in: Proceedings of the 22nd International
Conference on World Wide Web. International World Wide Web Conferences
Steering Committee, 2013, pp. 909–918.

[186] S. Kim, J. Zhang, Z. Chen, A. Oh, S. Liu, A hierarchical aspect-sentiment model

for online reviews, in: AAAI, 2013.

[187] H. Wang, Y. Lu, C. Zhai, Latent aspect rating analysis on review text data: a
in: The 16th ACM SIGKDD Conference on

rating regression approach,
Knowledge Discovery and Data Mining (KDD’2010), 2010, pp. 783–792.

[188] Y. Jo, A.H. Oh, Aspect and sentiment uniﬁcation model for online review
analysis, in: Proceedings of the Fourth ACM International Conference on Web
Search and Data Mining, ACM, 2011, pp. 815–824.

[189] T. Wang et al., Product aspect extraction supervised with online domain

knowledge, Knowl.-Based Syst. 71 (2014) 86–100.

[190] K. Zhang et al., Incorporating conditional random ﬁelds and active learning to

improve sentiment identiﬁcation, Neural Networks (2014).

[191] X. Zheng, Z. Lin, X. Wang, K.-J. Lin, M. Song,

Incorporating appraisal
expression patterns into topic modeling for aspect and sentiment word
identiﬁcation, Knowl.-Based Syst. 61 (2014) 29–47.

[192] T.R. Gruber, Toward principles for the design of ontologies used for

knowledge sharing?, Int J. Hum.–Comput. Stud. 43 (5) (1995) 907–928.

[193] Z. Hai, K. Chang, J.-J. Kim, C.C. Yang, Identifying features in opinion mining via
intrinsic and extrinsic domain relevance, IEEE Trans. Knowl. Data Eng. 26 (3)
(2014) 623–634.

[194] S. Mukherjee, S. Joshi, Sentiment aggregation using ConceptNet ontology, in:

IJCNLP, 2013.

[195] S. Mukherjee, S. Joshi, Author-speciﬁc sentiment aggregation for polarity
prediction of reviews, in: Proceedings of the 9th edition of the Language
Resources and Evaluation Conference (LREC 2014), 2014.

[196] L. Zhou, P. Chaovalit, Ontology-supported polarity mining, J. Am. Soc. Inform.

Sci. Ttechnol. 59 (1) (2008) 98–110.

[197] G. Vinodhini, R.M. Chandrasekaran, Opinion mining using principal
component analysis based ensemble model for e-commerce application,
CSI Trans. ICT (2014) 1–11.

[198] B. Pang, L. Lee, Seeing stars: exploiting class relationships for sentiment
categorization with respect to rating scales, in: Proceedings of the 43rd
Annual Meeting on Association for Computational Linguistics, ACL’05, 2005,
pp. 115–124.

[199] A. Heydari, Mhd. A. Tavakoli, N. Salim, Z. Heydari, Detection of review spam:

a survey, Expert Syst. Appl. 42 (7) (2015) 3634–3642.

[200] M. Ott, C. Cardie,

J.T. Hancock, Negative deceptive opinion spam,

in:
Proceedings of the 2013 Conference of the North American Chapter of the
Association for Computational Linguistics: Human Language Technologies,
June 2013, pp. 497–501.

[201] R. Socher, A. Perelygin, J.Y. Wu, J. Chuang, C.D. Manning, A.Y. Ng, C. Potts,
Recursive deep models for semantic compositionality over a sentiment
treebank, in: Proceedings of the Conference on Empirical Methods in Natural
Language Processing (EMNLP), vol. 1631, 2013, p. 1642.

[202] E. Cambria, D. Olsher, D. Rajagopal, SenticNet 3: a common and common-
sense knowledge base for cognition-driven sentiment analysis, in: Twenty-
eighth AAAI Conference on Artiﬁcial Intelligence, 2014, pp. 1515–1521.

[203] D. Bell, T. Koulouri, S. Lauria, R.D. Macredie, J. Sutton, Microblogging as a
mechanism for human–robot interaction, Knowl.-Based Syst. 69 (2014) 64–
77.

[204] K. Gimpel, N. Schneider, B. O’Connor, D. Das, D. Mills, J. Eisenstein, N.A. Smith,
Part-of-speech tagging for twitter: annotation, features, and experiments, in:
Carnegie-Mellon Univ Pittsburgh Pa School of Computer Science, 2010.

[205] S. Rill, D. Reinel, J. Scheidt, R.V. Zicari, PoliTwi: early detection of emerging
political topics on twitter and the impact on concept-level sentiment
analysis, Knowl.-Based Syst. 69 (2014) 24–33.

46

K. Ravi, V. Ravi / Knowledge-Based Systems 89 (2015) 14–46

[206] O. Popescu, C. Strapparava, Time corpora: epochs, opinions and changes,

Knowl.-Based Syst. 69 (2014) 3–13.

[207] C.-E. Wu, R.T.-H. Tsai, Using relation selection to improve value propagation
in a ConceptNet-based sentiment dictionary, Knowl.-Based Syst. 69 (2014)
100–107.

[208] D. Rajagopal, E. Cambria, D. Olsher, K. Kwok, A graph-based approach to
commonsense concept extraction and semantic similarity detection,
in:
Proceedings of the 22nd International Conference on World Wide Web
Companion (WWW’13), Republic and Canton of Geneva, Switzerland, 2013,
pp. 565–570.

[209] A. Ortigosa, J.M. Martín, R.M. Carro, Sentiment analysis in Facebook and its

application to e-learning, Comput. Hum. Behav. 31 (2014) 527–541.

[210] H. Costa, L.H.C. Merschmann, F. Barth, F. Benevenuto, Pollution, bad-
mouthing, and local marketing: the underground of location-based social
networks, Inform. Sci. 279 (2014) 123–137.

[211] A. Montejo-Ráez, M.C. Díaz-Galiano, F. Martinez-Santiago, L.A. Ureña-López,

Crowd explicit sentiment analysis, Knowl.-Based Syst. 69 (2014) 134–139.

[212] M. Ott, Y. Choi, C. Cardie, J.T. Hancock, Finding deceptive opinion spam by any
stretch of the imagination, in: Proceedings of the 49th Annual Meeting of the
Association for Computational Linguistics: Human Language Technologies,
vol. 1, 2011, pp. 309–319.

[213] S. Poria, E. Cambria, G. Winterstein, G.-B. Huang, Sentic patterns:
dependency-based rules for concept-level sentiment analysis, Knowl.-Based
Syst. 69 (2014) 45–63.

[214] S. Poria, A. Gelbukh, E. Cambria, A. Hussain, G.-B. Huang, EmoSenticSpace: a
novel framework for affective common-sense reasoning, Knowl.-Based Syst.
69 (2014) 108–123.

[215] G. Matthews, I.J. Deary, M.C. Whiteman, Personality Traits, Cambridge, UK,

2009, pp. 23–26.

[216] A. Weichselbraun, S. Gindl, A. Scharl, Enriching semantic knowledge bases for
opinion mining in big data applications, Knowl.-Based Syst. 69 (2014) 78–85.
[217] R. Justo, T. Corcoran, S.M. Lukin, M. Walker, M. InÃÓs Torres, Extracting
relevant knowledge for the detection of sarcasm and nastiness in the social
web, Knowl.-Based Syst. 69 (2014) 124–133.

[218] A. Bagheri et al., Care more about customers: unsupervised domain-
independent aspect detection for sentiment analysis of customer reviews,
Knowl.-Based Syst. 52 (2013) 201–213.

[219] C.P. Wei, Y.M. Chen, C.S. Yang, C.C. Yang, Understanding what concerns
feature extraction from

consumers: a semantic approach to product
consumer reviews, Inform. Syst. E-Bus. Manage. 8 (2) (2010) 149–167.

[220] S. Banerjee, Alton Y.K. Chua, Applauses in hotel reviews: Genuine or
deceptive?, in: Science and Information Conference (SAI), 2014, IEEE, 2014,
pp 938–942.

[221] H.-J. Min, J.C. Park, Identifying helpful reviews based on customer’s mentions

about experiences, Expert Syst. Appl. 39 (2012) 11830–11838.

[222] P. Racherla, W. Friske, Perceived ‘usefulness’ of online consumer reviews: an
exploratory investigation across three services categories, Electron. Commer.
Res. Appl. 11 (2012) 548–559.

[223] S.M. Mudambi, D. Schuff, What makes a helpful online review? A study of

customer reviews on amazon.com, MIS Quart. 34 (2010) 185–200.

[224] H. Huang, David C. Yen, Predicting the helpfulness of online reviews—a
replication, Int. J. Hum.–Comput. Interact. 29 (2) (2013) 129–138, http://
dx.doi.org/10.1080/10447318.2012.694791.

[225] C.C. Chen, Y.-D. Tseng, Quality evaluation of product reviews using an

information quality framework, Decis. Support Syst. 50 (2011) 755–768.

[226] S. Lee,

J.Y. Choeh, Predicting the helpfulness of online reviews using
multilayer perceptron neural networks, Expert Syst. Appl. 41 (2014) 3041–
3046.

[227] T.L. Ngo-Ye, A.P. Sinha, The inﬂuence of reviewer engagement characteristics
on online review helpfulness: a text regression model, Decis. Support Syst. 61
(2014) 47–58.

[228] S. Krishnamoorthy, Linguistic features for review helpfulness prediction,

Expert Syst. Appl. 42 (2015) 3751–3759.

[229] N. Purnawirawan, P. De Pelsmacker, N. Dens, Balance and sequence in online
J.

reviews: how perceived usefulness affects attitudes and intentions,
Interactive Market. 26 (2012) 244–255.

[230] M.A. Walker, P. Anand, J.E. Fox Tree, R. Abbott, J. King, A corpus for research

on deliberation and debate, in: LREC, 2012.

[231] Nan Hu, Ling Liu, V. Sambamurthy, Fraud detection in online consumer

reviews, Decis. Support Syst. 50 (2011) 614–626.

[232] D. Hernández Fusilier et al., Detecting positive and negative deceptive
(2014), http://

Inform. Process. Manage.

opinions using PU-learning,
dx.doi.org/10.1016/j.ipm.2014.11.001.

[233] B. Liu, Y. Dai, X.L. Li, W.S. Lee, Y. Philip, Partially supervised classiﬁcation of
text documents, in: ICML 2002, Proceedings of the Nineteenth International
Conference on Machine Learning, July 2002, pp. 387–394.
Jindal, Liu, Opinion spam and analysis, in: Proceedings of the International
Conference on Web Search and Web Data Mining, ACM, 2008.

[234]

[235] S.P. Algur, A.P. Patil, P.S. Hiremath, S. Shivashankar, Conceptual

level
similarity measure based review spam detection, in: 2010 International
Conference on Signal and Image Processing (ICSIP), IEEE, 2010, pp. 416–
423.

[236] F. Li, M. Huang, Y. Yang, X. Zhu, Learning to identify review spam, in: IJCAI
Proceedings-International Joint Conference on Artiﬁcial Intelligence, vol. 22,
no. 3, 2011, p. 2488.

[237] G. Wang, S. Xie, B. Liu, P.S. Yu, Review graph based online store review
spammer detection, in: 2011 IEEE 11th International Conference on Data
Mining (ICDM), IEEE, 2011, pp. 1242–1247.

[238] E.-P. Lim, V.-A. Nguyen, N. Jindal, B. Liu, H.W. Lauw, Detecting product review
spammers using rating behaviors,
the 19th ACM
International Conference on Information and Knowledge Management,
ACM, 2010, pp. 939–948.

in: Proceedings of

[239] A. Mukherjee, B. Liu, N. Glance, Spotting fake reviewer groups in consumer
reviews, in: Proceedings of the 21st International Conference on World Wide
Web, ACM, 2012, pp. 191–200.

[240] H. Xu et al., Implicit feature identiﬁcation in Chinese reviews using explicit

topic mining model, Knowl.-Based Syst. 76 (2015) 166–175.

[241] Z. Yan et al., EXPRS: an extended pagerank method for product feature
extraction from online consumer reviews, Inform. Manage. (2015), http://
dx.doi.org/10.1016/j.im.2015.02.002.

[242] C. Zhang, D. Zeng, J. Li, F.-Y. Wang, W. Zuo, Sentiment analysis of chinese
documents: from sentence to document level, J. Am. Soc. Inform. Sci. Technol.
60 (12) (2009) 2474–2487.

[243] S. Li, L. Zhou, Y. Li, Improving aspect extraction by augmenting a frequency-
based method with web-based similarity measures, Inform. Process. Manage.
51 (2015) 58–67.

[244] O. Owoputi, B. O’Connor, C. Dyer, K. Gimpel, N. Schneider, N.A. Smith,
Improved part-of-speech tagging for online conversational text with word
clusters, in: HLT-NAACL, 2013, pp. 380–390.

[245] C. Paice, Another stemmer, SIGIR Forum 24 (3) (1990) 56–61.
[246] K. Atkinson, Gnu Aspell 0.60.4, 2006.
[247] M.F. Porter, Snowball: A Language for Stemming Algorithms, 2001.
[248] K. Toutanova, D. Klein, C. Manning, Y. Singer, Feature-rich part-of-speech
tagging with a cyclic dependency network, in: Proceedings of HLT-NAACL
2003, pp. 252–259.

[249] L. Kong, N. Schneider, S. Swayamdipta, A. Bhatia, C. Dyer, N.A. Smith, A
dependency parser for tweets, in: Proceedings of the Conference on Empirical
Methods in Natural Language Processing, Doha, Qatar, vol. 4, no. 1.2., 2014.
[250] L. Derczynski, A. Ritter, S. Clarke, K. Bontcheva, Twitter part-of-speech
tagging for all: overcoming sparse and noisy data, in: Proceedings of the
International Conference on Recent Advances
in Natural Language
Processing, ACL, 2013.

[251] B. O’Connor, M. Krieger, D. Ahn, TweetMotif: exploratory search and topic

summarization for Twitter, in: ICWSM-2010, 2010.

